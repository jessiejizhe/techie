{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Techie A collection of Techie concepts GitHub Page Whenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files. Theme used: MKDocs python -m pip install --upgrade pip pip install mkdocs Make changes and test in browser mkdocs serve http://127.0.0.1:8000/ Generate a /site directory and publish to github pages mkdocs build mkdocs gh-deploy Markdown Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for Syntax highlighted code block # Header 1 ## Header 2 ### Header 3 - Bulleted - List 1. Numbered 2. List **Bold** and _Italic_ and `Code` text [Link](url) and ![Image](src) For more details see GitHub Flavored Markdown .","title":"Home"},{"location":"#techie","text":"A collection of Techie concepts","title":"Techie"},{"location":"#github-page","text":"Whenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files. Theme used: MKDocs python -m pip install --upgrade pip pip install mkdocs Make changes and test in browser mkdocs serve http://127.0.0.1:8000/ Generate a /site directory and publish to github pages mkdocs build mkdocs gh-deploy","title":"GitHub Page"},{"location":"#markdown","text":"Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for Syntax highlighted code block # Header 1 ## Header 2 ### Header 3 - Bulleted - List 1. Numbered 2. List **Bold** and _Italic_ and `Code` text [Link](url) and ![Image](src) For more details see GitHub Flavored Markdown .","title":"Markdown"},{"location":"ETL/","text":"ETL DBT DBT ( Data Building Tool ) is a command-line tool that enables data analysts and engineers to transform data in their warehouses simply by writing select statements . DBT performs the T (Transform) of ETL but it doesn\u2019t offer support for Extraction and Load operations. DBT\u2019s only function is to take code, compile it to SQL, and then run against your database. Multiple databases are supported, including: Postgres Redshift BigQuery Snowflake Presto DBT can be easily installed using pip (the Python package installers) and it comes with both CLI and a UI. The CLI offers a set of functionalities to execute your data pipelines: run tests , compile , generate documentation, etc. The UI doesn\u2019t offer the possibility to change your data pipeline and it is used mostly for documentation purposes. One of the most important concepts in DBT is the concept of model . Every model is a select statement that has to be orchestrated with the other models to transform the data in the desired way. Every model is written using the query language of your favorite data warehouse (DW). The output of each model can be stored in different ways, depending on the desired behavior: Materialize a table \u2014 full refresh Append to a table \u2014 incrementally build your output Ephemeral \u2014 the output will not be stored in your DW but it can be used as a data source from other models. Every DBT model can be complemented with a schema definition . This means that the documentation lives in the same repository as your codebase, making it easier to understand every step of what has been developed. DBT helps to serve high-quality data, allowing you to write different typologies of tests to check your data . Simple tests can be defined using YAML syntax, placing the test file in the same folder as your models. More advanced testing can be implemented using SQL syntax. Pros: It is Opensource and open to customization. It is easy to apply version control The documentation lives with your DBT project and it is automatically generated from your codebase. It doesn\u2019t require any specific skills on the jobs market. If your engineers are familiar with SQL and have a basic knowledge of Python, that\u2019s enough to approach DBT. The template of each project is automatically generated running DBT init. This enforces a standard for all of our data pipelines. All of the computational work is pushed towards your DW. This allows you to attain high performance when using a technology similar to BigQuery or Snowflake. Because of the point above, orchestrating a DBT pipeline requires minimal resources. It allows you to test your data (schema tests, referential integrity tests, custom tests) and ensures data quality. It makes it easier to debug complex chains of queries . They can be split into multiple models and macros that can be tested separately. It\u2019s well documented and the learning curve is not very steep. Cons: SQL based ; it might offer less readability compared with tools that have an interactive UI. Lack of debugging functionalities is a problem, especially when you write complex macros . Sometimes you will find yourself overriding DBT standard behaviour, rewriting macros that are used behind the scenes. This requires an understanding of the source code. The UI is for documentation-only purposes . It helps you to visualise the transformation process, but it\u2019s up to your data engineers to keep the DBT project tidy and understandable. Having an interactive UI that allows you to visually see the flow of the pipeline and amend the queries can be helpful, especially when it comes to complex data pipelines. Documentation generation for BigQuery is time-consuming due to a poor implementation that scans all of the shards inside a dataset. It covers only the T of ETL , so you will need other tools to perform Extraction and Load.","title":"ETL"},{"location":"ETL/#etl","text":"","title":"ETL"},{"location":"ETL/#dbt","text":"DBT ( Data Building Tool ) is a command-line tool that enables data analysts and engineers to transform data in their warehouses simply by writing select statements . DBT performs the T (Transform) of ETL but it doesn\u2019t offer support for Extraction and Load operations. DBT\u2019s only function is to take code, compile it to SQL, and then run against your database. Multiple databases are supported, including: Postgres Redshift BigQuery Snowflake Presto DBT can be easily installed using pip (the Python package installers) and it comes with both CLI and a UI. The CLI offers a set of functionalities to execute your data pipelines: run tests , compile , generate documentation, etc. The UI doesn\u2019t offer the possibility to change your data pipeline and it is used mostly for documentation purposes. One of the most important concepts in DBT is the concept of model . Every model is a select statement that has to be orchestrated with the other models to transform the data in the desired way. Every model is written using the query language of your favorite data warehouse (DW). The output of each model can be stored in different ways, depending on the desired behavior: Materialize a table \u2014 full refresh Append to a table \u2014 incrementally build your output Ephemeral \u2014 the output will not be stored in your DW but it can be used as a data source from other models. Every DBT model can be complemented with a schema definition . This means that the documentation lives in the same repository as your codebase, making it easier to understand every step of what has been developed. DBT helps to serve high-quality data, allowing you to write different typologies of tests to check your data . Simple tests can be defined using YAML syntax, placing the test file in the same folder as your models. More advanced testing can be implemented using SQL syntax. Pros: It is Opensource and open to customization. It is easy to apply version control The documentation lives with your DBT project and it is automatically generated from your codebase. It doesn\u2019t require any specific skills on the jobs market. If your engineers are familiar with SQL and have a basic knowledge of Python, that\u2019s enough to approach DBT. The template of each project is automatically generated running DBT init. This enforces a standard for all of our data pipelines. All of the computational work is pushed towards your DW. This allows you to attain high performance when using a technology similar to BigQuery or Snowflake. Because of the point above, orchestrating a DBT pipeline requires minimal resources. It allows you to test your data (schema tests, referential integrity tests, custom tests) and ensures data quality. It makes it easier to debug complex chains of queries . They can be split into multiple models and macros that can be tested separately. It\u2019s well documented and the learning curve is not very steep. Cons: SQL based ; it might offer less readability compared with tools that have an interactive UI. Lack of debugging functionalities is a problem, especially when you write complex macros . Sometimes you will find yourself overriding DBT standard behaviour, rewriting macros that are used behind the scenes. This requires an understanding of the source code. The UI is for documentation-only purposes . It helps you to visualise the transformation process, but it\u2019s up to your data engineers to keep the DBT project tidy and understandable. Having an interactive UI that allows you to visually see the flow of the pipeline and amend the queries can be helpful, especially when it comes to complex data pipelines. Documentation generation for BigQuery is time-consuming due to a poor implementation that scans all of the shards inside a dataset. It covers only the T of ETL , so you will need other tools to perform Extraction and Load.","title":"DBT"},{"location":"checklist/","text":"[ ] DevOps [ ] operating system [ ] file system [ ] developer environment [ ] git [ ] ssh [ ] vim [ ] Regex [ ] CI/CD [ ] Docker [ ] Kubernetes [ ] Data Formats [ ] avro [ ] csv [ ] parquet [ ] xml [ ] json [ ] lz4 [ ] orc [ ] data/dat [ ] Data Ingestion [ ] Kafka [ ] RabbitMQ [ ] Fluentd [ ] Sqoop [ ] Kinesis (AWS) [ ] Data Model [ ] Relational [ ] MySQL [ ] PostgreSQL [ ] RDS (AWS) [ ] Key Value [ ] Redis [ ] Riak [ ] DynamoDB (AWS) [ ] Columnar [ ] Casandra [ ] HBase [ ] RedShift (AWS) [ ] Document [ ] MongoDB [ ] ElasticSearch [ ] CouchBase [ ] Graph [ ] Neo4J [ ] OrientDB [ ] ArangoDB [ ] Query [ ] Batch [ ] MapReduce [ ] Spark [ ] Elastic MapReduce (AWS) [ ] Batch SQL [ ] Hive [ ] Presto [ ] Drill [ ] Streaming [ ] Storm [ ] Spark Streaming [ ] Samza [ ] Misc [ ] Druid - real-time analytics database designed for fast slice-and-dice analytics (\"OLAP\" queries) [ ] OracleDB - multi-model database management system, commonly used for running online transaction processing, data warehousing and mixed database workloads. [ ] Statistics [ ] Hypothesis Test [ ] A/B Testing [ ] Experiment Design [ ] Machine Learning [ ] Linear Regression [ ] Logistic Regression [ ] K-Nearest Neighbors [ ] Naive Bayes [ ] Support Vector Machine [ ] Decision Tree [ ] Random Forest [ ] AdaBoost [ ] Gradient Boost [ ] XGBoost [ ] LightGBM [ ] CatBoost [ ] Causal Inference [ ] Data Structures [ ] Array [ ] Linked List [ ] Tuple / Struct [ ] Hash Table / Dictionary [ ] Stack [ ] Queue [ ] Heap [ ] Tree [ ] Graph [ ] Matrix [ ] Algorithms [ ] divide and conquer [ ] string manipulation [ ] two pointers [ ] searching (binary, BFS, DFS) [ ] sorting (quick, merge, bubble, heap, bucket, counting, selection, insertion) [ ] bit manipulations [ ] typological order [ ] dynamic programming [ ] greedy [ ] hashing [ ] backtracking [ ] Programming Languages [ ] Bash [ ] Python [ ] R [ ] Java [ ] JavaScript [ ] HTML [ ] CSS [ ] Apache [x] Hadoop [x] MapReduce [x] HDFS [ ] YARN [ ] Airflow [ ] DataFu [ ] Druid [ ] Flume [ ] Hive [ ] Kafka [ ] Maven [ ] Oozie [ ] Pig [ ] Phoenix [ ] Spark [ ] Storm [ ] Stream [ ] Superset [ ] Traffic System (ATS) [ ] Zeppelin [ ] Zookeeper","title":"Checklist"},{"location":"data/","text":"Data Serialization Data Formats avro Apache Avro\u2122 is a data serialization system. Avro stores the data definition in JSON format. Avro relies on schema, to have smaller serialization size, and to handle schema changes like missing fields, added fields and changed fields; as a result, old programs can read new data and new programs can read old data. csv A comma-separated values ( CSV ) file is a delimited text file that uses a comma) to separate values. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields. data / dat .data or .dat is a file containing pertinent information about a program or another file. json lz4 orc parquet xml Databases Druid Redis Database Engines Hive MySQL MongoDB NoSQL Oracle PostgreSQL Redshift SQLlite","title":"Data Serialization"},{"location":"data/#data-serialization","text":"","title":"Data Serialization"},{"location":"data/#data-formats","text":"","title":"Data Formats"},{"location":"data/#avro","text":"Apache Avro\u2122 is a data serialization system. Avro stores the data definition in JSON format. Avro relies on schema, to have smaller serialization size, and to handle schema changes like missing fields, added fields and changed fields; as a result, old programs can read new data and new programs can read old data.","title":"avro"},{"location":"data/#csv","text":"A comma-separated values ( CSV ) file is a delimited text file that uses a comma) to separate values. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields.","title":"csv"},{"location":"data/#data-dat","text":".data or .dat is a file containing pertinent information about a program or another file.","title":"data / dat"},{"location":"data/#json","text":"","title":"json"},{"location":"data/#lz4","text":"","title":"lz4"},{"location":"data/#orc","text":"","title":"orc"},{"location":"data/#parquet","text":"","title":"parquet"},{"location":"data/#xml","text":"","title":"xml"},{"location":"data/#databases","text":"","title":"Databases"},{"location":"data/#druid","text":"","title":"Druid"},{"location":"data/#redis","text":"","title":"Redis"},{"location":"data/#database-engines","text":"","title":"Database Engines"},{"location":"data/#hive","text":"","title":"Hive"},{"location":"data/#mysql","text":"","title":"MySQL"},{"location":"data/#mongodb","text":"","title":"MongoDB"},{"location":"data/#nosql","text":"","title":"NoSQL"},{"location":"data/#oracle","text":"","title":"Oracle"},{"location":"data/#postgresql","text":"","title":"PostgreSQL"},{"location":"data/#redshift","text":"","title":"Redshift"},{"location":"data/#sqllite","text":"","title":"SQLlite"},{"location":"Apache/HDFS/","text":"HDFS Overview Design Concept Scalable distributed filesystem Distribute data on local disks on several nodes Low cost commodity hardware Design Factors Hundreds/Thousands of nodes Portability across heterogeneous hardware/software Handle large data sets High throughput Approach Simplified coherency model \u2013 write once read many Data Replication \u2013 helps handle hardware failures Move computation close to data Relax POSIX requirements \u2013 increase throughput POSIX - Portable Operating System Interface, an IEEE standard designed to facilitate application portability Summary Single NameNode a master server that manages the file system namespace and regulates access to files by clients Multiple DataNotes typically one per node in the cluster Functions Manage storage Serving read/write requests from clients Block creation, deletion, replication based on instructions from NameNode HDFS -> HDFS2 HDFS has single NameNode and multiple DataNodes. HDFS2 improvements: HDFS Federation benefits increased namespace scalability performance isolation Multiple Namenode servers Multiple namespaces High Availability (redundant NameNodes) Heterogeneous Storage and Archival Storage (ARCHIVE, DISK, SSD, RAM_DISK) Write Process write process is initiated by a client Data gets cached on the client NameNode contacted once a block of data is accumulated NameNode responds with list of DataNodes NameNode is Rack aware Rack awareness is the knowledge of network structure(topology). i.e. location of different data node across the Hadoop cluster. 1stDataNode receives data, writes to local and forwards to 2nd DataNode ... NameNode commits file creation into persistent store. NameNode receives heartbeat and block reports from all DataNodes. Read Process Client gets DataNode list from NameNode Read from replica closest to reader Performance Envelope HDFS block size default block size is 64MB good for large files Importance of #blocks in a file NameNode memory usage Every block represented as object (default replication this will be further increased 3X) Number of map tasks data typically processed block at a time A lot of #small files Impact on NameNode Memory usage ~150 bytes per object 1 billion objects => 300GB memory! Network load Number of checks with DataNodes proportional to number of blocks Performance Impact Map tasks depends on #blocks 10GB of data, 32k file size => 327680 map tasks \u21d2lots of queued tasks \u21d2large overhead of spin up/tear down for each task (latency) \u21d2Inefficient disk I/O with small sizes Large files lots of small files is bad! Solutions Merge/Concatenate files Sequence files HBase, HIVE configuration CombineFileInputFormat optimizes maps Tuning Parameters Parameters in hdfs-site.xml Block Size default 64MB typically bumped up to 128MB parameter: dfs.blocksize, dfs.block.size Replication default is 3 parameter: dfs.replication tradeoffs Lower it to reduce replication cost, less robust Higher replication can make data local to more workers node count map task Full list dfs.datanode.handler.count (10): Sets the number of server threads on each datanode. dfs.namenode.fs-limits.max-blocks-per-file: Maximum number of blocks per file. Robustness NameNode receives heartbeat and block reports from DataNodes Replication trade off w.r.t robustness Might lose a node or local disk during the run \u2013 cannot recover if there is no replication. If there is data corruption of a block from one of the DataNodes \u2013 again cannot recover without replication. Common Failures & Mitigations Common Failures DataNode Failures: Server can fail, disk can crash, data corruption. Network Failures NameNode Failures: Disk failure, node failure Mitigation of Common Failures Periodic heartbeat: from DataNode to NameNode. For DataNodes without recent heartbeat Marked dead, no new IO sent Blocks below replication factor re-replicated on other nodes. Data Corruption Checksum computed on file creation Checksums stored in HDFS namespace. Used to check retrieved data, re-read from alternate replica if need. Multiple copies of central meta data structures. Failover to standby NameNode \u2013 manual by default. HDFS Access HDFS command invoked via bin/hdfs script user commands - filesystem shell commands administrator commands debug commands HDFS NFS Gateway Mount HDFS as a filesystem on the client Browse files using regular filesystem commands Upload/download files from HDFS Stream data to HDFS Apache Flume collecting, aggregating streaming data and moving into HDFS Apache Sqoop Bulk transfers between Hadoop and datastores. HDFS APIs Native Java API for HDFS** Base class : org.apache.hadoop.fs.FileSystem Important classes FSDataInputStream read : read bytes readFully : read from stream to buffer seek: seek to given offset getPos: get current position in stream FSDataOutputStream getPos: get current position in stream hflush: flush out the data in client's user buffer close: close the underlying output stream Methods : get, open, create Reading from HDFS using API get an instance of FileSystem FileSystem fs = FileSystem.get(URI.create(uri),conf); Open an input stream in = fs.open(new Path(uri)); Use IO utilities to copy from input stream IOUtils.copyBytes(in, System.out,4096,false); Close the stream IOUtils.closeStream(in) Writing to HDFS using API get an instance of FileSystem FileSystem fs = FileSystem.get(URI.create(outuri),conf); Create a file out = fs.create(new Path(outuri)); Write to output stream out.write(buffer, 0, nbytes); Close the file out.close(); C API for HDFS libhdfs, header file (hdfs.h) WebHDFS REST API Enabling WebHDFS in hdfs-site.xml dfs.webhdfs.enabled dfs.web.authentication.kerberos.principal dfs.web.authentication.kerberos.keytab HTTP Operations HTTP GET: file status, checksums, attributes HTTP PUT: create, change ownership, rename, permissions,snapshot HTTP POST: append, concat HTTP DELETE: Delete files, snapshot","title":"HDFS"},{"location":"Apache/HDFS/#hdfs","text":"","title":"HDFS"},{"location":"Apache/HDFS/#overview","text":"Design Concept Scalable distributed filesystem Distribute data on local disks on several nodes Low cost commodity hardware Design Factors Hundreds/Thousands of nodes Portability across heterogeneous hardware/software Handle large data sets High throughput Approach Simplified coherency model \u2013 write once read many Data Replication \u2013 helps handle hardware failures Move computation close to data Relax POSIX requirements \u2013 increase throughput POSIX - Portable Operating System Interface, an IEEE standard designed to facilitate application portability Summary Single NameNode a master server that manages the file system namespace and regulates access to files by clients Multiple DataNotes typically one per node in the cluster Functions Manage storage Serving read/write requests from clients Block creation, deletion, replication based on instructions from NameNode","title":"Overview"},{"location":"Apache/HDFS/#hdfs-hdfs2","text":"HDFS has single NameNode and multiple DataNodes. HDFS2 improvements: HDFS Federation benefits increased namespace scalability performance isolation Multiple Namenode servers Multiple namespaces High Availability (redundant NameNodes) Heterogeneous Storage and Archival Storage (ARCHIVE, DISK, SSD, RAM_DISK)","title":"HDFS -&gt; HDFS2"},{"location":"Apache/HDFS/#write-process","text":"write process is initiated by a client Data gets cached on the client NameNode contacted once a block of data is accumulated NameNode responds with list of DataNodes NameNode is Rack aware Rack awareness is the knowledge of network structure(topology). i.e. location of different data node across the Hadoop cluster. 1stDataNode receives data, writes to local and forwards to 2nd DataNode ... NameNode commits file creation into persistent store. NameNode receives heartbeat and block reports from all DataNodes.","title":"Write Process"},{"location":"Apache/HDFS/#read-process","text":"Client gets DataNode list from NameNode Read from replica closest to reader","title":"Read Process"},{"location":"Apache/HDFS/#performance-envelope","text":"HDFS block size default block size is 64MB good for large files Importance of #blocks in a file NameNode memory usage Every block represented as object (default replication this will be further increased 3X) Number of map tasks data typically processed block at a time A lot of #small files Impact on NameNode Memory usage ~150 bytes per object 1 billion objects => 300GB memory! Network load Number of checks with DataNodes proportional to number of blocks Performance Impact Map tasks depends on #blocks 10GB of data, 32k file size => 327680 map tasks \u21d2lots of queued tasks \u21d2large overhead of spin up/tear down for each task (latency) \u21d2Inefficient disk I/O with small sizes Large files lots of small files is bad! Solutions Merge/Concatenate files Sequence files HBase, HIVE configuration CombineFileInputFormat optimizes maps","title":"Performance Envelope"},{"location":"Apache/HDFS/#tuning-parameters","text":"Parameters in hdfs-site.xml Block Size default 64MB typically bumped up to 128MB parameter: dfs.blocksize, dfs.block.size Replication default is 3 parameter: dfs.replication tradeoffs Lower it to reduce replication cost, less robust Higher replication can make data local to more workers node count map task Full list dfs.datanode.handler.count (10): Sets the number of server threads on each datanode. dfs.namenode.fs-limits.max-blocks-per-file: Maximum number of blocks per file.","title":"Tuning Parameters"},{"location":"Apache/HDFS/#robustness","text":"NameNode receives heartbeat and block reports from DataNodes Replication trade off w.r.t robustness Might lose a node or local disk during the run \u2013 cannot recover if there is no replication. If there is data corruption of a block from one of the DataNodes \u2013 again cannot recover without replication.","title":"Robustness"},{"location":"Apache/HDFS/#common-failures-mitigations","text":"Common Failures DataNode Failures: Server can fail, disk can crash, data corruption. Network Failures NameNode Failures: Disk failure, node failure Mitigation of Common Failures Periodic heartbeat: from DataNode to NameNode. For DataNodes without recent heartbeat Marked dead, no new IO sent Blocks below replication factor re-replicated on other nodes. Data Corruption Checksum computed on file creation Checksums stored in HDFS namespace. Used to check retrieved data, re-read from alternate replica if need. Multiple copies of central meta data structures. Failover to standby NameNode \u2013 manual by default.","title":"Common Failures &amp; Mitigations"},{"location":"Apache/HDFS/#hdfs-access","text":"HDFS command invoked via bin/hdfs script user commands - filesystem shell commands administrator commands debug commands HDFS NFS Gateway Mount HDFS as a filesystem on the client Browse files using regular filesystem commands Upload/download files from HDFS Stream data to HDFS Apache Flume collecting, aggregating streaming data and moving into HDFS Apache Sqoop Bulk transfers between Hadoop and datastores.","title":"HDFS Access"},{"location":"Apache/HDFS/#hdfs-apis","text":"","title":"HDFS APIs"},{"location":"Apache/HDFS/#native-java-api-for-hdfs","text":"Base class : org.apache.hadoop.fs.FileSystem Important classes FSDataInputStream read : read bytes readFully : read from stream to buffer seek: seek to given offset getPos: get current position in stream FSDataOutputStream getPos: get current position in stream hflush: flush out the data in client's user buffer close: close the underlying output stream Methods : get, open, create Reading from HDFS using API get an instance of FileSystem FileSystem fs = FileSystem.get(URI.create(uri),conf); Open an input stream in = fs.open(new Path(uri)); Use IO utilities to copy from input stream IOUtils.copyBytes(in, System.out,4096,false); Close the stream IOUtils.closeStream(in) Writing to HDFS using API get an instance of FileSystem FileSystem fs = FileSystem.get(URI.create(outuri),conf); Create a file out = fs.create(new Path(outuri)); Write to output stream out.write(buffer, 0, nbytes); Close the file out.close();","title":"Native Java API for HDFS**"},{"location":"Apache/HDFS/#c-api-for-hdfs","text":"libhdfs, header file (hdfs.h)","title":"C API for HDFS"},{"location":"Apache/HDFS/#webhdfs-rest-api","text":"Enabling WebHDFS in hdfs-site.xml dfs.webhdfs.enabled dfs.web.authentication.kerberos.principal dfs.web.authentication.kerberos.keytab HTTP Operations HTTP GET: file status, checksums, attributes HTTP PUT: create, change ownership, rename, permissions,snapshot HTTP POST: append, concat HTTP DELETE: Delete files, snapshot","title":"WebHDFS REST API"},{"location":"Apache/Hadoop/","text":"Hadoop Framework Basic Modules Common (libraries) HDFS (file system) YARN (resource manager & job scheduler) MapReduce (programming model to scale data across different processes) Improvements MapReduce -> YARN Separate resource management and job scheduling/monitoring. YARN improvements global ResourceManager NodeManager on each node ApplicationMaster per application High Availability ResouceManager Timeline Server Use of Cgroups Secure Containers web services REST APIs HDFS -> HDFS2 HDFS has single NameNode and multiple DataNodes. HDFS2 improvements HDFS Federation benefits increased namespace scalability performance isolation Multiple Namenode servers Multiple namespaces High Availability (redundant NameNodes) Heterogeneous Storage and Archival Storage (ARCHIVE, DISK, SSD, RAM_DISK) Hadoop -> Spark Spark is multi-stage in-memory programming Hadoop is 2-stage disk based map reduce programming Spark requires a cluster management and a distributed storage system. Hadoop Frameworks supports in-memory caching data Tez Dataflow graphs Custom data types Can run complex DAG of tasks Dynamic DAG changes Resource usage efficiency Spark Advanced DAG execution engine Supports cyclic data flow (good for machine learning) In-memory computing Java, Scala, Python, R Existing optimized libraries Hadoop Resource Scheduling Schedulers are by default - FIFO (queue). Fairshare Scheduler try to balance out the resource allocation across applications over time Balances out resource allocation among apps over time Can organize into queues/sub-queues Guarantee minimum shares Limits per user/app Weighted app priorities Capacity Scheduler guaranteed capacity for each application or group, and there are safeguards to prevent a user or an application from taking down the whole cluster by running it out of resources queues and sub-queues Capacity Guarantee with elasticity ACLs for security An ACL (access control list) provides a way to set different permissions for specific named users or named groups, not only the file's owner and the file's group. Runtime changes/draining apps Resource based scheduling Hadoop-Based Applications Databases / Stores avro data structures within context of Hadoop MapReduce jobs Hbase Scalable data store Non-relational distributed database Runs on top of HDFS Compression In-memory operations: MemStore, BlockCache Features Consistency High Availability Automatic Sharding Replication Security SQL like access (Hive, Spark, Impala) Cassandra distributed data management system Querying Pig Platform for data processing, good for ETL Components Pig Latin: High level language infrastructure layer Execution environment local MapReduce Tez Extensible (can write custom functions) Hive Data warehouse software HiveQL: SQL like language to structure and query data Data in HDFS, HBase Execution environment MapReduce Tez Spark Custom mappers/reducers Table and storage management Beeline Hive command line interface (CLI) HCatalog webHcat (REST API for HCatalog) Impala Spark Machine Learning / Graph Processing Giraph Mahout Spark","title":"Hadoop"},{"location":"Apache/Hadoop/#hadoop-framework-basic-modules","text":"Common (libraries) HDFS (file system) YARN (resource manager & job scheduler) MapReduce (programming model to scale data across different processes)","title":"Hadoop Framework Basic Modules"},{"location":"Apache/Hadoop/#improvements","text":"","title":"Improvements"},{"location":"Apache/Hadoop/#mapreduce-yarn","text":"Separate resource management and job scheduling/monitoring. YARN improvements global ResourceManager NodeManager on each node ApplicationMaster per application High Availability ResouceManager Timeline Server Use of Cgroups Secure Containers web services REST APIs","title":"MapReduce -&gt; YARN"},{"location":"Apache/Hadoop/#hdfs-hdfs2","text":"HDFS has single NameNode and multiple DataNodes. HDFS2 improvements HDFS Federation benefits increased namespace scalability performance isolation Multiple Namenode servers Multiple namespaces High Availability (redundant NameNodes) Heterogeneous Storage and Archival Storage (ARCHIVE, DISK, SSD, RAM_DISK)","title":"HDFS -&gt; HDFS2"},{"location":"Apache/Hadoop/#hadoop-spark","text":"Spark is multi-stage in-memory programming Hadoop is 2-stage disk based map reduce programming Spark requires a cluster management and a distributed storage system.","title":"Hadoop -&gt; Spark"},{"location":"Apache/Hadoop/#hadoop-frameworks","text":"supports in-memory caching data","title":"Hadoop Frameworks"},{"location":"Apache/Hadoop/#tez","text":"Dataflow graphs Custom data types Can run complex DAG of tasks Dynamic DAG changes Resource usage efficiency","title":"Tez"},{"location":"Apache/Hadoop/#spark","text":"Advanced DAG execution engine Supports cyclic data flow (good for machine learning) In-memory computing Java, Scala, Python, R Existing optimized libraries","title":"Spark"},{"location":"Apache/Hadoop/#hadoop-resource-scheduling","text":"Schedulers are by default - FIFO (queue).","title":"Hadoop Resource Scheduling"},{"location":"Apache/Hadoop/#fairshare-scheduler","text":"try to balance out the resource allocation across applications over time Balances out resource allocation among apps over time Can organize into queues/sub-queues Guarantee minimum shares Limits per user/app Weighted app priorities","title":"Fairshare Scheduler"},{"location":"Apache/Hadoop/#capacity-scheduler","text":"guaranteed capacity for each application or group, and there are safeguards to prevent a user or an application from taking down the whole cluster by running it out of resources queues and sub-queues Capacity Guarantee with elasticity ACLs for security An ACL (access control list) provides a way to set different permissions for specific named users or named groups, not only the file's owner and the file's group. Runtime changes/draining apps Resource based scheduling","title":"Capacity Scheduler"},{"location":"Apache/Hadoop/#hadoop-based-applications","text":"","title":"Hadoop-Based Applications"},{"location":"Apache/Hadoop/#databases-stores","text":"","title":"Databases / Stores"},{"location":"Apache/Hadoop/#avro","text":"data structures within context of Hadoop MapReduce jobs","title":"avro"},{"location":"Apache/Hadoop/#hbase","text":"Scalable data store Non-relational distributed database Runs on top of HDFS Compression In-memory operations: MemStore, BlockCache Features Consistency High Availability Automatic Sharding Replication Security SQL like access (Hive, Spark, Impala)","title":"Hbase"},{"location":"Apache/Hadoop/#cassandra","text":"distributed data management system","title":"Cassandra"},{"location":"Apache/Hadoop/#querying","text":"","title":"Querying"},{"location":"Apache/Hadoop/#pig","text":"Platform for data processing, good for ETL Components Pig Latin: High level language infrastructure layer Execution environment local MapReduce Tez Extensible (can write custom functions)","title":"Pig"},{"location":"Apache/Hadoop/#hive","text":"Data warehouse software HiveQL: SQL like language to structure and query data Data in HDFS, HBase Execution environment MapReduce Tez Spark Custom mappers/reducers Table and storage management Beeline Hive command line interface (CLI) HCatalog webHcat (REST API for HCatalog)","title":"Hive"},{"location":"Apache/Hadoop/#impala","text":"","title":"Impala"},{"location":"Apache/Hadoop/#spark_1","text":"","title":"Spark"},{"location":"Apache/Hadoop/#machine-learning-graph-processing","text":"","title":"Machine Learning / Graph Processing"},{"location":"Apache/Hadoop/#giraph","text":"","title":"Giraph"},{"location":"Apache/Hadoop/#mahout","text":"","title":"Mahout"},{"location":"Apache/Hadoop/#spark_2","text":"","title":"Spark"},{"location":"Apache/MapReduce/","text":"MapReduce A layer of software to help you bring computation to the data and organize the output Framework user defines pair mapper & reducer functions Hadoop handles the logistics: shuffle, group, distribute Flow User defines a map function map() map() reads data and outputs <key,value> User defines a reduce function reduce() reduce() reads <key,value> and outputs result Principle In general 1 mapper per data split (typically) 1 reducer per computer core (best parallelism) Composite \\<keys> Extra info in \\<values> Cascade Map/Reduce jobs bin keys into ranges to reduce computational cost N keys into R groups if size (N/R) increases shuffle cost increases reducer complexity decreases Aggregate map output when possible (combiner option) Joining Data Combine datasets by key A standard data management function Joins can be inner, left or right outer Summary Task Decomposition mappers are separate and independent mappers work on data parts Common mappers Filter (subset data) Identity (just pass data) Splitter (as for counting) Limitations Must fit paradigm Map/Reduce data not persistent Requires programming/debugging Not interactive Force pipeline into Map and Reduce steps (cannot accommodate map-reduce-map .etc) Read from disk for each MapReduce job (bad for iterative algorithms, i.e. machine learning)","title":"MapReduce"},{"location":"Apache/MapReduce/#mapreduce","text":"A layer of software to help you bring computation to the data and organize the output","title":"MapReduce"},{"location":"Apache/MapReduce/#framework","text":"user defines pair mapper & reducer functions Hadoop handles the logistics: shuffle, group, distribute","title":"Framework"},{"location":"Apache/MapReduce/#flow","text":"User defines a map function map() map() reads data and outputs <key,value> User defines a reduce function reduce() reduce() reads <key,value> and outputs result","title":"Flow"},{"location":"Apache/MapReduce/#principle","text":"In general 1 mapper per data split (typically) 1 reducer per computer core (best parallelism) Composite \\<keys> Extra info in \\<values> Cascade Map/Reduce jobs bin keys into ranges to reduce computational cost N keys into R groups if size (N/R) increases shuffle cost increases reducer complexity decreases Aggregate map output when possible (combiner option)","title":"Principle"},{"location":"Apache/MapReduce/#joining-data","text":"Combine datasets by key A standard data management function Joins can be inner, left or right outer","title":"Joining Data"},{"location":"Apache/MapReduce/#summary","text":"Task Decomposition mappers are separate and independent mappers work on data parts Common mappers Filter (subset data) Identity (just pass data) Splitter (as for counting)","title":"Summary"},{"location":"Apache/MapReduce/#limitations","text":"Must fit paradigm Map/Reduce data not persistent Requires programming/debugging Not interactive Force pipeline into Map and Reduce steps (cannot accommodate map-reduce-map .etc) Read from disk for each MapReduce job (bad for iterative algorithms, i.e. machine learning)","title":"Limitations"},{"location":"Apache/Spark/","text":"Spark born at UC Berkeley, managed by Apache Advantages over MapReduce ~20 highly efficient distributed operations, any combination of them good for iterative algorithms, i.e. machine learning, by in-memory caching of data Native Python, Scala, R interfaces; interactive shells Architecture Master Node Driver Program Spark Context (object, gateway to connect spark instance and submit jobs) Cluster Manager 2 interfaces YARN Standalone Provision/Restart Workers Worker Node Spark Executor JVM (Java Virtual Machine) <--> HDFS RDD Resilient Distributed Dataset: data containers (immutable) Dataset are created from HDFS, S3, HBase, JSON, text, Local hierarchy of folders transforming another RDD Distributed distributed across the cluster of machines divided in partitions, atomic chunks of data Resilient Recover from errors, e.g. node failure, slow processes Track history of each partition, re-run Create RDD integer_RDD = sc.parallelize(range(10), 3) text_RDD = sc.textFile(\"file:///home/cloudera/testfile1\") text_RDD = sc.textFile(\"/user/cloudera/input/testfile1\") check partitions # Gather all data on the driver integer_RDD.collect() # Maintain splitting in partitions integer_RDD.glom().collect() check data # outputs the first line text_RDD.take(1) wordcount # map def split_words(line): return line.split() def create_pair(word): return (word, 1) pairs_RDD = text_RDD.flatMap(split_words).map(create_pair) # reduce def sum_counts(a, b): return a + b wordcounts_RDD = pairs_RDD.reduceByKey(sum_counts) Transformations RDD are immutable never modify RDD inplace transform RDD to another RDD transformations are lazy (nothing happens straight away) narrow vs wide narrow map() filter() wide groupByKey() reduceByKey(func) repartition(numPartitions) Apply transformation map applys function to each element of RDD, works on partition instead of on element def lower(line): return line.lower() lower_text_RDD = text_RDD.map(lower) flatMap(func) - map then flatten output def split_words(line): return line.split() words_RDD = text_RDD.flatMap(split_words) filter(func) - keep only elements where func is true def starts_with_a(word): return word.lower().startswith(\"a\") words_RDD.filter(starts_with_a).collect() sample(withReplacement, fraction, seed) - get a random data fraction coalesce(numPartitions) - merge partitions to reduce them to numPartitions sc.parallelize(range(10), 4).glom().collect() sc.parallelize(range(10), 4).coalesce(2).glom().collect() groupByKey() - wide transformations of (K, V) pairs to (K, iterable of all V) -- shuffle pairs_RDD.groupByKey().collect() for k,v in pairs_RDD.groupByKey().collect(): print \"Key:\", k, \",Values:\", list(v) reduceByKey(func) - wide transformation of (K, V) pairs to (K, result of reduction by func on all V) repartition(numPartitions) : similar to coalesce, shuffles all data to increase or decrease number of partitions to numPartitions Shuffle Global redistribution of data High impact on performance Process write to local disk requests data over the network DAG Directed Acyclic Graph are used to track dependencies (also known as lineage or provenance). DAG in Spark nodes are RDDs arrows are Transformations to recover lost partitions Actions Final stage of workflow Triggers execution of the DAG collect() and take return results to the Driver or writes to HDFS Examples collect() - copy all elements to the driver take(n) - copy first n elements reduce(func) - aggregate elements with func (takes 2 elements, returns 1) saveAsTextFile(filename) - save to local file or HDFS Memory Caching By default each job re-processes from HDFS Mark RDD with .cache() Lazy When to cache? Generally not the input data Do validation and cleaning Cache for iterative algorithm How to cache? Memory (most common) Disk (rare) Both (for heavy calculations) Speedup Easily 10x or even 100x depending on application Caching is gradual Fault tolerant Broadcast Broadcast variables Large variable used in all nodes Transfer just once per Executor Efficient peer-to-peer transfer as soon as one node gets a chunk of the data, it will copy this variable by sharing its chunk of data with the other executor config = sc.broadcast({\"order\":3, \"filter\":True}) config.value Accumulator Common pattern of accumulating to a variable across the cluster Write-only on nodes accum = sc.accumulator(0) def test_accum(x): accum.add(x) sc.parallelize([1, 2, 3, 4]).foreach(test_accum) accum.value","title":"Spark"},{"location":"Apache/Spark/#spark","text":"born at UC Berkeley, managed by Apache","title":"Spark"},{"location":"Apache/Spark/#advantages","text":"over MapReduce ~20 highly efficient distributed operations, any combination of them good for iterative algorithms, i.e. machine learning, by in-memory caching of data Native Python, Scala, R interfaces; interactive shells","title":"Advantages"},{"location":"Apache/Spark/#architecture","text":"Master Node Driver Program Spark Context (object, gateway to connect spark instance and submit jobs) Cluster Manager 2 interfaces YARN Standalone Provision/Restart Workers Worker Node Spark Executor JVM (Java Virtual Machine) <--> HDFS","title":"Architecture"},{"location":"Apache/Spark/#rdd","text":"Resilient Distributed Dataset: data containers (immutable) Dataset are created from HDFS, S3, HBase, JSON, text, Local hierarchy of folders transforming another RDD Distributed distributed across the cluster of machines divided in partitions, atomic chunks of data Resilient Recover from errors, e.g. node failure, slow processes Track history of each partition, re-run Create RDD integer_RDD = sc.parallelize(range(10), 3) text_RDD = sc.textFile(\"file:///home/cloudera/testfile1\") text_RDD = sc.textFile(\"/user/cloudera/input/testfile1\") check partitions # Gather all data on the driver integer_RDD.collect() # Maintain splitting in partitions integer_RDD.glom().collect() check data # outputs the first line text_RDD.take(1) wordcount # map def split_words(line): return line.split() def create_pair(word): return (word, 1) pairs_RDD = text_RDD.flatMap(split_words).map(create_pair) # reduce def sum_counts(a, b): return a + b wordcounts_RDD = pairs_RDD.reduceByKey(sum_counts)","title":"RDD"},{"location":"Apache/Spark/#transformations","text":"RDD are immutable never modify RDD inplace transform RDD to another RDD transformations are lazy (nothing happens straight away) narrow vs wide narrow map() filter() wide groupByKey() reduceByKey(func) repartition(numPartitions) Apply transformation map applys function to each element of RDD, works on partition instead of on element def lower(line): return line.lower() lower_text_RDD = text_RDD.map(lower) flatMap(func) - map then flatten output def split_words(line): return line.split() words_RDD = text_RDD.flatMap(split_words) filter(func) - keep only elements where func is true def starts_with_a(word): return word.lower().startswith(\"a\") words_RDD.filter(starts_with_a).collect() sample(withReplacement, fraction, seed) - get a random data fraction coalesce(numPartitions) - merge partitions to reduce them to numPartitions sc.parallelize(range(10), 4).glom().collect() sc.parallelize(range(10), 4).coalesce(2).glom().collect() groupByKey() - wide transformations of (K, V) pairs to (K, iterable of all V) -- shuffle pairs_RDD.groupByKey().collect() for k,v in pairs_RDD.groupByKey().collect(): print \"Key:\", k, \",Values:\", list(v) reduceByKey(func) - wide transformation of (K, V) pairs to (K, result of reduction by func on all V) repartition(numPartitions) : similar to coalesce, shuffles all data to increase or decrease number of partitions to numPartitions Shuffle Global redistribution of data High impact on performance Process write to local disk requests data over the network","title":"Transformations"},{"location":"Apache/Spark/#dag","text":"Directed Acyclic Graph are used to track dependencies (also known as lineage or provenance). DAG in Spark nodes are RDDs arrows are Transformations to recover lost partitions","title":"DAG"},{"location":"Apache/Spark/#actions","text":"Final stage of workflow Triggers execution of the DAG collect() and take return results to the Driver or writes to HDFS Examples collect() - copy all elements to the driver take(n) - copy first n elements reduce(func) - aggregate elements with func (takes 2 elements, returns 1) saveAsTextFile(filename) - save to local file or HDFS","title":"Actions"},{"location":"Apache/Spark/#memory-caching","text":"By default each job re-processes from HDFS Mark RDD with .cache() Lazy When to cache? Generally not the input data Do validation and cleaning Cache for iterative algorithm How to cache? Memory (most common) Disk (rare) Both (for heavy calculations) Speedup Easily 10x or even 100x depending on application Caching is gradual Fault tolerant","title":"Memory Caching"},{"location":"Apache/Spark/#broadcast","text":"Broadcast variables Large variable used in all nodes Transfer just once per Executor Efficient peer-to-peer transfer as soon as one node gets a chunk of the data, it will copy this variable by sharing its chunk of data with the other executor config = sc.broadcast({\"order\":3, \"filter\":True}) config.value Accumulator Common pattern of accumulating to a variable across the cluster Write-only on nodes accum = sc.accumulator(0) def test_accum(x): accum.add(x) sc.parallelize([1, 2, 3, 4]).foreach(test_accum) accum.value","title":"Broadcast"},{"location":"CS61A/1-intro/","text":"Intro Libraries An import statement that loads functionality for accessing data on the Internet. In particular, it makes available a function called urlopen , which can access the content at a uniform resource locator (URL), a location of something on the Internet. from urllib.request import urlopen Functions encapsulate logic that manipulates data. shakespeare = urlopen('http://composingprograms.com/shakespeare.txt') >>> shakespeare <http.client.HTTPResponse object at 0x0000013C74319908> Objects A set is a type of object, one that supports set operations like computing intersections and membership. An object seamlessly bundles together data and the logic that manipulates that data, in a way that manages the complexity of both. all unique words that appear in Shakespeare's plays words = set(shakespeare.read().decode().split()) Interpreters Evaluating compound expressions requires a precise procedure that interprets code in a predictable way. A program that implements such a procedure, evaluating compound expressions, is called an interpreter. >>> {w for w in words if len(w) == 6 and w[::-1] in words} {'redder', 'drawer', 'reward', 'diaper', 'repaid'} Functions are objects, objects are functions, and interpreters are instances of both. Errors Guiding principles of Debugging Test incrementally Isolate errors Check your assumptions Consult others Elements of Programming Every powerful language has three such mechanisms: primitive expressions and statements , which represent the simplest building blocks that the language provides, means of combination , by which compound elements are built from simpler ones, and means of abstraction , by which compound elements can be named and manipulated as units. Expression An expression describes a computation and evaluates to a value Primitive expressions: 2 (number or numeral), add (name), 'hello' (string) All expressions can use function call notation. add(2, 3) Operator(Operand, Operand) Operators and operands are also expressions. Evaluation procedure for call expressions: Evaluate the operator and then the operand subexpressions Apply the function that is the value of the operator to the arguments that are the values of the operands Names & Environment Most important lessons An environment is a sequence of frames. A name evaluates to the value bound to that name in the earliest frame of the current environment in which that name is found. The = symbol is called the assignment operator. Assignment is our simplest means of abstraction . Assign multiple values to multiple names in a single statement area, circumference = pi * radius * radius, 2 * pi * radius Environment diagrams visualize the interpreter\u2019s process. The possibility of binding names to values and later retrieving those values by name means that the interpreter must maintain some sort of memory that keeps track of the names, values, and bindings. This memory is called an environment . Operators truediv >>> 5 / 4 1.25 >>> 8 / 4 2.0 floordiv >>> 5 // 4 1 >>> -5 // 4 -2 Examples from math import sqrt sqrt(169) Objects Note: Download from http://composingprograms.com/shakespeare.txt shakes = open('shakespeare.txt') text = shakes.read().split() len(text) text[:25] text.count('thou') text.count(',') Sets words = set(text) len(words) max(words) max(words, key=len) Reversals 'DRAW'[::-1] {w for w in words if w == w[::-1] and len(w)>4} {w for w in words if w[::-1] in words and len(w) == 4} {w for w in words if w[::-1] in words and len(w) > 6} logical expressions >>> True and 13 13 >>> False or 0 0 >>> not 10 False >>> not None True >>> True and 1 / 0 and False Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ZeroDivisionError: division by zero >>> True or 1/0 or False True >>> True and 0 0 >>> False or 1 1 >>> 1 and 3 and 6 and 10 and 15 15 >>> -1 and 1>0 True >>> 0 or False or 2 or 1/0 2 >>> (1+1) and 1 1 >>> 1/0 or True Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ZeroDivisionError: division by zero","title":"CS61A-intro"},{"location":"CS61A/1-intro/#intro","text":"","title":"Intro"},{"location":"CS61A/1-intro/#libraries","text":"An import statement that loads functionality for accessing data on the Internet. In particular, it makes available a function called urlopen , which can access the content at a uniform resource locator (URL), a location of something on the Internet. from urllib.request import urlopen Functions encapsulate logic that manipulates data. shakespeare = urlopen('http://composingprograms.com/shakespeare.txt') >>> shakespeare <http.client.HTTPResponse object at 0x0000013C74319908>","title":"Libraries"},{"location":"CS61A/1-intro/#objects","text":"A set is a type of object, one that supports set operations like computing intersections and membership. An object seamlessly bundles together data and the logic that manipulates that data, in a way that manages the complexity of both. all unique words that appear in Shakespeare's plays words = set(shakespeare.read().decode().split())","title":"Objects"},{"location":"CS61A/1-intro/#interpreters","text":"Evaluating compound expressions requires a precise procedure that interprets code in a predictable way. A program that implements such a procedure, evaluating compound expressions, is called an interpreter. >>> {w for w in words if len(w) == 6 and w[::-1] in words} {'redder', 'drawer', 'reward', 'diaper', 'repaid'} Functions are objects, objects are functions, and interpreters are instances of both.","title":"Interpreters"},{"location":"CS61A/1-intro/#errors","text":"Guiding principles of Debugging Test incrementally Isolate errors Check your assumptions Consult others","title":"Errors"},{"location":"CS61A/1-intro/#elements-of-programming","text":"Every powerful language has three such mechanisms: primitive expressions and statements , which represent the simplest building blocks that the language provides, means of combination , by which compound elements are built from simpler ones, and means of abstraction , by which compound elements can be named and manipulated as units.","title":"Elements of Programming"},{"location":"CS61A/1-intro/#expression","text":"An expression describes a computation and evaluates to a value Primitive expressions: 2 (number or numeral), add (name), 'hello' (string) All expressions can use function call notation. add(2, 3) Operator(Operand, Operand) Operators and operands are also expressions. Evaluation procedure for call expressions: Evaluate the operator and then the operand subexpressions Apply the function that is the value of the operator to the arguments that are the values of the operands","title":"Expression"},{"location":"CS61A/1-intro/#names-environment","text":"Most important lessons An environment is a sequence of frames. A name evaluates to the value bound to that name in the earliest frame of the current environment in which that name is found. The = symbol is called the assignment operator. Assignment is our simplest means of abstraction . Assign multiple values to multiple names in a single statement area, circumference = pi * radius * radius, 2 * pi * radius Environment diagrams visualize the interpreter\u2019s process. The possibility of binding names to values and later retrieving those values by name means that the interpreter must maintain some sort of memory that keeps track of the names, values, and bindings. This memory is called an environment .","title":"Names &amp; Environment"},{"location":"CS61A/1-intro/#operators","text":"truediv >>> 5 / 4 1.25 >>> 8 / 4 2.0 floordiv >>> 5 // 4 1 >>> -5 // 4 -2","title":"Operators"},{"location":"CS61A/1-intro/#examples","text":"from math import sqrt sqrt(169)","title":"Examples"},{"location":"CS61A/1-intro/#objects_1","text":"Note: Download from http://composingprograms.com/shakespeare.txt shakes = open('shakespeare.txt') text = shakes.read().split() len(text) text[:25] text.count('thou') text.count(',')","title":"Objects"},{"location":"CS61A/1-intro/#sets","text":"words = set(text) len(words) max(words) max(words, key=len)","title":"Sets"},{"location":"CS61A/1-intro/#reversals","text":"'DRAW'[::-1] {w for w in words if w == w[::-1] and len(w)>4} {w for w in words if w[::-1] in words and len(w) == 4} {w for w in words if w[::-1] in words and len(w) > 6}","title":"Reversals"},{"location":"CS61A/1-intro/#logical-expressions","text":">>> True and 13 13 >>> False or 0 0 >>> not 10 False >>> not None True >>> True and 1 / 0 and False Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ZeroDivisionError: division by zero >>> True or 1/0 or False True >>> True and 0 0 >>> False or 1 1 >>> 1 and 3 and 6 and 10 and 15 15 >>> -1 and 1>0 True >>> 0 or False or 2 or 1/0 2 >>> (1+1) and 1 1 >>> 1/0 or True Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ZeroDivisionError: division by zero","title":"logical expressions"},{"location":"CS61A/2-function/","text":"Functions The special value None represents nothing in Python. Pure Functions just return values simpler to test essential for writing concurrent programs, in which multiple call expressions may be evaluated simultaneously Functions have some input (their arguments) and return some output (the result of applying them) Non-pure Functions have side effects (consequence of calling a function) In addition to returning a value, applying a non-pure function can generate side effects , which make some change to the state of the interpreter or computer. A common side effect is to generate additional output beyond the return value. >> print(print(1), print(2)) 1 2 None None >>> two = print(2) 2 >>> print(two) None define a function def <name>(<formal parameters>): return <return expression> A description of the formal parameters of a function is called the function's signature. The body of a function is not executed until the function is called (not when it is defined). Good functions are Each function should have exactly one job. Don't repeat yourself is a central tenet of software engineering. Functions should be defined generally. Conventions Function names are lowercase, with words separated by underscores. Descriptive names are encouraged. Function names typically evoke operations applied to arguments by the interpreter (e.g., print , add , square ) or the name of the quantity that results (e.g., max , abs , sum ). Parameter names are lowercase, with words separated by underscores. Single-word names are preferred. Parameter names should evoke the role of the parameter in the function, not just the kind of argument that is allowed. Single letter parameter names are acceptable when their role is obvious, but avoid \"l\" (lowercase ell), \"O\" (capital oh), or \"I\" (capital i) to avoid confusion with numerals. Aspects of a function abstraction (3 core attributes) The domain of a function is the set of arguments it can take. The range of a function is the set of values it can return. The intent / behavior of a function is the relationship it computes between inputs and output (as well as any side effects it might generate). Function Documentation docstring def pressure(v, t, n): \"\"\"Compute the pressure in pascals of an ideal gas. Applies the ideal gas law: http://en.wikipedia.org/wiki/Ideal_gas_law v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v When you call help with the name of a function as an argument, you see its docstring (type q to quit Python help). help(pressure) Comments in Python can be attached to the end of a line following the # symbol. python3 -m doctest test.py python3 -m doctest -v test.py Default Argument Values def pressure(v, t, n=6.022e23): \"\"\"Compute the pressure in pascals of an ideal gas. v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas (default: one mole) \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v In the def statement header, = does not perform assignment, but instead indicates a default value to use when the function is called. By contrast, the assignment statement to k in the body of the function binds the name k to an approximation of Boltzmann's constant. Statements Expressions can also be executed as statements, in which case they are evaluated, but their value is discarded. Executing a pure function has no effect, but executing a non-pure function can cause effects as a consequence of function application. A statement is executed by the interpreter to perform an action. Compound Statements The first header determines a statement\u2019s type def statements are compound statements A suite is a sequence of statements To \u201cexecute\u201d a suite means to execute its sequence of statements, in order Conditional Statements Boolean Contexts iterations for while Testing python test.py -v and then??? python -i test.py Assertions def fib(n): \"\"\"Compute the nth Fibonacci number, for n >= 2.\"\"\" pred, curr = 0, 1 # Fibonacci numbers 1 and 2 k = 2 # Which Fib number is curr? while k < n: pred, curr = curr, pred + curr k = k + 1 return curr An assert statement has an expression in a boolean context, followed by a quoted line of text (single or double quotes are both fine, but be consistent) that will be displayed if the expression evaluates to a false value. assert fib(8) == 13, 'The 8th Fibonacci number should be 13' When the expression being asserted evaluates to a true value, executing an assert statement has no effect. When it is a false value, assert causes an error that halts execution. def fib_test(): assert fib(2) == 1, 'The 2nd Fibonacci number should be 1' assert fib(3) == 1, 'The 3rd Fibonacci number should be 1' assert fib(50) == 7778742049, 'Error at the 50th Fibonacci number' A test function for fib should test several arguments, including extreme values of n . Doctests The first line of a docstring should contain a one-line description of the function, followed by a blank line. A detailed description of arguments and behavior may follow. In addition, the docstring may include a sample interactive session that calls the function. def sum_naturals(n): \"\"\"Return the sum of the first n natural numbers. >>> sum_naturals(10) 55 >>> sum_naturals(100) 5050 \"\"\" total, k = 0, 1 while k <= n: total, k = total + k, k + 1 return total example >>> from doctest import run_docstring_examples >>> run_docstring_examples(sum_naturals, globals(), True) Finding tests in NoName Trying: sum_naturals(10) Expecting: 55 ok Trying: sum_naturals(100) Expecting: 5050 ok Its first argument is the function to test. The second should always be the result of the expression globals() , a built-in function that returns the global environment. The third argument is True to indicate that we would like \"verbose\" output: a catalog of all tests run. When the return value of a function does not match the expected result, the run_docstring_examples function will report this problem as a test failure. python3 -m doctest <python_source_file> Higher-Order Functions Functions that manipulate functions are called higher-order functions. Benefits - express general methods of computation - remove repetition - separate concerns among functions functions as arguments def summation(n, term): total, k = 0, 1 while k <= n: total, k = total + term(k), k + 1 return total def cube(x): return x*x*x def sum_cubes(n): return summation(n, cube) result = sum_cubes(3) 1e6, a shorthand for 1 * 10^6 = 1000000 functions as general methods def improve(update, close, guess=1): while not close(guess): guess = update(guess) return guess def golden_update(guess): return 1/guess + 1 def square_close_to_successor(guess): return approx_eq(guess * guess, guess + 1) def approx_eq(x, y, tolerance=1e-15): return abs(x - y) < tolerance nested definitions This two-argument update function is incompatible with improve (it takes two arguments, not one), and it provides only a single update, while we really care about taking square roots by repeated updates. The solution to both of these issues is to place function definitions inside the body of other definitions. def sqrt(a): def sqrt_update(x): return average(x, a/x) def sqrt_close(x): return approx_eq(x * x, a) return improve(sqrt_update, sqrt_close) Lexical Scope This discipline of sharing names among nested definitions is called lexical scoping . Critically, the inner functions have access to the names in the environment where they are defined (not where they are called). functions as returned values Functions defined within other function bodies are bound to names in a local frame. def make_adder(n): \"\"\"Return a function that takes one argument k and returns k + n. >>> add_three = make_adder(3) >>> add_three(4) 7 \"\"\" def adder(k): return k + n return adder # equivalently >>> f = make_add(2000) >>> f(13) >>> 2013 Currying Curry : Transform a multi-argument function into a single-argument, higher-order function. We can use higher-order functions to convert a function that takes multiple arguments into a chain of functions that each take a single argument. More specifically, given a function f(x, y) , we can define a function g such that g(x)(y) is equivalent to f(x, y) . >>> def curried_pow(x): def h(y): return pow(x, y) return h >>> curried_pow(2)(3) 8 >>> def map_to_range(start, end, f): while start < end: print(f(start)) start = start + 1 >>> map_to_range(0, 10, curried_pow(2)) 1 2 4 8 16 32 64 128 256 512 curry vs uncurry >>> def curry2(f): \"\"\"Return a curried version of the given two-argument function.\"\"\" def g(x): def h(y): return f(x, y) return h return g >>> def uncurry2(g): \"\"\"Return a two-argument version of the given curried function.\"\"\" def f(x, y): return g(x)(y) return f results >>> pow_curried = curry2(pow) >>> pow_curried(2)(5) 32 >>> uncurry2(pow_curried)(2, 5) 32 Self-Reference Returning a function using its own name def print_all(x): print(x) return print_all print(1)(3)(5) # 1 3 5 def print_sums(x): print(x) def next_sum(y): return print_sums(x+y) return next_sum print_sums(1)(3)(5) # 1 4 9 Lambda Function Create functions values on the fly, no intrinsic name >>> square = lambda x: x * x >>> square(10) 100 >>> (lambda x: x * x)(3) 9 >>> (lambda f, x: f(x))(lambda y: y + 1, 10) 11 Abstractions and naming practical naming conventions - n, k, i -- usually integers - x, y, z -- usually real numbers - f, g, h -- usually functions Function Decorators Python provides special syntax to apply higher-order functions as part of executing a def statement, called a decorator. Perhaps the most common example is a trace . The decorator symbol @ may also be followed by a call expression. The expression following @ is evaluated first (just as the name trace was evaluated above), the def statement second, and finally the result of evaluating the decorator expression is applied to the newly defined function, and the result is bound to the name in the def statement. def trace(fn): def wrapped(x): print('-> ', fn, '(', x, ')') return fn(x) return wrapped Application >>> @trace def triple(x): return 3 * x >>> triple(12) -> <function triple at 0x102a39848> ( 12 ) 36 # equivalently >>> def triple(x): return 3 * x >>> triple = trace(triple) Recursive Functions A function is called recursive if the body of the function calls the function itself, either directly or indirectly. Recursive functions start with conditional statements check for base cases ; base cases are evaluated without recursive calls . Recursive cases are evaluated with recursive calls ; they simplify the original problem. def fact(n): if n == 0: return 1 else: return n * fact(n-1) def fact_iter(n): total, k = 1, 1 while k <= n: total, k = total * k, k + 1 return total While we can unwind the recursion using our model of computation, it is often clearer to think about recursive calls as functional abstractions. That is, we should not care about how fact(n-1) is implemented in the body of fact ; we should simply trust that it computes the factorial of n-1 . Treating a recursive call as a functional abstraction has been called a recursive leap of faith . Mutual Recursion When a recursive procedure is divided among two functions that call each other, the functions are said to be mutually recursive . As an example, consider the following definition of even and odd for non-negative integers. def is_even(n): if n == 0: return True else: return is_odd(n-1) def is_odd(n): if n == 0: return False else: return is_even(n-1) result = is_even(4) Mutually recursive functions can be turned into a single recursive function by breaking the abstraction boundary between the two functions. def is_even(n): if n == 0: return True else: if (n-1) == 0: return False else: return is_even((n-1)-1) Tree Recursion A function with multiple recursive calls is said to be tree recursive because each call branches into multiple smaller calls, each of which branches into yet smaller calls, just as the branches of a tree become smaller but more numerous as they extend from the trunk. Fibonacci def fib(n): if n == 1: return 0 elif n == 2: return 1 else: return fib(n-2) + fib(n-1) Counting Partitions def count_partitions(n, m): \"\"\" number of positive integer n using parts up to size m possibility 1: use at least one 4 possibility 2: don't use any 4 \"\"\" if n == 0: return 1 elif n < 0: return 0 elif m == 0: return 0 else: with_m = count_partitions(n-m, m) without_m = count_partitions(n, m-1) return with_m + without_m","title":"CS61A-function"},{"location":"CS61A/2-function/#functions","text":"The special value None represents nothing in Python. Pure Functions just return values simpler to test essential for writing concurrent programs, in which multiple call expressions may be evaluated simultaneously Functions have some input (their arguments) and return some output (the result of applying them) Non-pure Functions have side effects (consequence of calling a function) In addition to returning a value, applying a non-pure function can generate side effects , which make some change to the state of the interpreter or computer. A common side effect is to generate additional output beyond the return value. >> print(print(1), print(2)) 1 2 None None >>> two = print(2) 2 >>> print(two) None define a function def <name>(<formal parameters>): return <return expression> A description of the formal parameters of a function is called the function's signature. The body of a function is not executed until the function is called (not when it is defined). Good functions are Each function should have exactly one job. Don't repeat yourself is a central tenet of software engineering. Functions should be defined generally. Conventions Function names are lowercase, with words separated by underscores. Descriptive names are encouraged. Function names typically evoke operations applied to arguments by the interpreter (e.g., print , add , square ) or the name of the quantity that results (e.g., max , abs , sum ). Parameter names are lowercase, with words separated by underscores. Single-word names are preferred. Parameter names should evoke the role of the parameter in the function, not just the kind of argument that is allowed. Single letter parameter names are acceptable when their role is obvious, but avoid \"l\" (lowercase ell), \"O\" (capital oh), or \"I\" (capital i) to avoid confusion with numerals. Aspects of a function abstraction (3 core attributes) The domain of a function is the set of arguments it can take. The range of a function is the set of values it can return. The intent / behavior of a function is the relationship it computes between inputs and output (as well as any side effects it might generate).","title":"Functions"},{"location":"CS61A/2-function/#function-documentation","text":"docstring def pressure(v, t, n): \"\"\"Compute the pressure in pascals of an ideal gas. Applies the ideal gas law: http://en.wikipedia.org/wiki/Ideal_gas_law v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v When you call help with the name of a function as an argument, you see its docstring (type q to quit Python help). help(pressure) Comments in Python can be attached to the end of a line following the # symbol. python3 -m doctest test.py python3 -m doctest -v test.py","title":"Function Documentation"},{"location":"CS61A/2-function/#default-argument-values","text":"def pressure(v, t, n=6.022e23): \"\"\"Compute the pressure in pascals of an ideal gas. v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas (default: one mole) \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v In the def statement header, = does not perform assignment, but instead indicates a default value to use when the function is called. By contrast, the assignment statement to k in the body of the function binds the name k to an approximation of Boltzmann's constant.","title":"Default Argument Values"},{"location":"CS61A/2-function/#statements","text":"Expressions can also be executed as statements, in which case they are evaluated, but their value is discarded. Executing a pure function has no effect, but executing a non-pure function can cause effects as a consequence of function application. A statement is executed by the interpreter to perform an action. Compound Statements The first header determines a statement\u2019s type def statements are compound statements A suite is a sequence of statements To \u201cexecute\u201d a suite means to execute its sequence of statements, in order Conditional Statements Boolean Contexts iterations for while","title":"Statements"},{"location":"CS61A/2-function/#testing","text":"python test.py -v and then??? python -i test.py Assertions def fib(n): \"\"\"Compute the nth Fibonacci number, for n >= 2.\"\"\" pred, curr = 0, 1 # Fibonacci numbers 1 and 2 k = 2 # Which Fib number is curr? while k < n: pred, curr = curr, pred + curr k = k + 1 return curr An assert statement has an expression in a boolean context, followed by a quoted line of text (single or double quotes are both fine, but be consistent) that will be displayed if the expression evaluates to a false value. assert fib(8) == 13, 'The 8th Fibonacci number should be 13' When the expression being asserted evaluates to a true value, executing an assert statement has no effect. When it is a false value, assert causes an error that halts execution. def fib_test(): assert fib(2) == 1, 'The 2nd Fibonacci number should be 1' assert fib(3) == 1, 'The 3rd Fibonacci number should be 1' assert fib(50) == 7778742049, 'Error at the 50th Fibonacci number' A test function for fib should test several arguments, including extreme values of n . Doctests The first line of a docstring should contain a one-line description of the function, followed by a blank line. A detailed description of arguments and behavior may follow. In addition, the docstring may include a sample interactive session that calls the function. def sum_naturals(n): \"\"\"Return the sum of the first n natural numbers. >>> sum_naturals(10) 55 >>> sum_naturals(100) 5050 \"\"\" total, k = 0, 1 while k <= n: total, k = total + k, k + 1 return total example >>> from doctest import run_docstring_examples >>> run_docstring_examples(sum_naturals, globals(), True) Finding tests in NoName Trying: sum_naturals(10) Expecting: 55 ok Trying: sum_naturals(100) Expecting: 5050 ok Its first argument is the function to test. The second should always be the result of the expression globals() , a built-in function that returns the global environment. The third argument is True to indicate that we would like \"verbose\" output: a catalog of all tests run. When the return value of a function does not match the expected result, the run_docstring_examples function will report this problem as a test failure. python3 -m doctest <python_source_file>","title":"Testing"},{"location":"CS61A/2-function/#higher-order-functions","text":"Functions that manipulate functions are called higher-order functions. Benefits - express general methods of computation - remove repetition - separate concerns among functions functions as arguments def summation(n, term): total, k = 0, 1 while k <= n: total, k = total + term(k), k + 1 return total def cube(x): return x*x*x def sum_cubes(n): return summation(n, cube) result = sum_cubes(3) 1e6, a shorthand for 1 * 10^6 = 1000000 functions as general methods def improve(update, close, guess=1): while not close(guess): guess = update(guess) return guess def golden_update(guess): return 1/guess + 1 def square_close_to_successor(guess): return approx_eq(guess * guess, guess + 1) def approx_eq(x, y, tolerance=1e-15): return abs(x - y) < tolerance nested definitions This two-argument update function is incompatible with improve (it takes two arguments, not one), and it provides only a single update, while we really care about taking square roots by repeated updates. The solution to both of these issues is to place function definitions inside the body of other definitions. def sqrt(a): def sqrt_update(x): return average(x, a/x) def sqrt_close(x): return approx_eq(x * x, a) return improve(sqrt_update, sqrt_close) Lexical Scope This discipline of sharing names among nested definitions is called lexical scoping . Critically, the inner functions have access to the names in the environment where they are defined (not where they are called). functions as returned values Functions defined within other function bodies are bound to names in a local frame. def make_adder(n): \"\"\"Return a function that takes one argument k and returns k + n. >>> add_three = make_adder(3) >>> add_three(4) 7 \"\"\" def adder(k): return k + n return adder # equivalently >>> f = make_add(2000) >>> f(13) >>> 2013","title":"Higher-Order Functions"},{"location":"CS61A/2-function/#currying","text":"Curry : Transform a multi-argument function into a single-argument, higher-order function. We can use higher-order functions to convert a function that takes multiple arguments into a chain of functions that each take a single argument. More specifically, given a function f(x, y) , we can define a function g such that g(x)(y) is equivalent to f(x, y) . >>> def curried_pow(x): def h(y): return pow(x, y) return h >>> curried_pow(2)(3) 8 >>> def map_to_range(start, end, f): while start < end: print(f(start)) start = start + 1 >>> map_to_range(0, 10, curried_pow(2)) 1 2 4 8 16 32 64 128 256 512 curry vs uncurry >>> def curry2(f): \"\"\"Return a curried version of the given two-argument function.\"\"\" def g(x): def h(y): return f(x, y) return h return g >>> def uncurry2(g): \"\"\"Return a two-argument version of the given curried function.\"\"\" def f(x, y): return g(x)(y) return f results >>> pow_curried = curry2(pow) >>> pow_curried(2)(5) 32 >>> uncurry2(pow_curried)(2, 5) 32","title":"Currying"},{"location":"CS61A/2-function/#self-reference","text":"Returning a function using its own name def print_all(x): print(x) return print_all print(1)(3)(5) # 1 3 5 def print_sums(x): print(x) def next_sum(y): return print_sums(x+y) return next_sum print_sums(1)(3)(5) # 1 4 9","title":"Self-Reference"},{"location":"CS61A/2-function/#lambda-function","text":"Create functions values on the fly, no intrinsic name >>> square = lambda x: x * x >>> square(10) 100 >>> (lambda x: x * x)(3) 9 >>> (lambda f, x: f(x))(lambda y: y + 1, 10) 11","title":"Lambda Function"},{"location":"CS61A/2-function/#abstractions-and-naming","text":"practical naming conventions - n, k, i -- usually integers - x, y, z -- usually real numbers - f, g, h -- usually functions","title":"Abstractions and naming"},{"location":"CS61A/2-function/#function-decorators","text":"Python provides special syntax to apply higher-order functions as part of executing a def statement, called a decorator. Perhaps the most common example is a trace . The decorator symbol @ may also be followed by a call expression. The expression following @ is evaluated first (just as the name trace was evaluated above), the def statement second, and finally the result of evaluating the decorator expression is applied to the newly defined function, and the result is bound to the name in the def statement. def trace(fn): def wrapped(x): print('-> ', fn, '(', x, ')') return fn(x) return wrapped Application >>> @trace def triple(x): return 3 * x >>> triple(12) -> <function triple at 0x102a39848> ( 12 ) 36 # equivalently >>> def triple(x): return 3 * x >>> triple = trace(triple)","title":"Function Decorators"},{"location":"CS61A/2-function/#recursive-functions","text":"A function is called recursive if the body of the function calls the function itself, either directly or indirectly. Recursive functions start with conditional statements check for base cases ; base cases are evaluated without recursive calls . Recursive cases are evaluated with recursive calls ; they simplify the original problem. def fact(n): if n == 0: return 1 else: return n * fact(n-1) def fact_iter(n): total, k = 1, 1 while k <= n: total, k = total * k, k + 1 return total While we can unwind the recursion using our model of computation, it is often clearer to think about recursive calls as functional abstractions. That is, we should not care about how fact(n-1) is implemented in the body of fact ; we should simply trust that it computes the factorial of n-1 . Treating a recursive call as a functional abstraction has been called a recursive leap of faith .","title":"Recursive Functions"},{"location":"CS61A/2-function/#mutual-recursion","text":"When a recursive procedure is divided among two functions that call each other, the functions are said to be mutually recursive . As an example, consider the following definition of even and odd for non-negative integers. def is_even(n): if n == 0: return True else: return is_odd(n-1) def is_odd(n): if n == 0: return False else: return is_even(n-1) result = is_even(4) Mutually recursive functions can be turned into a single recursive function by breaking the abstraction boundary between the two functions. def is_even(n): if n == 0: return True else: if (n-1) == 0: return False else: return is_even((n-1)-1)","title":"Mutual Recursion"},{"location":"CS61A/2-function/#tree-recursion","text":"A function with multiple recursive calls is said to be tree recursive because each call branches into multiple smaller calls, each of which branches into yet smaller calls, just as the branches of a tree become smaller but more numerous as they extend from the trunk. Fibonacci def fib(n): if n == 1: return 0 elif n == 2: return 1 else: return fib(n-2) + fib(n-1) Counting Partitions def count_partitions(n, m): \"\"\" number of positive integer n using parts up to size m possibility 1: use at least one 4 possibility 2: don't use any 4 \"\"\" if n == 0: return 1 elif n < 0: return 0 elif m == 0: return 0 else: with_m = count_partitions(n-m, m) without_m = count_partitions(n, m-1) return with_m + without_m","title":"Tree Recursion"},{"location":"CS61A/3-data_abstraction/","text":"Data Abstraction Containers Built-in operators for testing whether an element appears in a compound value. >>> digits = [1, 8, 2, 8] >>> 1 in digits True >>> 8 in digits True >>> 5 not in digits True >>> not(5 in digits) True Identity Operators Identity <exp0> is <exp1> evaluates to True if both <exp0> and <exp1> evaluate to the same object Equality <exp0> == <exp1> evaluates to True if both <exp0> and <exp1> evaluate to equal values Identical objects are always equal values Native Data Types Every value in Python has a class that determines what type of value it is. Values that share a class also share behavior. Native data types have the following properties: There are expressions that evaluate to values of native types, called literals . There are built-in functions and operators to manipulate values of native types. Python includes three native numeric types: integers ( int ), real numbers ( float ), and complex numbers ( complex ). Integer literals (sequences of adjacent numerals) evaluate to int values, and mathematical operators manipulate these values. Data Abstraction Lecture Slide We need to guarantee that constructor and selector functions work together to specify the right behavior. Data abstraction uses selectors and constructors to define behavior. If behavior conditions are met, then the representation is valid. You can recognize data abstraction by its behavior. rational data abstraction implemented as functions constructor is a higher order function def rational(n, d): def select(name): if name == 'n': return n elif name == 'd': return d return select selector calls the object itself def numer(x): return x('n') def denom(x): return x('d') The Closure Property of Data Types A method for combining data values satisfies the closure property if: The result of combination can itself be combined using the same method Closure is powerful because it permits us to create hierarchical structures Hierarchical structures are made up of parts, which themselves are made up of parts, and so on Box-and-Pointer Notation in Environment Diagrams Lists are represented as a row of index-labeled adjacent boxes, one per element. Each box either contains a primitive value or points to a compound value. From Textbook The general technique of isolating the parts of a program that deal with how data are represented from the parts that deal with how data are manipulated is a powerful design methodology called data abstraction . Data abstraction makes programs much easier to design, maintain, and modify. In general, the underlying idea of data abstraction is to identify a basic set of operations in terms of which all manipulations of values of some kind will be expressed, and then to use only those operations in manipulating the data A powerful strategy for designing programs: wishful thinking . Compound Data Structure: List 0-indexed in Python: the index represents how far an element is offset from the beginning of the list. pair = [10, 20] x,y = pair >>> pair[0] 10 >>> from operator import getitem >>> getitem(pair, 0) 10 We don't actually need the list type to create pairs. def pair(x, y): \"\"\"Return a function that represents a pair.\"\"\" def get(index): if index == 0: return x elif index == 1: return y return get def select(p, i): \"\"\"Return the element at index i of pair p.\"\"\" return p(i) >>> p = pair(20, 14) >>> select(p, 0) 20 >>> select(p, 1) 14 Sequences A sequence is an ordered collection of values. Common behavior of many kinds of sequences Length. A sequence has a finite length. An empty sequence has length 0. A sequence has an element corresponding to any non-negative integer index less than its length, starting at 0 for the first element. list >>> digits = [1, 8, 2, 8] >>> len(digits) 4 >>> digits[3] 8 append >>> [2, 7] + digits * 2 [2, 7, 1, 8, 2, 8, 1, 8, 2, 8] list in list >>> pairs = [[10, 20], [30, 40]] >>> pairs[1] [30, 40] >>> pairs[1][0] 30 Sequence Iteration # index def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total, index = 0, 0 while index < len(s): if s[index] == value: total = total + 1 index = index + 1 return total # element def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total = 0 for elem in s: if elem == value: total = total + 1 return total recursively def mysum(L): if L == []: return 0 else: return L[0] + mysum(L[1:]) Sequence Unpacking >>> pairs = [[1,2], [2,2], [3,2], [4,4]] >>> for x, y in pairs: if x == y: same_count = same_count + 1 >>> same_count 2 range >>> list(range(-2, 2)) [-2, -1, 0, 1] >>> list(range(5, 8)) [5, 6, 7] >>> list(range(4)) [0, 1, 2, 3] list comprehensions >>> odds = [1, 3, 5, 7, 9] >>> [x+1 for x in odds] [2, 4, 6, 8, 10] >>> [x for x in odds if 25 % x == 0] [1, 5] Sequence Aggregation Several built-in functions take iterable arguments and aggregate them into a value. sum : Return the sum of a 'start' value (default: 0) plus an iterable of numbers. max : With a single iterable argument, return its largest item. With two or more arguments, return the largest argument. all : Return True if bool(x) is True for all values x in the iterable. If the iterable is empty, return True. def divisors(n): return [1] + [x for x in range(2, n) if n % x == 0] def width(area, height): assert area % height == 0 return area // height def perimeter(width, height): return 2 * width + 2 * height def minimum_perimeter(area): heights = divisors(area) perimeters = [perimeter(width(area, h), h) for h in heights] return min(perimeters) >>> [minimum_perimeter(n) for n in range(1, 10)] [4, 6, 8, 8, 12, 10, 16, 12, 12] Higher-Order Function def apply_to_all(map_fn, s): return [map_fn(x) for x in s] def keep_if(filter_fn, s): return [x for x in s if filter_fn(x)] def reduce(reduce_fn, s, initial): reduced = initial for x in s: reduced = reduce_fn(reduced, x) return reduced i.e. >>> reduce(mul, [2, 4, 8], 1) 64 find perfect numbers >>> def divisors_of(n): divides_n = lambda x: n % x == 0 return [1] + keep_if(divides_n, range(2, n)) >>> divisors_of(12) [1, 2, 3, 4, 6] >>> from operator import add >>> def sum_of_divisors(n): return reduce(add, divisors_of(n), 0) >>> def perfect(n): return sum_of_divisors(n) == n >>> keep_if(perfect, range(1, 1000)) [1, 6, 28, 496] Conventional Names The more common name for apply_to_all is map . The more common name for keep_if is filter . The reduce function is built into the functools module of the Python standard library. In this version, the initial argument is optional. >>> apply_to_all = lambda map_fn, s: list(map(map_fn, s)) >>> keep_if = lambda filter_fn, s: list(filter(filter_fn, s)) >>> from functools import reduce >>> from operator import mul >>> def product(s): return reduce(mul, s) >>> product([1, 2, 3, 4, 5]) 120 Sequence Abstraction membership >>> digits [1, 8, 2, 8] >>> 2 in digits True >>> 1828 not in digits True slicing >>> digits[0:2] [1, 8] >>> digits[1:] [8, 2, 8] >>> digits[::-1] [8, 2, 8, 1] >>> digits[0:len(digits):2] [1, 2] >>> [digits[i] for i in range(1,3)] [8, 2] Strings assert -- used for debugging x = \"hello\" #if condition returns True, then nothing happens: assert x == \"hello\" #if condition returns False, AssertionError is raised: assert x == \"goodbye\", \"x should be hello\" membership >>> 'here' in \"Where's Waldo?\" True multiline literals \\n = line feed starts a new line >>> \"\"\"The Zen of Python claims, Readability counts. Read more: import this.\"\"\" 'The Zen of Python\\nclaims, \"Readability counts.\"\\nRead more: import this.' string coercion >>> str(2) + ' is an element of ' + str(digits) '2 is an element of [1, 8, 2, 8]' Dictionaries construct a dictionary from tuples >>> dict([(3, 9), (4, 16), (5, 25)]) {3: 9, 4: 16, 5: 25} example numerals = {'I': 1, 'V': 5, 'X': 10} >>> numerals['X'] 10 key, value, pair >>> numerals.keys() dict_keys(['I', 'V', 'X']) >>> numerals.values() dict_values([1, 5, 10]) >>> numerals.items() dict_items([('I', 1), ('V', 5), ('X', 10)]) if keys in dictionary >>> 'X' in numerals True >>> 'X-ray' in numerals False >>> numerals.get('X', 0) 10 >>> numerals.get('X-ray', 0) 0 dictionary comprehension >>> squares = {x:x*x for x in range(10)} >>> squares {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81} >>> squares[7] 49 limitations dictionaries are unordered collections of key-value pairs restrictions two keys cannot be equal a key cannot be a list or a dictionary (or any mutable type ) dictionary object >>> numerals['X'].pop('X') >>> numerals.get('X') >>> numerals.get('A', 0) 0 >>> numerals.get('V', 0) 5 Trees Recursive description (wooden trees) A tree has a root label and a list of branches Each branch is a tree A tree with zero branches is called a leaf A tree starts at the root Relative description (family trees) Each location in a tree is called a node Each node has a label that can be any value (labels are usually referred as locations) One node can be the parent/child of another (ancestor, descendant, sibling .etc) The top node is the root node Implementation A tree has a root label and a list of branches Each branch is a tree Constructor def tree(label, branches=[]): for branch in branches: assert is_tree(branch) # check: each branch is a tree return [label] + branches Selectors def label(tree): return tree[0] def branches(tree): return tree[1:] check tree or leaf def is_tree(tree): if type(tree) != list or len(tree) < 1: return False for branch in branches (tree): if not is_tree(branch): return False return True def is_leaf(tree): return not branches(tree) # check branches are empty example >>> tree(1) [1] >>> is_leaf(tree(1)) True >>> t = tree(1, [tree(5, [tree(7)]), tree(6)]) >>> t [1, [5, [7]], [6]] >>> label(t) 1 >>> branches(t) [[5, [7]], [6]] >>> branches(t)[0] [5, [7]] >>> is_tree(branches(t)[0]) True >>> label(branches(t)[0]) 5 a tree with no branches >>> leaf = tree(4, []) # same as tree(4) >>> is_tree(leaf) True >>> branches(leaf) [] Strings >>> s = 'Hello' >>> dir(s) ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] ASCII -- American Standard Code for Information Interchange Layout was chosen to support sorting by character code Rows indexed 2-5 are a useful 6-bit (64 element) subset Control characters were designed for transmission >>> ord('A') 65 >>> hex(ord('A')) '0x41' # row 4, column 1 in ASCII table get a sound (alert) from the computer -- \\a is \"Bell\" in ASCII >>> print('\\a') Unicode Standard as of 2021 137,994 characters in Unicode 12.1 150 scripts (organized) Enumeration of character properties, such as case Supports bidirectional display order A canonical name for every character >>> print('\\u0420\\u043e\\u0441\\u0441\\u0438\\u044f') \u0420\u043e\u0441\u0441\u0438\u044f >>> from unicodedata import name, lookup >>> name('A') 'LATIN CAPITAL LETTER A' >>> lookup('WHITE SMILING FACE') '\u263a' >>> lookup('WHITE SMILING FACE').encode() b'\\xe2\\x98\\xba' Mutable Objects All names that refer to the same object are affected by a mutation Only objects of mutable types can change: lists & dictionaries Mutation Can Happen Within a Function Call A function can change the value of any object in its scope. Mutation Sameness and Change As long as we never modify objects, a compound object is just the totality of its pieces A rational number is just its numerator and denominator This view is no longer valid in the presence of change A compound data object has an \"identity\" in addition to the pieces of which it is composed A list is still \"the same\" list even if we change its contents Conversely, we could have two lists that happen to have the same contents, but are different Mutable Default Arguments are Dangerous A default argument value is part of a function value, not generated by a call Lists >>> suits = ['coin', 'string', 'myriad'] # A list literal >>> original_suits = suits >>> suits.pop() # Removes and returns the final element 'myriad' >>> suits.remove('string') # Removes the first element that equals the argument >>> suits.append('cup') # Add an element to the end >>> suits.extend(['sword', 'club']) # Add all elements of a list to the end >>> suits[2] = 'spade' # Replace an element >>> suits[0:2] = ['heart', 'diamond'] # Replace a slice >>> suits ['heart', 'diamond', 'spade', 'club'] >>> original_suits ['heart', 'diamond', 'spade', 'club'] Lists in Lists in Lists >>> t = [1, 2, 3] >>> t[1:3] = [t] >>> [t] [[1, [...]]] >>> t.extend(t) >>> t [1, [...], 1, [...]] >>> t = [1] >>> t.append(t) >>> t [1, [...]] # it's actually [1, [1, [1, [...]]]] # in printing, it seems forever # in storage, it is not another example >>> t = [[1, 2], [3, 4]] >>> t[0].append(t[1:2]) >>> t [[1, 2, [[3, 4]]], [3, 4]] slicing -- inserting vs replacing -- can change list length s[0:0] -- inserting >>> s1 = [1, 2, 3] >>> t = [4, [5], 6] >>> s1[0:0] = t >>> s1 [4, [5], 6, 1, 2, 3] s[0:1] -- replacing >>> s2 = [1, 2, 3] >>> s2[0:1] = t >>> s2 [4, [5], 6, 2, 3] element replacing -- doesn't change list length >>> s3 = [1, 2, 3] >>> t = [4, [5], 6] >>> s3[0] = t >>> s3 [[4, [5], 6], 2, 3] make a copy s = [1, 2, 3] t = list(s) append vs extend >>> l = [1, 2, 3] >>> l.append(4) >>> l [1, 2, 3, 4] >>> l.append([5,6]) >>> l [1, 2, 3, 4, [5, 6]] >>> l.extend([7,8]) >>> l [1, 2, 3, 4, [5, 6], 7, 8] >>> l.extend(9) !ERROR! + creates a new list; append() modifies on the original list list mutations append(el) : Adds el to the end of the list, and returns None extend(lst) : Extends the list by concatenating it with lst, and returns None insert(i, el) : Insert el at index i (does not replace element but adds a new one), and returns None remove(el) : Removes the first occurrence of el in list, otherwise errors, and returns None pop(i) : Removes and returns the element at index i Tuples Immutable sequences >>> (3, 4, 5, 6) (3, 4, 5, 6) >>> 3, 4, 5, 6 (3, 4, 5, 6) >>> () () >>> tuple() () >>> tuple([3, 4, 5, 6]) (3, 4, 5, 6) operations >>> (3, 4) + (5, 6) (3, 4, 5, 6) >>> 5 in (3, 4, 5, 6) True tuples can be used as keys in dictionary, but list cannot >>> {(1, 2): 3} {(1, 2): 3} >>> {[1, 2]: 3} !ERROR! An immutable sequence may still change if it contains a mutable value as an element >>> s = ([1, 2], 3) >>> s[0][0] = 4 >>> s ([4, 2], 3) >>> s = ([1, 2], 3) >>> s[0] = 4 !ERROR! Linked Lists A linked list is either empty or a first value and the rest of the linked list A common representation of a sequence constructed from nested pairs is called a linked list . four = [1, [2, [3, [4, 'empty']]]] recursive structure empty = 'empty' def is_link(s): \"\"\"s is a linked list if it is empty or a (first, rest) pair.\"\"\" return s == empty or (len(s) == 2 and is_link(s[1])) def link(first, rest): \"\"\"Construct a linked list from its first element and the rest.\"\"\" assert is_link(rest), \"rest must be a linked list.\" return [first, rest] def first(s): \"\"\"Return the first element of a linked list s.\"\"\" assert is_link(s), \"first only applies to linked lists.\" assert s != empty, \"empty linked list has no first element.\" return s[0] def rest(s): \"\"\"Return the rest of the elements of a linked list s.\"\"\" assert is_link(s), \"rest only applies to linked lists.\" assert s != empty, \"empty linked list has no rest.\" return s[1] link is a constructor and first and rest are selectors for an abstract data representation of linked lists. The behavior condition for a linked list is that, like a pair, its constructor and selectors are inverse functions. >>> four = link(1, link(2, link(3, link(4, empty)))) >>> first(four) 1 >>> rest(four) [2, [3, [4, 'empty']]] linked list satisfies sequence abstraction def len_link(s): \"\"\"Return the length of linked list s.\"\"\" length = 0 while s != empty: s, length = rest(s), length + 1 return length def getitem_link(s, i): \"\"\"Return the element at index i of linked list s.\"\"\" while i > 0: s, i = rest(s), i - 1 return first(s) recursively def len_link_recursive(s): \"\"\"Return the length of a linked list s.\"\"\" if s == empty: return 0 return 1 + len_link_recursive(rest(s)) def getitem_link_recursive(s, i): \"\"\"Return the element at index i of linked list s.\"\"\" if i == 0: return first(s) return getitem_link_recursive(rest(s), i - 1) transform list >>> def extend_link(s, t): \"\"\"Return a list with the elements of s followed by those of t.\"\"\" assert is_link(s) and is_link(t) if s == empty: return t else: return link(first(s), extend_link(rest(s), t)) >>> extend_link(four, four) [1, [2, [3, [4, [1, [2, [3, [4, 'empty']]]]]]]] >>> def apply_to_all_link(f, s): \"\"\"Apply f to each element of s.\"\"\" assert is_link(s) if s == empty: return s else: return link(f(first(s)), apply_to_all_link(f, rest(s))) >>> apply_to_all_link(lambda x: x*x, four) [1, [4, [9, [16, 'empty']]]] >>> def keep_if_link(f, s): \"\"\"Return a list with elements of s for which f(e) is true.\"\"\" assert is_link(s) if s == empty: return s else: kept = keep_if_link(f, rest(s)) if f(first(s)): return link(first(s), kept) else: return kept >>> keep_if_link(lambda x: x%2 == 0, four) [2, [4, 'empty']] combine list >>> def join_link(s, separator): \"\"\"Return a string of all elements in s separated by separator.\"\"\" if s == empty: return \"\" elif rest(s) == empty: return str(first(s)) else: return str(first(s)) + separator + join_link(rest(s), separator) >>> join_link(four, \", \") '1, 2, 3, 4' count partitions def partitions(n, m): \"\"\"Return a linked list of partitions of n using parts of up to m. Each partition is represented as a linked list. \"\"\" if n == 0: return link(empty, empty) # A list containing the empty partition elif n < 0 or m == 0: return empty else: using_m = partitions(n-m, m) with_m = apply_to_all_link(lambda s: link(m, s), using_m) without_m = partitions(n, m-1) return extend_link(with_m, without_m) def print_partitions(n, m): lists = partitions(n, m) strings = apply_to_all_link(lambda s: join_link(s, \" + \"), lists) print(join_link(strings, \"\\n\")) print_partitions(6, 4) 4 + 2 4 + 1 + 1 3 + 3 3 + 2 + 1 3 + 1 + 1 + 1 2 + 2 + 2 2 + 2 + 1 + 1 2 + 1 + 1 + 1 + 1 1 + 1 + 1 + 1 + 1 + 1 Sets built-in Python container type Set literals are enclosed in braces Duplicate elements are removed on construction Sets have arbitrary order Checking if an element is in set takes constant time -- implemented by hashing >>> s = {'one', 'two', 'three', 'four', 'four'} >>> s {'three', 'one', 'four', 'two'} >>> 'three' in s True >>> len(s) 4 >>> s.union({'one', 'five'}) {'three', 'five', 'one', 'four', 'two'} >>> s.intersection({'six', 'five', 'four', 'three'}) {'three', 'four'} >>> s {'three', 'one', 'four', 'two'} Nonlocal Statements Effect Future assignments to that name change its pre-existing binding in the first non-local frame of the current environment in which that name is bound. Python Particulars Python pre-computes which frame contains each name before executing the body of a function. Within the body of a function, all instances of a name must refer to the same frame. Lists, dictionaries, functions have local state . nonlocal statement def make_withdraw(balance): \"\"\"Return a withdraw function that draws down balance with each call.\"\"\" def withdraw(amount): nonlocal balance # Declare the name \"balance\" nonlocal if amount > balance: return 'Insufficient funds' balance = balance - amount # Re-bind the existing balance name return balance return withdraw Only after a nonlocal statement can a function change the binding of names in these frames. By introducing nonlocal statements, we have created a dual role for assignment statements. Either they change local bindings, or they change nonlocal bindings. Benefit Non-local assignment has given us the ability to maintain some state that is local to a function, inaccessible to the rest of the program. Cost It matters whether the instances are bound to the same function or different instances of that function. Mutable Functions How to create mutable functions? Using non-local statements def make_withdraw(balance): \"\"\"Return a withdraw function with a starting balance.\"\"\" def withdraw(amount): nonlocal balance if amount > balance: return 'Insufficient funds' balance = balance - amount return balance return withdraw Mutable values can be changed without a nonlocal statement def make_withdraw_list(balance): b = [balance] def withdraw(amount): if amount > b[0]: return 'Insufficient funds' b[0] = b[0] - amount return b[0] return withdraw Referential Transparency Expressions are referentially transparent if substituting an expression with its value does not change the meaning of a program. Mutation operations violate the condition of referential transparency because they do more than just return a value; they change the environment . Iterators An iterator is an object that provides sequential access to values, one by one. An iterable value is any value that can be passed to iter to produce an iterator. An iterator is returned from iter and can be passed to next ; all iterators are mutable. The way that Python signals that there are no more values available is to raise a StopIteration exception when next is called. This exception can be handled using a try statement. >>> try: next(iterator) except StopIteration: print('No more values') No more values A container can provide an iterator that provides access to its elements in order. Built-in functions iter(iterable) : Return an iterator over the elements of an iterable value next(iterator) : Return the next element in an iterator Dictionary Iteration A dictionary, its keys, its values, and its items are all iterable values. The order of items in a dictionary is the order in which they were added (Python 3.6+) Historically, items appeared in an arbitrary order (Python 3.5 and earlier) >>> d = {'one': 1, 'two': 2, 'three': 3} >>> d['zero'] = 0 iterate over keys >>> k = iter(d.keys()) # or iter(d) >>> next(k) 'one' >>> next(k) 'two' >>> next(k) 'three' >>> next(k) 'zero' iterate over values v = iter(d.values()) >>> v = iter(d.values()) >>> next(v) 1 >>> next(v) 2 >>> next(v) 3 >>> next(v) 0 iterate over key-value pairs >>> i = iter(d.items()) >>> next(i) ('one', 1) >>> next(i) ('two', 2) >>> next(i) ('three', 3) >>> next(i) ('zero', 0) Once the dictionary's size/shape/structure is changed, the iterator is invalid. For Statements >>> r = range(3,6) >>> for i in r: ... print(i) ... 3 4 5 >>> ri = iter(r) >>> next(ri) 3 >>> for i in ri: ... print(i) ... 4 5 Built-in Iterator Functions Many built-in Python sequence operations return iterators that compute results lazily. map(func, iterable) : Iterate over func(x) for x in iterable filter(func, iterable) : Iterate over x in iterable if func(x) zip(first_iter, second_iter) : Iterate over co-indexed (x, y) pairs reversed(sequence) : Iterate over x in a sequence in reverse order To view the contents of an iterator, place the resulting elements into a container list(iterable) : Create a list containing all x in iterable tuple(iterable) : Create a tuple containing all x in iterable sorted(iterable) : Create a sorted list containing all x in iterable Sequence >>> bcd = ['b', 'c', 'd'] >>> [x.upper() for x in bcd] ['B', 'C', 'D'] Iterator >>> map(lambda x: x.upper(), bcd) <map object at 0x00000244BFC9E608> >>> m = map(lambda x: x.upper(), bcd) >>> next(m) 'B' >>> next(m) 'C' >>> next(m) 'D' compute results lazily >>> def double(x): ... print('**', x, '=>', 2*x, '**') ... return 2*x ... >>> m = map(double, range(3,7)) >>> f = lambda y: y >= 10 >>> t = filter(f, m) >>> next(t) ** 3 => 6 ** ** 4 => 8 ** ** 5 => 10 ** 10 >>> next(t) ** 6 => 12 ** 12 >>> list(t) [] exhaustive results when a list is called >>> list(filter(f, map(double, range(3,7)))) ** 3 => 6 ** ** 4 => 8 ** ** 5 => 10 ** ** 6 => 12 ** [10, 12] comparing zip(,) with items() >>> d = {'a': 1, 'b': 2} >>> items = iter(d.items()) >>> next(items) ('a', 1) >>> next(items) ('b', 2) >>> zip_items = zip(d.keys(), d.values()) >>> next(zip_items) ('a', 1) >>> next(zip_items) ('b', 2) Generators A generator function is a function that yields values instead of returning them. A normal function returns once; a generator function can yield multiple times. A generator is an iterator created automatically by calling a generator function . When a generator function is called, it returns a generator that iterates over its yields >>> def plus_minus(x): ... yield x ... yield -x ... >>> t = plus_minus(3) >>> next(t) 3 >>> next(t) -3 Generators can Yield from Iterators A yield from statement yields all values from an iterator or iterable (Python 3.3). yield vs return While a return statement closes the current frame after the function exits, a yield statement causes the frame to be saved until the next time next is called, which allows the generator to automatically keep track of the iteration state. yield vs yield from example 1 def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k yield from countdown(k-1) otherwise, it will be def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k for x in countdown(k-1): yield x example 2 def substrings(s): \"\"\"Yield all substrings of s. >>> list(substrings('tops')) ['t', 'to', 'top', 'tops', 'o', 'op', 'ops', 'p', 'ps', 's'] \"\"\" if s: yield from prefixes(s) yield from substrings(s[1:]) example 3 def prefixes(s): \"\"\" Yield all prefixes of s. >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: yield from prefixes(s[:-1]) yield s yield from , a shortcut, can be replaced by a for statement. def prefixes(s): \"\"\" Yield all prefixes of s. >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s changing the order of yield s will get def prefixes2(s): \"\"\" >>> result = prefixes2('dogs') >>> list(result) ['dogs', 'dog', 'do', 'd'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s","title":"CS61A-data abstraction"},{"location":"CS61A/3-data_abstraction/#data-abstraction","text":"Containers Built-in operators for testing whether an element appears in a compound value. >>> digits = [1, 8, 2, 8] >>> 1 in digits True >>> 8 in digits True >>> 5 not in digits True >>> not(5 in digits) True","title":"Data Abstraction"},{"location":"CS61A/3-data_abstraction/#identity-operators","text":"Identity <exp0> is <exp1> evaluates to True if both <exp0> and <exp1> evaluate to the same object Equality <exp0> == <exp1> evaluates to True if both <exp0> and <exp1> evaluate to equal values Identical objects are always equal values","title":"Identity Operators"},{"location":"CS61A/3-data_abstraction/#native-data-types","text":"Every value in Python has a class that determines what type of value it is. Values that share a class also share behavior. Native data types have the following properties: There are expressions that evaluate to values of native types, called literals . There are built-in functions and operators to manipulate values of native types. Python includes three native numeric types: integers ( int ), real numbers ( float ), and complex numbers ( complex ). Integer literals (sequences of adjacent numerals) evaluate to int values, and mathematical operators manipulate these values.","title":"Native Data Types"},{"location":"CS61A/3-data_abstraction/#data-abstraction_1","text":"Lecture Slide We need to guarantee that constructor and selector functions work together to specify the right behavior. Data abstraction uses selectors and constructors to define behavior. If behavior conditions are met, then the representation is valid. You can recognize data abstraction by its behavior. rational data abstraction implemented as functions constructor is a higher order function def rational(n, d): def select(name): if name == 'n': return n elif name == 'd': return d return select selector calls the object itself def numer(x): return x('n') def denom(x): return x('d') The Closure Property of Data Types A method for combining data values satisfies the closure property if: The result of combination can itself be combined using the same method Closure is powerful because it permits us to create hierarchical structures Hierarchical structures are made up of parts, which themselves are made up of parts, and so on Box-and-Pointer Notation in Environment Diagrams Lists are represented as a row of index-labeled adjacent boxes, one per element. Each box either contains a primitive value or points to a compound value. From Textbook The general technique of isolating the parts of a program that deal with how data are represented from the parts that deal with how data are manipulated is a powerful design methodology called data abstraction . Data abstraction makes programs much easier to design, maintain, and modify. In general, the underlying idea of data abstraction is to identify a basic set of operations in terms of which all manipulations of values of some kind will be expressed, and then to use only those operations in manipulating the data A powerful strategy for designing programs: wishful thinking . Compound Data Structure: List 0-indexed in Python: the index represents how far an element is offset from the beginning of the list. pair = [10, 20] x,y = pair >>> pair[0] 10 >>> from operator import getitem >>> getitem(pair, 0) 10 We don't actually need the list type to create pairs. def pair(x, y): \"\"\"Return a function that represents a pair.\"\"\" def get(index): if index == 0: return x elif index == 1: return y return get def select(p, i): \"\"\"Return the element at index i of pair p.\"\"\" return p(i) >>> p = pair(20, 14) >>> select(p, 0) 20 >>> select(p, 1) 14","title":"Data Abstraction"},{"location":"CS61A/3-data_abstraction/#sequences","text":"A sequence is an ordered collection of values. Common behavior of many kinds of sequences Length. A sequence has a finite length. An empty sequence has length 0. A sequence has an element corresponding to any non-negative integer index less than its length, starting at 0 for the first element. list >>> digits = [1, 8, 2, 8] >>> len(digits) 4 >>> digits[3] 8 append >>> [2, 7] + digits * 2 [2, 7, 1, 8, 2, 8, 1, 8, 2, 8] list in list >>> pairs = [[10, 20], [30, 40]] >>> pairs[1] [30, 40] >>> pairs[1][0] 30","title":"Sequences"},{"location":"CS61A/3-data_abstraction/#sequence-iteration","text":"# index def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total, index = 0, 0 while index < len(s): if s[index] == value: total = total + 1 index = index + 1 return total # element def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total = 0 for elem in s: if elem == value: total = total + 1 return total recursively def mysum(L): if L == []: return 0 else: return L[0] + mysum(L[1:])","title":"Sequence Iteration"},{"location":"CS61A/3-data_abstraction/#sequence-unpacking","text":">>> pairs = [[1,2], [2,2], [3,2], [4,4]] >>> for x, y in pairs: if x == y: same_count = same_count + 1 >>> same_count 2 range >>> list(range(-2, 2)) [-2, -1, 0, 1] >>> list(range(5, 8)) [5, 6, 7] >>> list(range(4)) [0, 1, 2, 3] list comprehensions >>> odds = [1, 3, 5, 7, 9] >>> [x+1 for x in odds] [2, 4, 6, 8, 10] >>> [x for x in odds if 25 % x == 0] [1, 5]","title":"Sequence Unpacking"},{"location":"CS61A/3-data_abstraction/#sequence-aggregation","text":"Several built-in functions take iterable arguments and aggregate them into a value. sum : Return the sum of a 'start' value (default: 0) plus an iterable of numbers. max : With a single iterable argument, return its largest item. With two or more arguments, return the largest argument. all : Return True if bool(x) is True for all values x in the iterable. If the iterable is empty, return True. def divisors(n): return [1] + [x for x in range(2, n) if n % x == 0] def width(area, height): assert area % height == 0 return area // height def perimeter(width, height): return 2 * width + 2 * height def minimum_perimeter(area): heights = divisors(area) perimeters = [perimeter(width(area, h), h) for h in heights] return min(perimeters) >>> [minimum_perimeter(n) for n in range(1, 10)] [4, 6, 8, 8, 12, 10, 16, 12, 12]","title":"Sequence Aggregation"},{"location":"CS61A/3-data_abstraction/#higher-order-function","text":"def apply_to_all(map_fn, s): return [map_fn(x) for x in s] def keep_if(filter_fn, s): return [x for x in s if filter_fn(x)] def reduce(reduce_fn, s, initial): reduced = initial for x in s: reduced = reduce_fn(reduced, x) return reduced i.e. >>> reduce(mul, [2, 4, 8], 1) 64 find perfect numbers >>> def divisors_of(n): divides_n = lambda x: n % x == 0 return [1] + keep_if(divides_n, range(2, n)) >>> divisors_of(12) [1, 2, 3, 4, 6] >>> from operator import add >>> def sum_of_divisors(n): return reduce(add, divisors_of(n), 0) >>> def perfect(n): return sum_of_divisors(n) == n >>> keep_if(perfect, range(1, 1000)) [1, 6, 28, 496]","title":"Higher-Order Function"},{"location":"CS61A/3-data_abstraction/#conventional-names","text":"The more common name for apply_to_all is map . The more common name for keep_if is filter . The reduce function is built into the functools module of the Python standard library. In this version, the initial argument is optional. >>> apply_to_all = lambda map_fn, s: list(map(map_fn, s)) >>> keep_if = lambda filter_fn, s: list(filter(filter_fn, s)) >>> from functools import reduce >>> from operator import mul >>> def product(s): return reduce(mul, s) >>> product([1, 2, 3, 4, 5]) 120","title":"Conventional Names"},{"location":"CS61A/3-data_abstraction/#sequence-abstraction","text":"membership >>> digits [1, 8, 2, 8] >>> 2 in digits True >>> 1828 not in digits True slicing >>> digits[0:2] [1, 8] >>> digits[1:] [8, 2, 8] >>> digits[::-1] [8, 2, 8, 1] >>> digits[0:len(digits):2] [1, 2] >>> [digits[i] for i in range(1,3)] [8, 2]","title":"Sequence Abstraction"},{"location":"CS61A/3-data_abstraction/#strings","text":"assert -- used for debugging x = \"hello\" #if condition returns True, then nothing happens: assert x == \"hello\" #if condition returns False, AssertionError is raised: assert x == \"goodbye\", \"x should be hello\" membership >>> 'here' in \"Where's Waldo?\" True multiline literals \\n = line feed starts a new line >>> \"\"\"The Zen of Python claims, Readability counts. Read more: import this.\"\"\" 'The Zen of Python\\nclaims, \"Readability counts.\"\\nRead more: import this.' string coercion >>> str(2) + ' is an element of ' + str(digits) '2 is an element of [1, 8, 2, 8]'","title":"Strings"},{"location":"CS61A/3-data_abstraction/#dictionaries","text":"construct a dictionary from tuples >>> dict([(3, 9), (4, 16), (5, 25)]) {3: 9, 4: 16, 5: 25} example numerals = {'I': 1, 'V': 5, 'X': 10} >>> numerals['X'] 10 key, value, pair >>> numerals.keys() dict_keys(['I', 'V', 'X']) >>> numerals.values() dict_values([1, 5, 10]) >>> numerals.items() dict_items([('I', 1), ('V', 5), ('X', 10)]) if keys in dictionary >>> 'X' in numerals True >>> 'X-ray' in numerals False >>> numerals.get('X', 0) 10 >>> numerals.get('X-ray', 0) 0 dictionary comprehension >>> squares = {x:x*x for x in range(10)} >>> squares {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81} >>> squares[7] 49 limitations dictionaries are unordered collections of key-value pairs restrictions two keys cannot be equal a key cannot be a list or a dictionary (or any mutable type ) dictionary object >>> numerals['X'].pop('X') >>> numerals.get('X') >>> numerals.get('A', 0) 0 >>> numerals.get('V', 0) 5","title":"Dictionaries"},{"location":"CS61A/3-data_abstraction/#trees","text":"Recursive description (wooden trees) A tree has a root label and a list of branches Each branch is a tree A tree with zero branches is called a leaf A tree starts at the root Relative description (family trees) Each location in a tree is called a node Each node has a label that can be any value (labels are usually referred as locations) One node can be the parent/child of another (ancestor, descendant, sibling .etc) The top node is the root node Implementation A tree has a root label and a list of branches Each branch is a tree Constructor def tree(label, branches=[]): for branch in branches: assert is_tree(branch) # check: each branch is a tree return [label] + branches Selectors def label(tree): return tree[0] def branches(tree): return tree[1:] check tree or leaf def is_tree(tree): if type(tree) != list or len(tree) < 1: return False for branch in branches (tree): if not is_tree(branch): return False return True def is_leaf(tree): return not branches(tree) # check branches are empty example >>> tree(1) [1] >>> is_leaf(tree(1)) True >>> t = tree(1, [tree(5, [tree(7)]), tree(6)]) >>> t [1, [5, [7]], [6]] >>> label(t) 1 >>> branches(t) [[5, [7]], [6]] >>> branches(t)[0] [5, [7]] >>> is_tree(branches(t)[0]) True >>> label(branches(t)[0]) 5 a tree with no branches >>> leaf = tree(4, []) # same as tree(4) >>> is_tree(leaf) True >>> branches(leaf) []","title":"Trees"},{"location":"CS61A/3-data_abstraction/#strings_1","text":">>> s = 'Hello' >>> dir(s) ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] ASCII -- American Standard Code for Information Interchange Layout was chosen to support sorting by character code Rows indexed 2-5 are a useful 6-bit (64 element) subset Control characters were designed for transmission >>> ord('A') 65 >>> hex(ord('A')) '0x41' # row 4, column 1 in ASCII table get a sound (alert) from the computer -- \\a is \"Bell\" in ASCII >>> print('\\a') Unicode Standard as of 2021 137,994 characters in Unicode 12.1 150 scripts (organized) Enumeration of character properties, such as case Supports bidirectional display order A canonical name for every character >>> print('\\u0420\\u043e\\u0441\\u0441\\u0438\\u044f') \u0420\u043e\u0441\u0441\u0438\u044f >>> from unicodedata import name, lookup >>> name('A') 'LATIN CAPITAL LETTER A' >>> lookup('WHITE SMILING FACE') '\u263a' >>> lookup('WHITE SMILING FACE').encode() b'\\xe2\\x98\\xba'","title":"Strings"},{"location":"CS61A/3-data_abstraction/#mutable-objects","text":"All names that refer to the same object are affected by a mutation Only objects of mutable types can change: lists & dictionaries Mutation Can Happen Within a Function Call A function can change the value of any object in its scope.","title":"Mutable Objects"},{"location":"CS61A/3-data_abstraction/#mutation","text":"Sameness and Change As long as we never modify objects, a compound object is just the totality of its pieces A rational number is just its numerator and denominator This view is no longer valid in the presence of change A compound data object has an \"identity\" in addition to the pieces of which it is composed A list is still \"the same\" list even if we change its contents Conversely, we could have two lists that happen to have the same contents, but are different Mutable Default Arguments are Dangerous A default argument value is part of a function value, not generated by a call","title":"Mutation"},{"location":"CS61A/3-data_abstraction/#lists","text":">>> suits = ['coin', 'string', 'myriad'] # A list literal >>> original_suits = suits >>> suits.pop() # Removes and returns the final element 'myriad' >>> suits.remove('string') # Removes the first element that equals the argument >>> suits.append('cup') # Add an element to the end >>> suits.extend(['sword', 'club']) # Add all elements of a list to the end >>> suits[2] = 'spade' # Replace an element >>> suits[0:2] = ['heart', 'diamond'] # Replace a slice >>> suits ['heart', 'diamond', 'spade', 'club'] >>> original_suits ['heart', 'diamond', 'spade', 'club'] Lists in Lists in Lists >>> t = [1, 2, 3] >>> t[1:3] = [t] >>> [t] [[1, [...]]] >>> t.extend(t) >>> t [1, [...], 1, [...]] >>> t = [1] >>> t.append(t) >>> t [1, [...]] # it's actually [1, [1, [1, [...]]]] # in printing, it seems forever # in storage, it is not another example >>> t = [[1, 2], [3, 4]] >>> t[0].append(t[1:2]) >>> t [[1, 2, [[3, 4]]], [3, 4]] slicing -- inserting vs replacing -- can change list length s[0:0] -- inserting >>> s1 = [1, 2, 3] >>> t = [4, [5], 6] >>> s1[0:0] = t >>> s1 [4, [5], 6, 1, 2, 3] s[0:1] -- replacing >>> s2 = [1, 2, 3] >>> s2[0:1] = t >>> s2 [4, [5], 6, 2, 3] element replacing -- doesn't change list length >>> s3 = [1, 2, 3] >>> t = [4, [5], 6] >>> s3[0] = t >>> s3 [[4, [5], 6], 2, 3] make a copy s = [1, 2, 3] t = list(s) append vs extend >>> l = [1, 2, 3] >>> l.append(4) >>> l [1, 2, 3, 4] >>> l.append([5,6]) >>> l [1, 2, 3, 4, [5, 6]] >>> l.extend([7,8]) >>> l [1, 2, 3, 4, [5, 6], 7, 8] >>> l.extend(9) !ERROR! + creates a new list; append() modifies on the original list list mutations append(el) : Adds el to the end of the list, and returns None extend(lst) : Extends the list by concatenating it with lst, and returns None insert(i, el) : Insert el at index i (does not replace element but adds a new one), and returns None remove(el) : Removes the first occurrence of el in list, otherwise errors, and returns None pop(i) : Removes and returns the element at index i","title":"Lists"},{"location":"CS61A/3-data_abstraction/#tuples","text":"Immutable sequences >>> (3, 4, 5, 6) (3, 4, 5, 6) >>> 3, 4, 5, 6 (3, 4, 5, 6) >>> () () >>> tuple() () >>> tuple([3, 4, 5, 6]) (3, 4, 5, 6) operations >>> (3, 4) + (5, 6) (3, 4, 5, 6) >>> 5 in (3, 4, 5, 6) True tuples can be used as keys in dictionary, but list cannot >>> {(1, 2): 3} {(1, 2): 3} >>> {[1, 2]: 3} !ERROR! An immutable sequence may still change if it contains a mutable value as an element >>> s = ([1, 2], 3) >>> s[0][0] = 4 >>> s ([4, 2], 3) >>> s = ([1, 2], 3) >>> s[0] = 4 !ERROR!","title":"Tuples"},{"location":"CS61A/3-data_abstraction/#linked-lists","text":"A linked list is either empty or a first value and the rest of the linked list A common representation of a sequence constructed from nested pairs is called a linked list . four = [1, [2, [3, [4, 'empty']]]] recursive structure empty = 'empty' def is_link(s): \"\"\"s is a linked list if it is empty or a (first, rest) pair.\"\"\" return s == empty or (len(s) == 2 and is_link(s[1])) def link(first, rest): \"\"\"Construct a linked list from its first element and the rest.\"\"\" assert is_link(rest), \"rest must be a linked list.\" return [first, rest] def first(s): \"\"\"Return the first element of a linked list s.\"\"\" assert is_link(s), \"first only applies to linked lists.\" assert s != empty, \"empty linked list has no first element.\" return s[0] def rest(s): \"\"\"Return the rest of the elements of a linked list s.\"\"\" assert is_link(s), \"rest only applies to linked lists.\" assert s != empty, \"empty linked list has no rest.\" return s[1] link is a constructor and first and rest are selectors for an abstract data representation of linked lists. The behavior condition for a linked list is that, like a pair, its constructor and selectors are inverse functions. >>> four = link(1, link(2, link(3, link(4, empty)))) >>> first(four) 1 >>> rest(four) [2, [3, [4, 'empty']]] linked list satisfies sequence abstraction def len_link(s): \"\"\"Return the length of linked list s.\"\"\" length = 0 while s != empty: s, length = rest(s), length + 1 return length def getitem_link(s, i): \"\"\"Return the element at index i of linked list s.\"\"\" while i > 0: s, i = rest(s), i - 1 return first(s) recursively def len_link_recursive(s): \"\"\"Return the length of a linked list s.\"\"\" if s == empty: return 0 return 1 + len_link_recursive(rest(s)) def getitem_link_recursive(s, i): \"\"\"Return the element at index i of linked list s.\"\"\" if i == 0: return first(s) return getitem_link_recursive(rest(s), i - 1) transform list >>> def extend_link(s, t): \"\"\"Return a list with the elements of s followed by those of t.\"\"\" assert is_link(s) and is_link(t) if s == empty: return t else: return link(first(s), extend_link(rest(s), t)) >>> extend_link(four, four) [1, [2, [3, [4, [1, [2, [3, [4, 'empty']]]]]]]] >>> def apply_to_all_link(f, s): \"\"\"Apply f to each element of s.\"\"\" assert is_link(s) if s == empty: return s else: return link(f(first(s)), apply_to_all_link(f, rest(s))) >>> apply_to_all_link(lambda x: x*x, four) [1, [4, [9, [16, 'empty']]]] >>> def keep_if_link(f, s): \"\"\"Return a list with elements of s for which f(e) is true.\"\"\" assert is_link(s) if s == empty: return s else: kept = keep_if_link(f, rest(s)) if f(first(s)): return link(first(s), kept) else: return kept >>> keep_if_link(lambda x: x%2 == 0, four) [2, [4, 'empty']] combine list >>> def join_link(s, separator): \"\"\"Return a string of all elements in s separated by separator.\"\"\" if s == empty: return \"\" elif rest(s) == empty: return str(first(s)) else: return str(first(s)) + separator + join_link(rest(s), separator) >>> join_link(four, \", \") '1, 2, 3, 4' count partitions def partitions(n, m): \"\"\"Return a linked list of partitions of n using parts of up to m. Each partition is represented as a linked list. \"\"\" if n == 0: return link(empty, empty) # A list containing the empty partition elif n < 0 or m == 0: return empty else: using_m = partitions(n-m, m) with_m = apply_to_all_link(lambda s: link(m, s), using_m) without_m = partitions(n, m-1) return extend_link(with_m, without_m) def print_partitions(n, m): lists = partitions(n, m) strings = apply_to_all_link(lambda s: join_link(s, \" + \"), lists) print(join_link(strings, \"\\n\")) print_partitions(6, 4) 4 + 2 4 + 1 + 1 3 + 3 3 + 2 + 1 3 + 1 + 1 + 1 2 + 2 + 2 2 + 2 + 1 + 1 2 + 1 + 1 + 1 + 1 1 + 1 + 1 + 1 + 1 + 1","title":"Linked Lists"},{"location":"CS61A/3-data_abstraction/#sets","text":"built-in Python container type Set literals are enclosed in braces Duplicate elements are removed on construction Sets have arbitrary order Checking if an element is in set takes constant time -- implemented by hashing >>> s = {'one', 'two', 'three', 'four', 'four'} >>> s {'three', 'one', 'four', 'two'} >>> 'three' in s True >>> len(s) 4 >>> s.union({'one', 'five'}) {'three', 'five', 'one', 'four', 'two'} >>> s.intersection({'six', 'five', 'four', 'three'}) {'three', 'four'} >>> s {'three', 'one', 'four', 'two'}","title":"Sets"},{"location":"CS61A/3-data_abstraction/#nonlocal-statements","text":"Effect Future assignments to that name change its pre-existing binding in the first non-local frame of the current environment in which that name is bound. Python Particulars Python pre-computes which frame contains each name before executing the body of a function. Within the body of a function, all instances of a name must refer to the same frame. Lists, dictionaries, functions have local state . nonlocal statement def make_withdraw(balance): \"\"\"Return a withdraw function that draws down balance with each call.\"\"\" def withdraw(amount): nonlocal balance # Declare the name \"balance\" nonlocal if amount > balance: return 'Insufficient funds' balance = balance - amount # Re-bind the existing balance name return balance return withdraw Only after a nonlocal statement can a function change the binding of names in these frames. By introducing nonlocal statements, we have created a dual role for assignment statements. Either they change local bindings, or they change nonlocal bindings. Benefit Non-local assignment has given us the ability to maintain some state that is local to a function, inaccessible to the rest of the program. Cost It matters whether the instances are bound to the same function or different instances of that function.","title":"Nonlocal Statements"},{"location":"CS61A/3-data_abstraction/#mutable-functions","text":"How to create mutable functions? Using non-local statements def make_withdraw(balance): \"\"\"Return a withdraw function with a starting balance.\"\"\" def withdraw(amount): nonlocal balance if amount > balance: return 'Insufficient funds' balance = balance - amount return balance return withdraw Mutable values can be changed without a nonlocal statement def make_withdraw_list(balance): b = [balance] def withdraw(amount): if amount > b[0]: return 'Insufficient funds' b[0] = b[0] - amount return b[0] return withdraw Referential Transparency Expressions are referentially transparent if substituting an expression with its value does not change the meaning of a program. Mutation operations violate the condition of referential transparency because they do more than just return a value; they change the environment .","title":"Mutable Functions"},{"location":"CS61A/3-data_abstraction/#iterators","text":"An iterator is an object that provides sequential access to values, one by one. An iterable value is any value that can be passed to iter to produce an iterator. An iterator is returned from iter and can be passed to next ; all iterators are mutable. The way that Python signals that there are no more values available is to raise a StopIteration exception when next is called. This exception can be handled using a try statement. >>> try: next(iterator) except StopIteration: print('No more values') No more values A container can provide an iterator that provides access to its elements in order. Built-in functions iter(iterable) : Return an iterator over the elements of an iterable value next(iterator) : Return the next element in an iterator","title":"Iterators"},{"location":"CS61A/3-data_abstraction/#dictionary-iteration","text":"A dictionary, its keys, its values, and its items are all iterable values. The order of items in a dictionary is the order in which they were added (Python 3.6+) Historically, items appeared in an arbitrary order (Python 3.5 and earlier) >>> d = {'one': 1, 'two': 2, 'three': 3} >>> d['zero'] = 0 iterate over keys >>> k = iter(d.keys()) # or iter(d) >>> next(k) 'one' >>> next(k) 'two' >>> next(k) 'three' >>> next(k) 'zero' iterate over values v = iter(d.values()) >>> v = iter(d.values()) >>> next(v) 1 >>> next(v) 2 >>> next(v) 3 >>> next(v) 0 iterate over key-value pairs >>> i = iter(d.items()) >>> next(i) ('one', 1) >>> next(i) ('two', 2) >>> next(i) ('three', 3) >>> next(i) ('zero', 0) Once the dictionary's size/shape/structure is changed, the iterator is invalid. For Statements >>> r = range(3,6) >>> for i in r: ... print(i) ... 3 4 5 >>> ri = iter(r) >>> next(ri) 3 >>> for i in ri: ... print(i) ... 4 5","title":"Dictionary Iteration"},{"location":"CS61A/3-data_abstraction/#built-in-iterator-functions","text":"Many built-in Python sequence operations return iterators that compute results lazily. map(func, iterable) : Iterate over func(x) for x in iterable filter(func, iterable) : Iterate over x in iterable if func(x) zip(first_iter, second_iter) : Iterate over co-indexed (x, y) pairs reversed(sequence) : Iterate over x in a sequence in reverse order To view the contents of an iterator, place the resulting elements into a container list(iterable) : Create a list containing all x in iterable tuple(iterable) : Create a tuple containing all x in iterable sorted(iterable) : Create a sorted list containing all x in iterable Sequence >>> bcd = ['b', 'c', 'd'] >>> [x.upper() for x in bcd] ['B', 'C', 'D'] Iterator >>> map(lambda x: x.upper(), bcd) <map object at 0x00000244BFC9E608> >>> m = map(lambda x: x.upper(), bcd) >>> next(m) 'B' >>> next(m) 'C' >>> next(m) 'D' compute results lazily >>> def double(x): ... print('**', x, '=>', 2*x, '**') ... return 2*x ... >>> m = map(double, range(3,7)) >>> f = lambda y: y >= 10 >>> t = filter(f, m) >>> next(t) ** 3 => 6 ** ** 4 => 8 ** ** 5 => 10 ** 10 >>> next(t) ** 6 => 12 ** 12 >>> list(t) [] exhaustive results when a list is called >>> list(filter(f, map(double, range(3,7)))) ** 3 => 6 ** ** 4 => 8 ** ** 5 => 10 ** ** 6 => 12 ** [10, 12] comparing zip(,) with items() >>> d = {'a': 1, 'b': 2} >>> items = iter(d.items()) >>> next(items) ('a', 1) >>> next(items) ('b', 2) >>> zip_items = zip(d.keys(), d.values()) >>> next(zip_items) ('a', 1) >>> next(zip_items) ('b', 2)","title":"Built-in Iterator Functions"},{"location":"CS61A/3-data_abstraction/#generators","text":"A generator function is a function that yields values instead of returning them. A normal function returns once; a generator function can yield multiple times. A generator is an iterator created automatically by calling a generator function . When a generator function is called, it returns a generator that iterates over its yields >>> def plus_minus(x): ... yield x ... yield -x ... >>> t = plus_minus(3) >>> next(t) 3 >>> next(t) -3 Generators can Yield from Iterators A yield from statement yields all values from an iterator or iterable (Python 3.3). yield vs return While a return statement closes the current frame after the function exits, a yield statement causes the frame to be saved until the next time next is called, which allows the generator to automatically keep track of the iteration state. yield vs yield from example 1 def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k yield from countdown(k-1) otherwise, it will be def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k for x in countdown(k-1): yield x example 2 def substrings(s): \"\"\"Yield all substrings of s. >>> list(substrings('tops')) ['t', 'to', 'top', 'tops', 'o', 'op', 'ops', 'p', 'ps', 's'] \"\"\" if s: yield from prefixes(s) yield from substrings(s[1:]) example 3 def prefixes(s): \"\"\" Yield all prefixes of s. >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: yield from prefixes(s[:-1]) yield s yield from , a shortcut, can be replaced by a for statement. def prefixes(s): \"\"\" Yield all prefixes of s. >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s changing the order of yield s will get def prefixes2(s): \"\"\" >>> result = prefixes2('dogs') >>> list(result) ['dogs', 'dog', 'do', 'd'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s","title":"Generators"},{"location":"CS61A/4-object_oriented/","text":"Object-Oriented Programming A method for organizing modular programs Abstraction barriers Bundling together information and related behavior A metaphor for computation using distributed state each object has its own local state each object also know how to change its own local state, based on method calls method calls are messages passed between objects several objects may all be instances of a common type different types may relate to each other Specialized syntax and vocabulary to support this metaphor Classes and Objects A class combines (and abstracts) data and functions An object is an instantiation of a class example String is a built-in class, append is a function Int is a built-in class, + is a function myball = Ball(10.0, 15.0, 0.0, -5.0) Classes A class serves as a template for its instances class <name>: <suite> A class statement creates a new class and \\<name> binds that class to in the first frame of the current environment Assignment & def statements in \\<suite> create attributes of the class (not names in frames) When a class is called A new instance of that class is created The __init__ method of the class is called with the new object as its first argument (named self ), along with any additional arguments provided in the call expression class Account: \"\"\"An account has a balance and a holder. All accounts share a common interest rate. >>> a = Account('John') >>> a.holder 'John' >>> a.deposit(100) 100 >>> a.withdraw(90) 10 >>> a.withdraw(90) 'Insufficient funds' >>> a.balance 10 >>> a.interest 0.02 >>> Account.interest = 0.04 >>> a.interest 0.04 \"\"\" interest = 0.02 # A class attribute def __init__(self, account_holder): self.holder = account_holder self.balance = 0 def deposit(self, amount): \"\"\"Add amount to balance.\"\"\" self.balance = self.balance + amount return self.balance def withdraw(self, amount): \"\"\"Subtract amount from balance if funds are available.\"\"\" if amount > self.balance: return 'Insufficient funds' self.balance = self.balance - amount return self.balance __init__ is called a constructor Constructor allocate memory for a Ball object initialize the Ball object with values return address of the Ball object similar to a list Objects Objects represent information They consist of data and behavior , bundled together to create abstractions Objects can represent things, but also properties, interactions, & processes A type of object is called a class ; classes are first-class values in Python Object-oriented programming: A metaphor for organizing large programs Special syntax that can improve the composition of programs (i.e. . expression) In Python, every value is an object All objects have attributes (named values that are part of the object) use . to designated an attribute of an object A lot of data manipulation happens through object methods (function-valued attributes) can be accessed through . expression date(2021,1,1).strftime('%Y-%M-%d') date(2021,1,1).strftime('%A %B %d') Functions do one thing; objects do many related things Instance help(isinstance) : Return whether an object is an instance of a class or of a subclass thereof. >>> n = 123 >>> isinstance(n, int) True Methods and Functions Python distinguishes between: Functions, which we have been creating since the beginning of the course Bound methods, which couple together a function and the object on which that method will be invoked Object + Function = Bound Method >>> type(Account.deposit) <class 'function'> >>> type(tom_account.deposit) <class 'method'> Methods Methods are functions defined in the suite of a class statement Invoking methods All invoked methods have access to the object via the self parameter, and so they can all access and manipulate the object's state Dot notation automatically supplies the first argument to a method Static Method class Math: @staticmethod def square(x): return x*x The decorator @staticmethod allows square to be a regular function, but happen to be grouped in Math class. Dot Expressions Objects receive messages via dot notation Dot notation accesses attributes of the instance or its class <expression> . <name> The <expression> can be any valid Python expression The <name> must be a simple name Evaluates to the value of the attribute looked up by <name> in the object that is the value of the <expression> Attributes Data stored within either an instance or a class Attributes can be accessed using dot notation built-in function getattr Objects are iterable (an interface) if they have an __iter__ method that returns an iterator . Class Attributes Class attributes are \"shared\" across all instances of a class because they are attributes of the class, not the instance. class Account: interest = 0.02 # A class attribute def __init__(self, account_holder): self.balance = 0 self.holder = account_holder # Additional methods would be defined here Python Object System Functions are objects. Bound methods are also objects: a function that has its first parameter \"self\" already bound to an instance. Dot expression evaluate to bound methods for class attributes that are functions <instance>.<method_name> Inheritance Inheritance is a method for relating classes together. class <name>(<base class>): <suite> Conceptually, the new subclass \"shares\" attributes with its base class. Using inheritance, we implement a subclass by specifying its differences from the base class. class Account: \"\"\"An account has a balance and a holder. >>> a = Account('John') >>> a.holder 'John' >>> a.deposit(100) 100 >>> a.withdraw(90) 10 >>> a.withdraw(90) 'Insufficient funds' >>> a.balance 10 >>> a.interest 0.02 \"\"\" interest = 0.02 # A class attribute def __init__(self, account_holder): self.holder = account_holder self.balance = 0 def deposit(self, amount): \"\"\"Add amount to balance.\"\"\" self.balance = self.balance + amount return self.balance def withdraw(self, amount): \"\"\"Subtract amount from balance if funds are available.\"\"\" if amount > self.balance: return 'Insufficient funds' self.balance = self.balance - amount return self.balance class CheckingAccount(Account): \"\"\"A bank account that charges for withdrawals. >>> ch = CheckingAccount('Jack') >>> ch.balance = 20 >>> ch.withdraw(5) 14 >>> ch.interest 0.01 \"\"\" withdraw_fee = 1 interest = 0.01 def withdraw(self, amount): return Account.withdraw(self, amount + self.withdraw_fee) # Alternatively: return super().withdraw(amount + self.withdraw_fee) class SavingsAccount(Account): \"\"\"A bank account that charges for deposits.\"\"\" deposit_fee = 2 def deposit(self, amount): return Account.deposit(self, amount - self.deposit_fee) The super() function in Python makes class inheritance more manageable and extensible. The function returns a temporary object that allows reference to a parent class. Multiple Inheritance class AsSeenOnTVAccount(CheckingAccount, SavingsAccount): \"\"\"A bank account that charges for everything.\"\"\" def __init__(self, account_holder): self.holder = account_holder self.balance = 1 # A free dollar! results >>> such_a_deal = AsSeenOnTVAccount(\"John\") >>> such_a_deal.balance 1 >>> such_a_deal.deposit(20) 19 Inheritance and Composition Inheritance is best for representing is-a relationships. E.g., a checking account is a specific type of account So, CheckingAccount inherits from Account Composition is best for representing has-a relationships E.g., a bank has a collection of bank accounts it manages So, A bank has a list of accounts as an attribute composition example class Bank: \"\"\"A bank has accounts and pays interest. >>> bank = Bank() >>> john = bank.open_account('John', 10) >>> jack = bank.open_account('Jack', 5, CheckingAccount) >>> jack.interest 0.01 >>> john.interest = 0.06 >>> bank.pay_interest() >>> john.balance 10.6 >>> jack.balance 5.05 \"\"\" def __init__(self): self.accounts = [] def open_account(self, holder, amount, account_type=Account): \"\"\"Open an account_type for holder and deposit amount.\"\"\" account = account_type(holder) account.deposit(amount) self.accounts.append(account) return account def pay_interest(self): \"\"\"Pay interest to all accounts.\"\"\" for account in self.accounts: account.deposit(account.balance * account.interest) Object Oriented Design Designing for inheritance -- don't repeat yourself. Attributes that have been overridden are still accessible via class objects. Representation String Representations In Python, all objects produce two string representations: The str is legible to humans The repr is legible to the Python interpreter The str and repr strings are often the same, but not always. str String for an Object The result of calling str on the value of an expression is what Python prints using the print function. >>> from fractions import Fraction >>> half = Fraction(1, 2) >>> repr(half) 'Fraction(1, 2)' >>> str(half) '1/2' >>> print(half) 1/2 repr String for an Object The repr function returns a Python expression (a string) that evaluates to an equal object. repr(object) -> string Return the canonical string representation of the object. For most object types, eval(repr(object)) == object . >>> 12e6 12000000.0 >>> print(repr(12e6)) 12000000.0 Some objects do not have a simple Python-readable string >>> repr(min) '<built-in function min>' eval and repr >>> s = 'Hello, World' >>> s 'Hello, World' >>> print(repr(s)) 'Hello, World' >>> print(s) Hello, World >>> print(str(s)) Hello, World >>> repr(s) \"'Hello, World'\" >>> eval(repr(s)) 'Hello, World' @property decorator allows functions to be called without call expression syntax (parentheses following an expression). >>> from math import atan2 >>> class ComplexRI(Complex): def __init__(self, real, imag): self.real = real self.imag = imag @property def magnitude(self): return (self.real ** 2 + self.imag ** 2) ** 0.5 @property def angle(self): return atan2(self.imag, self.real) def __repr__(self): return 'ComplexRI({0:g}, {1:g})'.format(self.real, self.imag) usage >>> ri = ComplexRI(5, 12) >>> ri.real 5 >>> ri.magnitude 13.0 >>> ri.real = 9 >>> ri.real 9 >>> ri.magnitude 15.0 Polymorphic Functions A function that applies to many (poly) different forms (morph) of data. str and repr are both polymorphic; they apply to any object. repr invokes a zero-argument method __repr__ on its argument. >>> half.__repr__() 'Fraction(1, 2)' str invokes a zero-argument method __str__ on its argument >>> half.__str__() '1/2' Implementation of repr and str The behavior of repr is slightly more complicated than invoking __repr__ on its argument. An instance attribute called __repr__ is ignored! Only class attributes are found. def repr(x): return type(x).__repr__(x) The behavior of str is also complicated. An instance attribute called __str__ is ignored. If no __str__ attribute is found, uses repr string. str is a class, not a function. def str(x): t = type(x) if hasattr(t, '__str__'): return t.__str__(x) else: return repr(x) Example class Bear: \"\"\"A Bear.\"\"\" def __init__(self): self.__repr__ = lambda: 'oski' self.__str__ = lambda: 'this bear' def __repr__(self): return 'Bear()' def __str__(self): return 'a bear' compare >>> oski = Bear() >>> print(oski) a bear >>> print(str(oski)) a bear >>> print(repr(oski)) Bear() >>> print(oski.__str__()) this bear >>> print(oski.__repr__()) oski Interfaces Message passing : Objects interact by looking up attributes on each other (passing messages). The attribute look-up rules allow different data types to respond to the same message A shared message (attribute name) that elicits similar behavior from different object classes is a powerful method of abstraction. An interface is a set of shared messages , along with a specification of what they mean. Special Method Names in Python Certain names are special because they have built-in behavior. These names always start and end with two underscores __init__ : Method invoked automatically when an object is constructed. __repr__ : Method invoked to display an object as a Python expression. __add__ : Method invoked to add one object to another. __radd__ = __add__ __bool__ : Method invoked to convert an object to True or False. Account.__bool__ = lambda self: self.balance != 0 __float__ : Method invoked to convert an object to a float (real number). Efficiency (Q) Constant Time Increasing n doesn't affect time Logarithmic Time Doubling the input increases the time by a constant C 1024x the input increases the time by only 10 times C i.e. exp_fast Linear Time Doubling the input doubles the time 1024x the input takes 1024x as much time i.e. exp Quadratic Time Functions that process all pairs of values in a sequence of length n take quadratic time i.e. overlap Exponential Time Tree-recursive functions can take exponential time i.e. recursive fib How many calculations to do Fib Tree? def fib(n): if n == 0 or n == 1: return n else: return fib(n-2) + fib(n-1) def count(f): def counted(n): counted.call_count += 1 return f(n) counted.call_count = 0 return counted Memoization Idea: remember the results that have been computed before. def memo(f): cache = {} def memoized(n): if n not in cache: cache[n] = f(n) return cache[n] return memoized Exponentiation def exp(b, n): if n == 0: return 1 else: return b * exp(b, n-1) def exp_fast(b, n): if n == 0: return 1 elif n % 2 == 0: return square(exp_fast(b, n//2)) else: return b * exp_fast(b, n-1) def square(x): return x * x Consumption of Space Which environment frames do we need to keep during evaluation? At any moment there is a set of active environments Values and frames in active environments consume memory Memory that is used for other values and frames can be recycled Active environments Environments for any function calls currently being evaluated Parent environments of functions named in active environments Object Examples Type Dispatching isinstance() >>> isinstance(123, int) True >>> isinstance(123, str) False >>> isinstance('123', str) True isnumeric() >>> '1234'.isnumeric() True >>> 'xyz'.isnumeric() False >>> '2.0'.isnumeric() False Date Object >>> from datetime import date, timedelta >>> today = date(2021,2,14) >>> today.year 2021 >>> today.strftime('%A, %B, %d') 'Sunday, February, 14' >>> today + timedelta(days=90) datetime.date(2021, 5, 15) >>> dir(today) ['__add__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__rsub__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', 'ctime', 'day', 'fromisoformat', 'fromordinal', 'fromtimestamp', 'isocalendar', 'isoformat', 'isoweekday', 'max', 'min', 'month', 'replace', 'resolution', 'strftime', 'timetuple', 'today', 'toordinal', 'weekday', 'year'] String Object >>> 'rOBERT dE nIRO'.swapcase() 'Robert De Niro' >>> 'eyes'.upper().endswith('YES') True >>> dir('x') ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] Sequence/List? Object assign >>> chinese = ['coin', 'string', 'myriad'] # A list literal >>> suits = chinese # Two names refer to the same list remove >>> suits.pop() # Remove and return the final element 'myriad' >>> suits.remove('string') # Remove the first element that equals the argument add >>> suits.append('cup') # Add an element to the end >>> suits.extend(['sword', 'club']) # Add all elements of a sequence to the end replace >>> suits[2] = 'spade' >>> suits[0:2] = ['heart', 'diamond'] # Replace a slice check >>> suits ['heart', 'diamond', 'spade', 'club'] >>> suits is ['heart', 'diamond', 'spade', 'club'] # check for identity False >>> suits == ['heart', 'diamond', 'spade', 'club'] # check for equality True properties >>> dir(suits) ['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort'] Tuple Object Built-in tuple is an immutable sequence, with finite length. >>> code = (\"up\", \"up\", \"down\", \"down\") + (\"left\", \"right\") * 2 >>> len(code) 8 >>> code[3] 'down' >>> code.count(\"down\") 2 >>> code.index(\"left\") 4 properties >>> dir(code) ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__','count', 'index'] Dictionary Object Dictionaries are Python's built-in data type for storing and manipulating correspondence relationships. >>> numerals = {'I': 1.0, 'V': 5, 'X': 10} >>> numerals['I'] = 1 >>> numerals.keys() dict_keys(['I', 'V', 'X']) >>> numerals.values() dict_values([1, 5, 10]) >>> numerals.items() dict_items([('I', 1), ('V', 5), ('X', 10)]) >>> numerals.get('A', 0) 0 >>> numerals.get('V', 0) 5 loop over >>> for k,v in numerals.items(): ... print(k,v) ... I 1 V 5 X 10 construct a dictionary >>> dict([(3, 9), (4, 16), (5, 25)]) {3: 9, 4: 16, 5: 25} >>> {x: x*x for x in range(3,6)} {3: 9, 4: 16, 5: 25} properties >>> dir(numerals) ['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values'] zip >>> numbers = [1, 2, 3] >>> letters = ['a', 'b', 'c'] >>> zipped = zip(numbers, letters) >>> type(zipped) <class 'zip'> >>> dict(zipped) {1: 'a', 2: 'b', 3: 'c'} implementation by function def dictionary(): \"\"\"Return a functional implementation of a dictionary.\"\"\" records = [] def getitem(key): matches = [r for r in records if r[0] == key] if len(matches) == 1: key, value = matches[0] return value def setitem(key, value): nonlocal records non_matches = [r for r in records if r[0] != key] records = non_matches + [[key, value]] def dispatch(message, key=None, value=None): if message == 'getitem': return getitem(key) elif message == 'setitem': setitem(key, value) return dispatch >>> d = dictionary() >>> d('setitem', 3, 9) >>> d('setitem', 4, 16) >>> d('getitem', 3) 9 >>> d('getitem', 4) 16 Class Examples MinList class MinList: \"\"\"A list that can only pop the smallest element \"\"\" def __init__(self): self.items = [] self.size = 0 def append(self, item): \"\"\"Appends an item to the MinList >>> m = MinList() >>> m.append(4) >>> m.append(2) >>> m.size 2 \"\"\" self.items.append(item) self.size += 1 def pop(self): \"\"\" Removes and returns the smallest item from the MinList >>> m = MinList() >>> m.append(4) >>> m.append(1) >>> m.append(5) >>> m.pop() 1 >>> m.size 2 \"\"\" min_out = min(self.items) self.items = [i for i in self.items if i != min_out] self.size -= 1 return min_out Email class Email: \"\"\"Every email object has 3 instance attributes: the message, the sender name, and the recipient name. \"\"\" def __init__(self, msg, sender_name, recipient_name): self.msg = msg self.sender_name = sender_name self.recipient_name = recipient_name class Server: \"\"\"Each Server has an instance attribute clients, which is a dictionary that associates client names with client objects. \"\"\" def __init__(self): self.clients = {} def send(self, email): \"\"\"Take an email and put it in the inbox of the client it is addressed to. \"\"\" client = self.clients[email.recipient_name] client.receive(email) def register_client(self, client, client_name): \"\"\"Takes a client object and client_name and adds them to the clients instance attribute. \"\"\" self.clients[client_name] = client class Client: \"\"\"Every Client has instance attributes name (which is used for addressing emails to the client), server (which is used to send emails out to other clients), and inbox (a list of all emails the client has received). \"\"\" def __init__(self, server, name): self.inbox = [] self.server = server self.name = name self.server.register_client(self, self.name) def compose(self, msg, recipient_name): \"\"\"Send an email with the given message msg to the given recipient client. \"\"\" email = Email(msg, self.name, recipient_name) self.server.send(email) def receive(self, email): \"\"\"Take an email and add it to the inbox of this client. \"\"\" self.inbox.append(email) Pet class Pet(): def __init__(self, name, owner): self.is_alive = True # It's alive!!! self.name = name self.owner = owner def eat(self, thing): print(self.name + \" ate a \" + str(thing) + \"!\") def talk(self): print(self.name) class Dog(Pet): def talk(self): print(self.name + ' says woof!') class Cat(Pet): def __init__(self, name, owner, lives=9): Pet.__init__(self, name, owner) self.lives = lives def talk(self): \"\"\" Print out a cat's greeting. >>> Cat('Thomas', 'Tammy').talk() Thomas says meow! \"\"\" print(self.name + ' says meow!') def lose_life(self): \"\"\"Decrements a cat's life by 1. When lives reaches zero, 'is_alive' becomes False. If this is called after lives has reached zero, print out that the cat has no more lives to lose. \"\"\" if self.lives > 0: self.lives -= 1 if self.lives == 0: self.is_alive = False else: print(\"This cat has no more lives to lose :(\") class NoisyCat(Cat): \"\"\"A Cat that repeats things twice.\"\"\" def __init__(self, name, owner, lives=9): # Is this method necessary? Why or why not? Cat.__init__(self, name, owner, lives) # not necessary because NoisyCat already inherits Cat\u2019s __init__ method def talk(self): \"\"\"Talks twice as much as a regular cat. >>> NoisyCat('Magic', 'James').talk() Magic says meow! Magic says meow! \"\"\" Cat.talk(self) Cat.talk(self) Vending Machine class VendingMachine: \"\"\"A vending machine that vends some product for some price. >>> v = VendingMachine('candy', 10) >>> v.vend() 'Inventory empty. Restocking required.' >>> v.add_funds(15) 'Inventory empty. Restocking required. Here is your $15.' >>> v.restock(2) 'Current candy stock: 2' >>> v.vend() 'You must add $10 more funds.' >>> v.add_funds(7) 'Current balance: $7' >>> v.vend() 'You must add $3 more funds.' >>> v.add_funds(5) 'Current balance: $12' >>> v.vend() 'Here is your candy and $2 change.' >>> v.add_funds(10) 'Current balance: $10' >>> v.vend() 'Here is your candy.' >>> v.add_funds(15) 'Inventory empty. Restocking required. Here is your $15.' >>> w = VendingMachine('soda', 2) >>> w.restock(3) 'Current soda stock: 3' >>> w.restock(3) 'Current soda stock: 6' >>> w.add_funds(2) 'Current balance: $2' >>> w.vend() 'Here is your soda.' \"\"\" def __init__(self, product, price): self.quantity = 0 self.balance = 0 self.product = product self.price = price def add_funds(self, fund): if self.quantity == 0: return 'Inventory empty. Restocking required. Here is your ${0}.'.format(fund) else: self.balance += fund return 'Current balance: ${0}'.format(self.balance) def restock(self, item): self.quantity += item return 'Current {0} stock: {1}'.format(self.product, self.quantity) def vend(self): if self.quantity == 0: return 'Inventory empty. Restocking required.' change = self.balance - self.price if change < 0: return 'You must add ${0} more funds.'.format(-change) elif change == 0: self.quantity -= 1 self.balance -= self.price return 'Here is your {}.'.format(self.product) else: self.quantity -= 1 self.balance = 0 return 'Here is your {} and ${} change.'.format(self.product, change) Mint Coin class Mint: \"\"\"A mint creates coins by stamping on years. The update method sets the mint's stamp to Mint.current_year. >>> mint = Mint() >>> mint.year 2020 >>> dime = mint.create(Dime) >>> dime.year 2020 >>> Mint.current_year = 2100 # Time passes >>> nickel = mint.create(Nickel) >>> nickel.year # The mint has not updated its stamp yet 2020 >>> nickel.worth() # 5 cents + (80 - 50 years) 35 >>> mint.update() # The mint's year is updated to 2100 >>> Mint.current_year = 2175 # More time passes >>> mint.create(Dime).worth() # 10 cents + (75 - 50 years) 35 >>> Mint().create(Dime).worth() # A new mint has the current year 10 >>> dime.worth() # 10 cents + (155 - 50 years) 115 >>> Dime.cents = 20 # Upgrade all dimes! >>> dime.worth() # 20 cents + (155 - 50 years) 125 \"\"\" current_year = 2020 def __init__(self): self.update() def create(self, kind): return kind(self.year) def update(self): self.year = Mint.current_year class Coin: def __init__(self, year): self.year = year def worth(self): year_gap = Mint.current_year - self.year if year_gap > 50: return self.cents + year_gap - 50 else: return self.cents # return max(self.cents,self.cents+Mint.current_year-self.year-50) class Nickel(Coin): cents = 5 class Dime(Coin): cents = 10 Non-Local Statement make adder increasing def make_adder_inc(a): \"\"\" >>> adder1 = make_adder_inc(5) >>> adder2 = make_adder_inc(6) >>> adder1(2) 7 >>> adder1(2) # 5 + 2 + 1 8 >>> adder1(10) # 5 + 10 + 2 17 >>> [adder1(x) for x in [1, 2, 3]] [9, 11, 13] >>> adder2(5) 11 \"\"\" step = 0 def adder(k): nonlocal step step += 1 return a + k + step - 1 return adder next Fibonacci def make_fib(): \"\"\"Returns a function that returns the next Fibonacci number every time it is called. >>> fib = make_fib() >>> fib() 0 >>> fib() 1 >>> fib() 1 >>> fib() 2 >>> fib() 3 >>> fib2 = make_fib() >>> fib() + sum([fib2() for _ in range(5)]) 12 >>> from construct_check import check >>> # Do not use lists in your implementation >>> check(this_file, 'make_fib', ['List']) True \"\"\" x, y = 0, 1 def fib(): nonlocal x, y res = x x, y = y, x + y return res return fib","title":"CS61A-object oriented"},{"location":"CS61A/4-object_oriented/#object-oriented-programming","text":"A method for organizing modular programs Abstraction barriers Bundling together information and related behavior A metaphor for computation using distributed state each object has its own local state each object also know how to change its own local state, based on method calls method calls are messages passed between objects several objects may all be instances of a common type different types may relate to each other Specialized syntax and vocabulary to support this metaphor","title":"Object-Oriented Programming"},{"location":"CS61A/4-object_oriented/#classes-and-objects","text":"A class combines (and abstracts) data and functions An object is an instantiation of a class example String is a built-in class, append is a function Int is a built-in class, + is a function myball = Ball(10.0, 15.0, 0.0, -5.0)","title":"Classes and Objects"},{"location":"CS61A/4-object_oriented/#classes","text":"A class serves as a template for its instances class <name>: <suite> A class statement creates a new class and \\<name> binds that class to in the first frame of the current environment Assignment & def statements in \\<suite> create attributes of the class (not names in frames) When a class is called A new instance of that class is created The __init__ method of the class is called with the new object as its first argument (named self ), along with any additional arguments provided in the call expression class Account: \"\"\"An account has a balance and a holder. All accounts share a common interest rate. >>> a = Account('John') >>> a.holder 'John' >>> a.deposit(100) 100 >>> a.withdraw(90) 10 >>> a.withdraw(90) 'Insufficient funds' >>> a.balance 10 >>> a.interest 0.02 >>> Account.interest = 0.04 >>> a.interest 0.04 \"\"\" interest = 0.02 # A class attribute def __init__(self, account_holder): self.holder = account_holder self.balance = 0 def deposit(self, amount): \"\"\"Add amount to balance.\"\"\" self.balance = self.balance + amount return self.balance def withdraw(self, amount): \"\"\"Subtract amount from balance if funds are available.\"\"\" if amount > self.balance: return 'Insufficient funds' self.balance = self.balance - amount return self.balance __init__ is called a constructor Constructor allocate memory for a Ball object initialize the Ball object with values return address of the Ball object similar to a list","title":"Classes"},{"location":"CS61A/4-object_oriented/#objects","text":"Objects represent information They consist of data and behavior , bundled together to create abstractions Objects can represent things, but also properties, interactions, & processes A type of object is called a class ; classes are first-class values in Python Object-oriented programming: A metaphor for organizing large programs Special syntax that can improve the composition of programs (i.e. . expression) In Python, every value is an object All objects have attributes (named values that are part of the object) use . to designated an attribute of an object A lot of data manipulation happens through object methods (function-valued attributes) can be accessed through . expression date(2021,1,1).strftime('%Y-%M-%d') date(2021,1,1).strftime('%A %B %d') Functions do one thing; objects do many related things","title":"Objects"},{"location":"CS61A/4-object_oriented/#instance","text":"help(isinstance) : Return whether an object is an instance of a class or of a subclass thereof. >>> n = 123 >>> isinstance(n, int) True","title":"Instance"},{"location":"CS61A/4-object_oriented/#methods-and-functions","text":"Python distinguishes between: Functions, which we have been creating since the beginning of the course Bound methods, which couple together a function and the object on which that method will be invoked Object + Function = Bound Method >>> type(Account.deposit) <class 'function'> >>> type(tom_account.deposit) <class 'method'>","title":"Methods and Functions"},{"location":"CS61A/4-object_oriented/#methods","text":"Methods are functions defined in the suite of a class statement Invoking methods All invoked methods have access to the object via the self parameter, and so they can all access and manipulate the object's state Dot notation automatically supplies the first argument to a method Static Method class Math: @staticmethod def square(x): return x*x The decorator @staticmethod allows square to be a regular function, but happen to be grouped in Math class.","title":"Methods"},{"location":"CS61A/4-object_oriented/#dot-expressions","text":"Objects receive messages via dot notation Dot notation accesses attributes of the instance or its class <expression> . <name> The <expression> can be any valid Python expression The <name> must be a simple name Evaluates to the value of the attribute looked up by <name> in the object that is the value of the <expression>","title":"Dot Expressions"},{"location":"CS61A/4-object_oriented/#attributes","text":"Data stored within either an instance or a class Attributes can be accessed using dot notation built-in function getattr Objects are iterable (an interface) if they have an __iter__ method that returns an iterator .","title":"Attributes"},{"location":"CS61A/4-object_oriented/#class-attributes","text":"Class attributes are \"shared\" across all instances of a class because they are attributes of the class, not the instance. class Account: interest = 0.02 # A class attribute def __init__(self, account_holder): self.balance = 0 self.holder = account_holder # Additional methods would be defined here","title":"Class Attributes"},{"location":"CS61A/4-object_oriented/#python-object-system","text":"Functions are objects. Bound methods are also objects: a function that has its first parameter \"self\" already bound to an instance. Dot expression evaluate to bound methods for class attributes that are functions <instance>.<method_name>","title":"Python Object System"},{"location":"CS61A/4-object_oriented/#inheritance","text":"Inheritance is a method for relating classes together. class <name>(<base class>): <suite> Conceptually, the new subclass \"shares\" attributes with its base class. Using inheritance, we implement a subclass by specifying its differences from the base class. class Account: \"\"\"An account has a balance and a holder. >>> a = Account('John') >>> a.holder 'John' >>> a.deposit(100) 100 >>> a.withdraw(90) 10 >>> a.withdraw(90) 'Insufficient funds' >>> a.balance 10 >>> a.interest 0.02 \"\"\" interest = 0.02 # A class attribute def __init__(self, account_holder): self.holder = account_holder self.balance = 0 def deposit(self, amount): \"\"\"Add amount to balance.\"\"\" self.balance = self.balance + amount return self.balance def withdraw(self, amount): \"\"\"Subtract amount from balance if funds are available.\"\"\" if amount > self.balance: return 'Insufficient funds' self.balance = self.balance - amount return self.balance class CheckingAccount(Account): \"\"\"A bank account that charges for withdrawals. >>> ch = CheckingAccount('Jack') >>> ch.balance = 20 >>> ch.withdraw(5) 14 >>> ch.interest 0.01 \"\"\" withdraw_fee = 1 interest = 0.01 def withdraw(self, amount): return Account.withdraw(self, amount + self.withdraw_fee) # Alternatively: return super().withdraw(amount + self.withdraw_fee) class SavingsAccount(Account): \"\"\"A bank account that charges for deposits.\"\"\" deposit_fee = 2 def deposit(self, amount): return Account.deposit(self, amount - self.deposit_fee) The super() function in Python makes class inheritance more manageable and extensible. The function returns a temporary object that allows reference to a parent class.","title":"Inheritance"},{"location":"CS61A/4-object_oriented/#multiple-inheritance","text":"class AsSeenOnTVAccount(CheckingAccount, SavingsAccount): \"\"\"A bank account that charges for everything.\"\"\" def __init__(self, account_holder): self.holder = account_holder self.balance = 1 # A free dollar! results >>> such_a_deal = AsSeenOnTVAccount(\"John\") >>> such_a_deal.balance 1 >>> such_a_deal.deposit(20) 19","title":"Multiple Inheritance"},{"location":"CS61A/4-object_oriented/#inheritance-and-composition","text":"Inheritance is best for representing is-a relationships. E.g., a checking account is a specific type of account So, CheckingAccount inherits from Account Composition is best for representing has-a relationships E.g., a bank has a collection of bank accounts it manages So, A bank has a list of accounts as an attribute composition example class Bank: \"\"\"A bank has accounts and pays interest. >>> bank = Bank() >>> john = bank.open_account('John', 10) >>> jack = bank.open_account('Jack', 5, CheckingAccount) >>> jack.interest 0.01 >>> john.interest = 0.06 >>> bank.pay_interest() >>> john.balance 10.6 >>> jack.balance 5.05 \"\"\" def __init__(self): self.accounts = [] def open_account(self, holder, amount, account_type=Account): \"\"\"Open an account_type for holder and deposit amount.\"\"\" account = account_type(holder) account.deposit(amount) self.accounts.append(account) return account def pay_interest(self): \"\"\"Pay interest to all accounts.\"\"\" for account in self.accounts: account.deposit(account.balance * account.interest)","title":"Inheritance and Composition"},{"location":"CS61A/4-object_oriented/#object-oriented-design","text":"Designing for inheritance -- don't repeat yourself. Attributes that have been overridden are still accessible via class objects.","title":"Object Oriented Design"},{"location":"CS61A/4-object_oriented/#representation","text":"String Representations In Python, all objects produce two string representations: The str is legible to humans The repr is legible to the Python interpreter The str and repr strings are often the same, but not always. str String for an Object The result of calling str on the value of an expression is what Python prints using the print function. >>> from fractions import Fraction >>> half = Fraction(1, 2) >>> repr(half) 'Fraction(1, 2)' >>> str(half) '1/2' >>> print(half) 1/2 repr String for an Object The repr function returns a Python expression (a string) that evaluates to an equal object. repr(object) -> string Return the canonical string representation of the object. For most object types, eval(repr(object)) == object . >>> 12e6 12000000.0 >>> print(repr(12e6)) 12000000.0 Some objects do not have a simple Python-readable string >>> repr(min) '<built-in function min>' eval and repr >>> s = 'Hello, World' >>> s 'Hello, World' >>> print(repr(s)) 'Hello, World' >>> print(s) Hello, World >>> print(str(s)) Hello, World >>> repr(s) \"'Hello, World'\" >>> eval(repr(s)) 'Hello, World' @property decorator allows functions to be called without call expression syntax (parentheses following an expression). >>> from math import atan2 >>> class ComplexRI(Complex): def __init__(self, real, imag): self.real = real self.imag = imag @property def magnitude(self): return (self.real ** 2 + self.imag ** 2) ** 0.5 @property def angle(self): return atan2(self.imag, self.real) def __repr__(self): return 'ComplexRI({0:g}, {1:g})'.format(self.real, self.imag) usage >>> ri = ComplexRI(5, 12) >>> ri.real 5 >>> ri.magnitude 13.0 >>> ri.real = 9 >>> ri.real 9 >>> ri.magnitude 15.0","title":"Representation"},{"location":"CS61A/4-object_oriented/#polymorphic-functions","text":"A function that applies to many (poly) different forms (morph) of data. str and repr are both polymorphic; they apply to any object. repr invokes a zero-argument method __repr__ on its argument. >>> half.__repr__() 'Fraction(1, 2)' str invokes a zero-argument method __str__ on its argument >>> half.__str__() '1/2' Implementation of repr and str The behavior of repr is slightly more complicated than invoking __repr__ on its argument. An instance attribute called __repr__ is ignored! Only class attributes are found. def repr(x): return type(x).__repr__(x) The behavior of str is also complicated. An instance attribute called __str__ is ignored. If no __str__ attribute is found, uses repr string. str is a class, not a function. def str(x): t = type(x) if hasattr(t, '__str__'): return t.__str__(x) else: return repr(x) Example class Bear: \"\"\"A Bear.\"\"\" def __init__(self): self.__repr__ = lambda: 'oski' self.__str__ = lambda: 'this bear' def __repr__(self): return 'Bear()' def __str__(self): return 'a bear' compare >>> oski = Bear() >>> print(oski) a bear >>> print(str(oski)) a bear >>> print(repr(oski)) Bear() >>> print(oski.__str__()) this bear >>> print(oski.__repr__()) oski","title":"Polymorphic Functions"},{"location":"CS61A/4-object_oriented/#interfaces","text":"Message passing : Objects interact by looking up attributes on each other (passing messages). The attribute look-up rules allow different data types to respond to the same message A shared message (attribute name) that elicits similar behavior from different object classes is a powerful method of abstraction. An interface is a set of shared messages , along with a specification of what they mean.","title":"Interfaces"},{"location":"CS61A/4-object_oriented/#special-method-names-in-python","text":"Certain names are special because they have built-in behavior. These names always start and end with two underscores __init__ : Method invoked automatically when an object is constructed. __repr__ : Method invoked to display an object as a Python expression. __add__ : Method invoked to add one object to another. __radd__ = __add__ __bool__ : Method invoked to convert an object to True or False. Account.__bool__ = lambda self: self.balance != 0 __float__ : Method invoked to convert an object to a float (real number).","title":"Special Method Names in Python"},{"location":"CS61A/4-object_oriented/#efficiency-q","text":"Constant Time Increasing n doesn't affect time Logarithmic Time Doubling the input increases the time by a constant C 1024x the input increases the time by only 10 times C i.e. exp_fast Linear Time Doubling the input doubles the time 1024x the input takes 1024x as much time i.e. exp Quadratic Time Functions that process all pairs of values in a sequence of length n take quadratic time i.e. overlap Exponential Time Tree-recursive functions can take exponential time i.e. recursive fib How many calculations to do Fib Tree? def fib(n): if n == 0 or n == 1: return n else: return fib(n-2) + fib(n-1) def count(f): def counted(n): counted.call_count += 1 return f(n) counted.call_count = 0 return counted Memoization Idea: remember the results that have been computed before. def memo(f): cache = {} def memoized(n): if n not in cache: cache[n] = f(n) return cache[n] return memoized Exponentiation def exp(b, n): if n == 0: return 1 else: return b * exp(b, n-1) def exp_fast(b, n): if n == 0: return 1 elif n % 2 == 0: return square(exp_fast(b, n//2)) else: return b * exp_fast(b, n-1) def square(x): return x * x","title":"Efficiency (Q)"},{"location":"CS61A/4-object_oriented/#consumption-of-space","text":"Which environment frames do we need to keep during evaluation? At any moment there is a set of active environments Values and frames in active environments consume memory Memory that is used for other values and frames can be recycled Active environments Environments for any function calls currently being evaluated Parent environments of functions named in active environments","title":"Consumption of Space"},{"location":"CS61A/4-object_oriented/#object-examples","text":"","title":"Object Examples"},{"location":"CS61A/4-object_oriented/#type-dispatching","text":"isinstance() >>> isinstance(123, int) True >>> isinstance(123, str) False >>> isinstance('123', str) True isnumeric() >>> '1234'.isnumeric() True >>> 'xyz'.isnumeric() False >>> '2.0'.isnumeric() False","title":"Type Dispatching"},{"location":"CS61A/4-object_oriented/#date-object","text":">>> from datetime import date, timedelta >>> today = date(2021,2,14) >>> today.year 2021 >>> today.strftime('%A, %B, %d') 'Sunday, February, 14' >>> today + timedelta(days=90) datetime.date(2021, 5, 15) >>> dir(today) ['__add__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__rsub__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', 'ctime', 'day', 'fromisoformat', 'fromordinal', 'fromtimestamp', 'isocalendar', 'isoformat', 'isoweekday', 'max', 'min', 'month', 'replace', 'resolution', 'strftime', 'timetuple', 'today', 'toordinal', 'weekday', 'year']","title":"Date Object"},{"location":"CS61A/4-object_oriented/#string-object","text":">>> 'rOBERT dE nIRO'.swapcase() 'Robert De Niro' >>> 'eyes'.upper().endswith('YES') True >>> dir('x') ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']","title":"String Object"},{"location":"CS61A/4-object_oriented/#sequencelist-object","text":"assign >>> chinese = ['coin', 'string', 'myriad'] # A list literal >>> suits = chinese # Two names refer to the same list remove >>> suits.pop() # Remove and return the final element 'myriad' >>> suits.remove('string') # Remove the first element that equals the argument add >>> suits.append('cup') # Add an element to the end >>> suits.extend(['sword', 'club']) # Add all elements of a sequence to the end replace >>> suits[2] = 'spade' >>> suits[0:2] = ['heart', 'diamond'] # Replace a slice check >>> suits ['heart', 'diamond', 'spade', 'club'] >>> suits is ['heart', 'diamond', 'spade', 'club'] # check for identity False >>> suits == ['heart', 'diamond', 'spade', 'club'] # check for equality True properties >>> dir(suits) ['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']","title":"Sequence/List? Object"},{"location":"CS61A/4-object_oriented/#tuple-object","text":"Built-in tuple is an immutable sequence, with finite length. >>> code = (\"up\", \"up\", \"down\", \"down\") + (\"left\", \"right\") * 2 >>> len(code) 8 >>> code[3] 'down' >>> code.count(\"down\") 2 >>> code.index(\"left\") 4 properties >>> dir(code) ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__','count', 'index']","title":"Tuple Object"},{"location":"CS61A/4-object_oriented/#dictionary-object","text":"Dictionaries are Python's built-in data type for storing and manipulating correspondence relationships. >>> numerals = {'I': 1.0, 'V': 5, 'X': 10} >>> numerals['I'] = 1 >>> numerals.keys() dict_keys(['I', 'V', 'X']) >>> numerals.values() dict_values([1, 5, 10]) >>> numerals.items() dict_items([('I', 1), ('V', 5), ('X', 10)]) >>> numerals.get('A', 0) 0 >>> numerals.get('V', 0) 5 loop over >>> for k,v in numerals.items(): ... print(k,v) ... I 1 V 5 X 10 construct a dictionary >>> dict([(3, 9), (4, 16), (5, 25)]) {3: 9, 4: 16, 5: 25} >>> {x: x*x for x in range(3,6)} {3: 9, 4: 16, 5: 25} properties >>> dir(numerals) ['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values'] zip >>> numbers = [1, 2, 3] >>> letters = ['a', 'b', 'c'] >>> zipped = zip(numbers, letters) >>> type(zipped) <class 'zip'> >>> dict(zipped) {1: 'a', 2: 'b', 3: 'c'} implementation by function def dictionary(): \"\"\"Return a functional implementation of a dictionary.\"\"\" records = [] def getitem(key): matches = [r for r in records if r[0] == key] if len(matches) == 1: key, value = matches[0] return value def setitem(key, value): nonlocal records non_matches = [r for r in records if r[0] != key] records = non_matches + [[key, value]] def dispatch(message, key=None, value=None): if message == 'getitem': return getitem(key) elif message == 'setitem': setitem(key, value) return dispatch >>> d = dictionary() >>> d('setitem', 3, 9) >>> d('setitem', 4, 16) >>> d('getitem', 3) 9 >>> d('getitem', 4) 16","title":"Dictionary Object"},{"location":"CS61A/4-object_oriented/#class-examples","text":"","title":"Class Examples"},{"location":"CS61A/4-object_oriented/#minlist","text":"class MinList: \"\"\"A list that can only pop the smallest element \"\"\" def __init__(self): self.items = [] self.size = 0 def append(self, item): \"\"\"Appends an item to the MinList >>> m = MinList() >>> m.append(4) >>> m.append(2) >>> m.size 2 \"\"\" self.items.append(item) self.size += 1 def pop(self): \"\"\" Removes and returns the smallest item from the MinList >>> m = MinList() >>> m.append(4) >>> m.append(1) >>> m.append(5) >>> m.pop() 1 >>> m.size 2 \"\"\" min_out = min(self.items) self.items = [i for i in self.items if i != min_out] self.size -= 1 return min_out","title":"MinList"},{"location":"CS61A/4-object_oriented/#email","text":"class Email: \"\"\"Every email object has 3 instance attributes: the message, the sender name, and the recipient name. \"\"\" def __init__(self, msg, sender_name, recipient_name): self.msg = msg self.sender_name = sender_name self.recipient_name = recipient_name class Server: \"\"\"Each Server has an instance attribute clients, which is a dictionary that associates client names with client objects. \"\"\" def __init__(self): self.clients = {} def send(self, email): \"\"\"Take an email and put it in the inbox of the client it is addressed to. \"\"\" client = self.clients[email.recipient_name] client.receive(email) def register_client(self, client, client_name): \"\"\"Takes a client object and client_name and adds them to the clients instance attribute. \"\"\" self.clients[client_name] = client class Client: \"\"\"Every Client has instance attributes name (which is used for addressing emails to the client), server (which is used to send emails out to other clients), and inbox (a list of all emails the client has received). \"\"\" def __init__(self, server, name): self.inbox = [] self.server = server self.name = name self.server.register_client(self, self.name) def compose(self, msg, recipient_name): \"\"\"Send an email with the given message msg to the given recipient client. \"\"\" email = Email(msg, self.name, recipient_name) self.server.send(email) def receive(self, email): \"\"\"Take an email and add it to the inbox of this client. \"\"\" self.inbox.append(email)","title":"Email"},{"location":"CS61A/4-object_oriented/#pet","text":"class Pet(): def __init__(self, name, owner): self.is_alive = True # It's alive!!! self.name = name self.owner = owner def eat(self, thing): print(self.name + \" ate a \" + str(thing) + \"!\") def talk(self): print(self.name) class Dog(Pet): def talk(self): print(self.name + ' says woof!') class Cat(Pet): def __init__(self, name, owner, lives=9): Pet.__init__(self, name, owner) self.lives = lives def talk(self): \"\"\" Print out a cat's greeting. >>> Cat('Thomas', 'Tammy').talk() Thomas says meow! \"\"\" print(self.name + ' says meow!') def lose_life(self): \"\"\"Decrements a cat's life by 1. When lives reaches zero, 'is_alive' becomes False. If this is called after lives has reached zero, print out that the cat has no more lives to lose. \"\"\" if self.lives > 0: self.lives -= 1 if self.lives == 0: self.is_alive = False else: print(\"This cat has no more lives to lose :(\") class NoisyCat(Cat): \"\"\"A Cat that repeats things twice.\"\"\" def __init__(self, name, owner, lives=9): # Is this method necessary? Why or why not? Cat.__init__(self, name, owner, lives) # not necessary because NoisyCat already inherits Cat\u2019s __init__ method def talk(self): \"\"\"Talks twice as much as a regular cat. >>> NoisyCat('Magic', 'James').talk() Magic says meow! Magic says meow! \"\"\" Cat.talk(self) Cat.talk(self)","title":"Pet"},{"location":"CS61A/4-object_oriented/#vending-machine","text":"class VendingMachine: \"\"\"A vending machine that vends some product for some price. >>> v = VendingMachine('candy', 10) >>> v.vend() 'Inventory empty. Restocking required.' >>> v.add_funds(15) 'Inventory empty. Restocking required. Here is your $15.' >>> v.restock(2) 'Current candy stock: 2' >>> v.vend() 'You must add $10 more funds.' >>> v.add_funds(7) 'Current balance: $7' >>> v.vend() 'You must add $3 more funds.' >>> v.add_funds(5) 'Current balance: $12' >>> v.vend() 'Here is your candy and $2 change.' >>> v.add_funds(10) 'Current balance: $10' >>> v.vend() 'Here is your candy.' >>> v.add_funds(15) 'Inventory empty. Restocking required. Here is your $15.' >>> w = VendingMachine('soda', 2) >>> w.restock(3) 'Current soda stock: 3' >>> w.restock(3) 'Current soda stock: 6' >>> w.add_funds(2) 'Current balance: $2' >>> w.vend() 'Here is your soda.' \"\"\" def __init__(self, product, price): self.quantity = 0 self.balance = 0 self.product = product self.price = price def add_funds(self, fund): if self.quantity == 0: return 'Inventory empty. Restocking required. Here is your ${0}.'.format(fund) else: self.balance += fund return 'Current balance: ${0}'.format(self.balance) def restock(self, item): self.quantity += item return 'Current {0} stock: {1}'.format(self.product, self.quantity) def vend(self): if self.quantity == 0: return 'Inventory empty. Restocking required.' change = self.balance - self.price if change < 0: return 'You must add ${0} more funds.'.format(-change) elif change == 0: self.quantity -= 1 self.balance -= self.price return 'Here is your {}.'.format(self.product) else: self.quantity -= 1 self.balance = 0 return 'Here is your {} and ${} change.'.format(self.product, change)","title":"Vending Machine"},{"location":"CS61A/4-object_oriented/#mint-coin","text":"class Mint: \"\"\"A mint creates coins by stamping on years. The update method sets the mint's stamp to Mint.current_year. >>> mint = Mint() >>> mint.year 2020 >>> dime = mint.create(Dime) >>> dime.year 2020 >>> Mint.current_year = 2100 # Time passes >>> nickel = mint.create(Nickel) >>> nickel.year # The mint has not updated its stamp yet 2020 >>> nickel.worth() # 5 cents + (80 - 50 years) 35 >>> mint.update() # The mint's year is updated to 2100 >>> Mint.current_year = 2175 # More time passes >>> mint.create(Dime).worth() # 10 cents + (75 - 50 years) 35 >>> Mint().create(Dime).worth() # A new mint has the current year 10 >>> dime.worth() # 10 cents + (155 - 50 years) 115 >>> Dime.cents = 20 # Upgrade all dimes! >>> dime.worth() # 20 cents + (155 - 50 years) 125 \"\"\" current_year = 2020 def __init__(self): self.update() def create(self, kind): return kind(self.year) def update(self): self.year = Mint.current_year class Coin: def __init__(self, year): self.year = year def worth(self): year_gap = Mint.current_year - self.year if year_gap > 50: return self.cents + year_gap - 50 else: return self.cents # return max(self.cents,self.cents+Mint.current_year-self.year-50) class Nickel(Coin): cents = 5 class Dime(Coin): cents = 10","title":"Mint Coin"},{"location":"CS61A/4-object_oriented/#non-local-statement","text":"","title":"Non-Local Statement"},{"location":"CS61A/4-object_oriented/#make-adder-increasing","text":"def make_adder_inc(a): \"\"\" >>> adder1 = make_adder_inc(5) >>> adder2 = make_adder_inc(6) >>> adder1(2) 7 >>> adder1(2) # 5 + 2 + 1 8 >>> adder1(10) # 5 + 10 + 2 17 >>> [adder1(x) for x in [1, 2, 3]] [9, 11, 13] >>> adder2(5) 11 \"\"\" step = 0 def adder(k): nonlocal step step += 1 return a + k + step - 1 return adder","title":"make adder increasing"},{"location":"CS61A/4-object_oriented/#next-fibonacci","text":"def make_fib(): \"\"\"Returns a function that returns the next Fibonacci number every time it is called. >>> fib = make_fib() >>> fib() 0 >>> fib() 1 >>> fib() 1 >>> fib() 2 >>> fib() 3 >>> fib2 = make_fib() >>> fib() + sum([fib2() for _ in range(5)]) 12 >>> from construct_check import check >>> # Do not use lists in your implementation >>> check(this_file, 'make_fib', ['List']) True \"\"\" x, y = 0, 1 def fib(): nonlocal x, y res = x x, y = y, x + y return res return fib","title":"next Fibonacci"},{"location":"CS61A/5-computer_programs/","text":"Computer Programs Functions can be manipulated as data using higher-order functions Data can be endowed with behavior using Message passing & object system. Organizing large programs functional abstraction data abstraction class inheritance generic functions Modular Design Separation of Concerns A design principle: Isolate different parts of a program that address different concerns a modular component can be developed and tested independently. Exceptions A built-in mechanism in a programming language to declare and respond to exceptional conditions Python raises an exception whenever an error occurs Exceptions can be handled by the program, preventing the interpreter from halting Unhandled exceptions will cause Python to halt execution and print a stack trace Exceptions are objects! They have classes with constructors. They enable non-local continuation of control If f calls g and g calls h, exceptions can shift control from h to f without waiting for g to return. (Exception handling tends to be slow.) Raising Exceptions Assert statements raise an exception of type AssertionError: assert <expression>, <string> Assertions are designed to be used liberally. They can be ignored to increase efficiency by running Python with the \"-O\" flag; \"O\" stands for optimized: python3 -O , then you will see >>> __debug__ False >>> assert False, 'Error' Raise statements raise <expression> <expression> must evaluate to a subclass of BaseException or an instance of one Exceptions are constructed like any other object. TypeError -- A function was passed the wrong number/type of argument NameError -- A name wasn't found KeyError -- A key wasn't found in a dictionary RecursionError -- Too many recursive calls >>> raise Exception('An error occurred') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> Exception: an error occurred The interpreter will print a stack backtrace , which is a structured block of text that describes the nested set of active function calls in the branch of execution in which the exception was raised. Handling Exceptions Try statements handle exceptions try: <try suite> except <exception class> as <name>: <except suite> ... Execution rule The <try suite> is executed first If, during the course of executing the <try suite> , an exception is raised that is not handled otherwise, and If the class of the exception inherits from <exception class> , then The <except suite> is executed, with <name> bound to the exception >>> try: ... x = 1/0 ... except ZeroDivisionError as e: ... print('handling a', type(e)) ... x = 0 ... handling a <class 'ZeroDivisionError'> >>> x 0 More examples def invert(x): \"\"\"Return 1/x >>> invert(2) Never printed if x is 0 0.5 \"\"\" result = 1/x # Raises a ZeroDivisionError if x is 0 print('Never printed if x is 0') return result Handle the exception def invert_safe(x): \"\"\"Return 1/x, or the string 'divison by zero' if x is 0. >>> invert_safe(2) Never printed if x is 0 0.5 >>> invert_safe(0) 'division by zero' \"\"\" try: return invert(x) except ZeroDivisionError as e: print('handled', e) return str(e) output >>> invert_safe(0) handled division by zero 'division by zero' why do we get \"division by zero\"? >>> 1/0 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ZeroDivisionError: division by zero Multiple try statements : Control jumps to the except suite of the most recent try statement that handles that type of exception try: ... this line always gets executed .. ... maybe this one too ... except: ... finaly: ... this will always run at the end ... ... usually for realeasing resources ... Scheme (programming language) Scheme is a dialect of Lisp, the second-oldest programming language that is still widely used today. Fundamentals Scheme programs consist of expressions, which can be Primitive expressions: 2, 3.3, true, +, quotient, ... Combinations: (quotient 10 2), (not true), ... Numbers are self-evaluating; symbols are bound to values Call expressions include an operator and 0 or more operands in parentheses Special Forms A combination that is not a call expression is a special form: if expression: (if <predicate> <consequent> <alternative>) and and or : (and <e1> ... <en>) , (or <e1> ... <en>) Binding symbols: (define <symbol> <expression>) New procedures: (define (<symbol> <formal parameters>) <body>) The cond special form that behaves like if-elif-else statements in Python The begin special form combines multiple expressions into one expression The let special form binds symbols to values temporarily ; just for one expression lambda expression Lambda expressions evaluate to anonymous procedures (lambda (<formal-parameters>) <body>) Scheme Lists like Python Linked List. In the late 1950s, computer scientists used confusing names cons : Two-argument procedure that creates a linked list car : Procedure that returns the first element of a list cdr : Procedure that returns the rest of a list nil : The empty list Symbolic Programming Quotation is used to refer to symbols directly in Lisp Quotation can also be applied to combinations to form lists Quasiquotation Programming Languages Machine languages : statements are interpreted by the hardware itself A fixed set of instructions invoke operations implemented by the circuitry of the central processing unit (CPU) Operations refer to specific hardware memory addresses; no abstraction mechanisms High-level languages : statements & expressions are interpreted by another program or compiled (translated) into another language Provide means of abstraction such as naming, function definition, and objects Abstract away system details to be independent of hardware and operating system Metalinguistic Abstraction A powerful form of abstraction is to define a new language that is tailored to a particular type of application or problem domain Type of application : Erlang was designed for concurrent programs. It has built-in elements for expressing concurrent communication. It is used, for example, to implement chat servers with many simultaneous connections Problem domain : The MediaWiki mark-up language was designed for generating static web pages. It has built-in elements for text formatting and cross-page linking. It is used, for example, to create Wikipedia pages A programming language has Syntax : The legal statements and expressions in the language Semantics : The execution/evaluation rule for those statements and expressions To create a new programming language, you either need a: Specification : A document describe the precise syntax and semantics of the language Canonical Implementation : An interpreter or compiler for the language Parsing A Parser takes text and returns an expression. Text -- Lexical Analysis -- Tokens -- Syntactic Analysis -- Expression Lexical Analysis Iterative process Checks for malformed tokens Determines types of tokens Processes one line at a time Syntactic Analysis Tree-recursive process Balances parentheses Returns tree structure Processes multiple lines Syntactic Analysis Syntactic analysis identifies the hierarchical structure of an expression, which may be nested. Each call to scheme_read consumes the input tokens for exactly one expression. Base case : symbols and numbers Recursive call : scheme_read sub-expressions and combine them Scheme expressions are represented as Scheme lists. Homoiconic means source code is data. Evaluation The Eval Function The eval function computes the value of an expression, which is always a number. It is a generic function that dispatches on the type of the expression (primitive or call). Primitive : a number evaluates... to itself Call : a call expression evaluates... to its argument values combined by an operator def calc_eval(exp): if type(exp) in (int, float): return exp elif isinstance(exp, Pair): arguments = exp.second.map(calc_eval) return calc_apply(exp.first, arguments) else: raise TypeError def calc_apply(operator, args): if operator == '+': return reduce(add, args, 0) elif operator == '-': ... elif operator == '*': ... elif operator == '/': ... else: raise TypeError Interactive Interpreters Read-Eval-Print Loop The user interface for many programming languages is an interactive interpreter Print a prompt Read text input from the user Parse the text input into an expression Evaluate the expression If any errors occur, report those errors, otherwise Print the value of the expression and repeat Raising Exceptions Exceptions are raised within lexical analysis, syntactic analysis, eval, and apply. Lexical analysis : The token 2.3.4 raises ValueError(\"invalid numeral\") Syntactic analysis : An extra ) raises SyntaxError(\"unexpected token\") Eval : An empty combination raises TypeError(\"() is not a number or call expression\") Apply : No arguments to - raises TypeError(\"- requires at least 1 argument\") Handling Exceptions An interactive interpreter prints information about each error. A well-designed interactive interpreter should not halt completely on an error, so that the user has an opportunity to try again in the current environment. Interpreters The Structure of an Interpreter Eval Base cases Primitive values (numbers) Look up values bound to symbols Recursive calls Eval(operator, operands) of call expressions \u2022 Apply(procedure, arguments) Eval(sub-expressions) of special forms Requires an environment for symbol lookup Apply Base cases Built-in primitive procedures Recursive calls Eval(body) of user-defined procedures Creates a new environment each time a user-defined procedure is applied Logical Forms if and / or cond Quotation The quote special form evaluates to the quoted expression, which is not evaluated Lambda Expressions Lambda expressions evaluate to user-defined procedures Define Define binds a symbol to a value in the first frame of the current environment. Evaluate the <expression> Bind <name> to its value in the current frame Declarative Programming Database Management Systems Database management systems (DBMS) are important, heavily used, and interesting! A table is a collection of records, which are rows that have a value for each column The Structured Query Language (SQL) is perhaps the most widely used declarative programming language Declarative vs Imperative Declarative Languages such as SQL & Prolog A \"program\" is a description of the desired result The interpreter figures out how to generate the result Imperative Languages such as Python & Scheme A \"program\" is a description of computational processes The interpreter carries out execution/evaluation rules Binary Numbers 2-levels are reliable for fluctuations (imagining how to distinguish water level) Negative Numbers -- Two's Complement start with an unsigned 4-bit binary number where leftmost bit is 0 0110 = 6 complement your binary number (flip bits) 1001 add one to your binary number 1010 = -6 solve the problem of summation of negative and positive numbers in base 2 n-bit signed binary numbers -2^(n-1) ... 2^(n-1) -1 Fraction Numbers \u00b1 mantissa x base ^ (\u00b1 exponent) Boolean Logic -- Building Gates AND (sequential) OR (parallel) NOT (resistor) A circuit is a collection of logical gates that transforms a set of binary inputs into a set of binary outputs. Examples Restaurant def search(query, ranking=lambda r: -r.stars): results = [r for r in Restaurant.all if query in r.name] return sorted(results, key=ranking) def num_shared_reviewers(restaurant, other): # return fast_overlap(restaurant.reviewers, other.reviewers) return len([r for r in restaurant.reviewers if r in other.reviewers]) class Restaurant: \"\"\"A restaurant.\"\"\" all = [] def __init__(self, name, stars, reviewers): self.name = name self.stars = stars self.reviewers = reviewers Restaurant.all.append(self) def similar(self, k, similarity=num_shared_reviewers): \"Return the K most similar restaurants to SELF, using SIMILARITY for comparison.\" others = list(Restaurant.all) others.remove(self) return sorted(others, key=lambda r: -similarity(self, r))[:k] def __repr__(self): return '<' + self.name + '>' load data import json def load_reviews(reviews_file): reviewers_by_restaurant = {} for line in open(reviews_file): r = json.loads(line) business_id = r['business_id'] if business_id not in reviewers_by_restaurant: reviewers_by_restaurant[business_id] = [] reviewers_by_restaurant[business_id].append(r['user_id']) return reviewers_by_restaurant def load_restaurants(reviewers_by_restaurant, restaurants_file): for line in open(restaurants_file): b = json.loads(line) reviewers = reviewers_by_restaurant.get(b['business_id'], []) Restaurant(b['name'], b['stars'], sorted(reviewers)) load_restaurants(load_reviews('reviews.json'), 'restaurants.json') improve speed def fast_overlap(s, t): \"\"\"Return the overlap between sorted S and sorted T. >>> fast_overlap([2, 3, 5, 6, 7], [1, 4, 5, 6, 7, 8]) 3 \"\"\" count, i, j = 0, 0, 0 while i < len(s) and j < len(t): if s[i] == t[j]: count, i, j = count + 1, i + 1, j + 1 elif s[i] < t[j]: i += 1 else: j += 1 return count SQL - Python import sqlite3 # SQL Intro db = sqlite3.Connection(\"nums.db\") db.execute(\"CREATE TABLE nums AS SELECT 2 as n UNION SELECT 3;\") db.execute(\"INSERT INTO nums VALUES (?), (?), (?);\", range(4, 7)) print(db.execute(\"SELECT * FROM nums;\").fetchall()) db.commit() db.commit() will create nums.db Next time, execute sqlite3 n.db from command line SQL Injection import readline import sqlite3 db = sqlite3.Connection(\":memory:\") db.execute(\"CREATE TABLE Students(name);\") db.execute(\"INSERT INTO Students VALUES ('John');\") def add_name(name): cmd = \"INSERT INTO Students VALUES ('\" + name + \"');\" print(\"Executing:\", cmd) db.executescript(cmd) print(\"Students:\", db.execute(\"select * from Students\").fetchall()) def add_name_safe(name): db.execute(\"INSERT INTO Students VALUES (?)\", [name]) print(\"Students:\", db.execute(\"select * from Students\").fetchall()) add_name_safe(\"Jack\") add_name_safe(\"Jill\") add_name_safe(\"Robert'); DROP TABLE Students; --\"); BlackJack import random import readline import sqlite3 points = {'A': 1, 'J': 10, 'Q': 10, 'K':10} points.update({n: n for n in range(2, 11)}) def hand_score(hand): \"\"\"Total score for a hand.\"\"\" total = sum([points[card] for card in hand]) if total <= 11 and 'A' in hand: return total + 10 return total db = sqlite3.Connection('cards.db') sql = db.execute sql('DROP TABLE IF EXISTS cards') sql('CREATE TABLE cards(card, place);') def play(card, place): \"\"\"Play a card so that the player can see it.\"\"\" sql('INSERT INTO cards VALUES (?, ?)', (card, place)) db.commit() def score(who): \"\"\"Compute the hand score for the player or dealer.\"\"\" cards = sql('SELECT * from cards where place = ?;', [who]) return hand_score([card for card, place in cards.fetchall()]) def bust(who): \"\"\"Check if the player or dealer went bust.\"\"\" return score(who) > 21 player, dealer = \"Player\", \"Dealer\" def play_hand(deck): \"\"\"Play a hand of Blackjack.\"\"\" play(deck.pop(), player) play(deck.pop(), dealer) play(deck.pop(), player) hidden = deck.pop() while 'y' in input(\"Hit? \").lower(): play(deck.pop(), player) if bust(player): print(player, \"went bust!\") return play(hidden, dealer) while score(dealer) < 17: play(deck.pop(), dealer) if bust(dealer): print(dealer, \"went bust!\") return print(player, score(player), \"and\", dealer, score(dealer)) deck = list(points.keys()) * 4 random.shuffle(deck) while len(deck) > 10: print('\\nDealing...') play_hand(deck) sql('UPDATE cards SET place=\"Discard\";')","title":"CS61A-computer programs"},{"location":"CS61A/5-computer_programs/#computer-programs","text":"Functions can be manipulated as data using higher-order functions Data can be endowed with behavior using Message passing & object system. Organizing large programs functional abstraction data abstraction class inheritance generic functions","title":"Computer Programs"},{"location":"CS61A/5-computer_programs/#modular-design","text":"Separation of Concerns A design principle: Isolate different parts of a program that address different concerns a modular component can be developed and tested independently.","title":"Modular Design"},{"location":"CS61A/5-computer_programs/#exceptions","text":"A built-in mechanism in a programming language to declare and respond to exceptional conditions Python raises an exception whenever an error occurs Exceptions can be handled by the program, preventing the interpreter from halting Unhandled exceptions will cause Python to halt execution and print a stack trace Exceptions are objects! They have classes with constructors. They enable non-local continuation of control If f calls g and g calls h, exceptions can shift control from h to f without waiting for g to return. (Exception handling tends to be slow.) Raising Exceptions Assert statements raise an exception of type AssertionError: assert <expression>, <string> Assertions are designed to be used liberally. They can be ignored to increase efficiency by running Python with the \"-O\" flag; \"O\" stands for optimized: python3 -O , then you will see >>> __debug__ False >>> assert False, 'Error' Raise statements raise <expression> <expression> must evaluate to a subclass of BaseException or an instance of one Exceptions are constructed like any other object. TypeError -- A function was passed the wrong number/type of argument NameError -- A name wasn't found KeyError -- A key wasn't found in a dictionary RecursionError -- Too many recursive calls >>> raise Exception('An error occurred') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> Exception: an error occurred The interpreter will print a stack backtrace , which is a structured block of text that describes the nested set of active function calls in the branch of execution in which the exception was raised. Handling Exceptions Try statements handle exceptions try: <try suite> except <exception class> as <name>: <except suite> ... Execution rule The <try suite> is executed first If, during the course of executing the <try suite> , an exception is raised that is not handled otherwise, and If the class of the exception inherits from <exception class> , then The <except suite> is executed, with <name> bound to the exception >>> try: ... x = 1/0 ... except ZeroDivisionError as e: ... print('handling a', type(e)) ... x = 0 ... handling a <class 'ZeroDivisionError'> >>> x 0 More examples def invert(x): \"\"\"Return 1/x >>> invert(2) Never printed if x is 0 0.5 \"\"\" result = 1/x # Raises a ZeroDivisionError if x is 0 print('Never printed if x is 0') return result Handle the exception def invert_safe(x): \"\"\"Return 1/x, or the string 'divison by zero' if x is 0. >>> invert_safe(2) Never printed if x is 0 0.5 >>> invert_safe(0) 'division by zero' \"\"\" try: return invert(x) except ZeroDivisionError as e: print('handled', e) return str(e) output >>> invert_safe(0) handled division by zero 'division by zero' why do we get \"division by zero\"? >>> 1/0 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ZeroDivisionError: division by zero Multiple try statements : Control jumps to the except suite of the most recent try statement that handles that type of exception try: ... this line always gets executed .. ... maybe this one too ... except: ... finaly: ... this will always run at the end ... ... usually for realeasing resources ...","title":"Exceptions"},{"location":"CS61A/5-computer_programs/#scheme-programming-language","text":"Scheme is a dialect of Lisp, the second-oldest programming language that is still widely used today. Fundamentals Scheme programs consist of expressions, which can be Primitive expressions: 2, 3.3, true, +, quotient, ... Combinations: (quotient 10 2), (not true), ... Numbers are self-evaluating; symbols are bound to values Call expressions include an operator and 0 or more operands in parentheses Special Forms A combination that is not a call expression is a special form: if expression: (if <predicate> <consequent> <alternative>) and and or : (and <e1> ... <en>) , (or <e1> ... <en>) Binding symbols: (define <symbol> <expression>) New procedures: (define (<symbol> <formal parameters>) <body>) The cond special form that behaves like if-elif-else statements in Python The begin special form combines multiple expressions into one expression The let special form binds symbols to values temporarily ; just for one expression lambda expression Lambda expressions evaluate to anonymous procedures (lambda (<formal-parameters>) <body>) Scheme Lists like Python Linked List. In the late 1950s, computer scientists used confusing names cons : Two-argument procedure that creates a linked list car : Procedure that returns the first element of a list cdr : Procedure that returns the rest of a list nil : The empty list Symbolic Programming Quotation is used to refer to symbols directly in Lisp Quotation can also be applied to combinations to form lists Quasiquotation","title":"Scheme (programming language)"},{"location":"CS61A/5-computer_programs/#programming-languages","text":"Machine languages : statements are interpreted by the hardware itself A fixed set of instructions invoke operations implemented by the circuitry of the central processing unit (CPU) Operations refer to specific hardware memory addresses; no abstraction mechanisms High-level languages : statements & expressions are interpreted by another program or compiled (translated) into another language Provide means of abstraction such as naming, function definition, and objects Abstract away system details to be independent of hardware and operating system Metalinguistic Abstraction A powerful form of abstraction is to define a new language that is tailored to a particular type of application or problem domain Type of application : Erlang was designed for concurrent programs. It has built-in elements for expressing concurrent communication. It is used, for example, to implement chat servers with many simultaneous connections Problem domain : The MediaWiki mark-up language was designed for generating static web pages. It has built-in elements for text formatting and cross-page linking. It is used, for example, to create Wikipedia pages A programming language has Syntax : The legal statements and expressions in the language Semantics : The execution/evaluation rule for those statements and expressions To create a new programming language, you either need a: Specification : A document describe the precise syntax and semantics of the language Canonical Implementation : An interpreter or compiler for the language","title":"Programming Languages"},{"location":"CS61A/5-computer_programs/#parsing","text":"A Parser takes text and returns an expression. Text -- Lexical Analysis -- Tokens -- Syntactic Analysis -- Expression Lexical Analysis Iterative process Checks for malformed tokens Determines types of tokens Processes one line at a time Syntactic Analysis Tree-recursive process Balances parentheses Returns tree structure Processes multiple lines Syntactic Analysis Syntactic analysis identifies the hierarchical structure of an expression, which may be nested. Each call to scheme_read consumes the input tokens for exactly one expression. Base case : symbols and numbers Recursive call : scheme_read sub-expressions and combine them Scheme expressions are represented as Scheme lists. Homoiconic means source code is data.","title":"Parsing"},{"location":"CS61A/5-computer_programs/#evaluation","text":"The Eval Function The eval function computes the value of an expression, which is always a number. It is a generic function that dispatches on the type of the expression (primitive or call). Primitive : a number evaluates... to itself Call : a call expression evaluates... to its argument values combined by an operator def calc_eval(exp): if type(exp) in (int, float): return exp elif isinstance(exp, Pair): arguments = exp.second.map(calc_eval) return calc_apply(exp.first, arguments) else: raise TypeError def calc_apply(operator, args): if operator == '+': return reduce(add, args, 0) elif operator == '-': ... elif operator == '*': ... elif operator == '/': ... else: raise TypeError","title":"Evaluation"},{"location":"CS61A/5-computer_programs/#interactive-interpreters","text":"Read-Eval-Print Loop The user interface for many programming languages is an interactive interpreter Print a prompt Read text input from the user Parse the text input into an expression Evaluate the expression If any errors occur, report those errors, otherwise Print the value of the expression and repeat Raising Exceptions Exceptions are raised within lexical analysis, syntactic analysis, eval, and apply. Lexical analysis : The token 2.3.4 raises ValueError(\"invalid numeral\") Syntactic analysis : An extra ) raises SyntaxError(\"unexpected token\") Eval : An empty combination raises TypeError(\"() is not a number or call expression\") Apply : No arguments to - raises TypeError(\"- requires at least 1 argument\") Handling Exceptions An interactive interpreter prints information about each error. A well-designed interactive interpreter should not halt completely on an error, so that the user has an opportunity to try again in the current environment.","title":"Interactive Interpreters"},{"location":"CS61A/5-computer_programs/#interpreters","text":"The Structure of an Interpreter Eval Base cases Primitive values (numbers) Look up values bound to symbols Recursive calls Eval(operator, operands) of call expressions \u2022 Apply(procedure, arguments) Eval(sub-expressions) of special forms Requires an environment for symbol lookup Apply Base cases Built-in primitive procedures Recursive calls Eval(body) of user-defined procedures Creates a new environment each time a user-defined procedure is applied Logical Forms if and / or cond Quotation The quote special form evaluates to the quoted expression, which is not evaluated Lambda Expressions Lambda expressions evaluate to user-defined procedures Define Define binds a symbol to a value in the first frame of the current environment. Evaluate the <expression> Bind <name> to its value in the current frame","title":"Interpreters"},{"location":"CS61A/5-computer_programs/#declarative-programming","text":"Database Management Systems Database management systems (DBMS) are important, heavily used, and interesting! A table is a collection of records, which are rows that have a value for each column The Structured Query Language (SQL) is perhaps the most widely used declarative programming language Declarative vs Imperative Declarative Languages such as SQL & Prolog A \"program\" is a description of the desired result The interpreter figures out how to generate the result Imperative Languages such as Python & Scheme A \"program\" is a description of computational processes The interpreter carries out execution/evaluation rules","title":"Declarative Programming"},{"location":"CS61A/5-computer_programs/#binary-numbers","text":"2-levels are reliable for fluctuations (imagining how to distinguish water level) Negative Numbers -- Two's Complement start with an unsigned 4-bit binary number where leftmost bit is 0 0110 = 6 complement your binary number (flip bits) 1001 add one to your binary number 1010 = -6 solve the problem of summation of negative and positive numbers in base 2 n-bit signed binary numbers -2^(n-1) ... 2^(n-1) -1 Fraction Numbers \u00b1 mantissa x base ^ (\u00b1 exponent) Boolean Logic -- Building Gates AND (sequential) OR (parallel) NOT (resistor) A circuit is a collection of logical gates that transforms a set of binary inputs into a set of binary outputs.","title":"Binary Numbers"},{"location":"CS61A/5-computer_programs/#examples","text":"","title":"Examples"},{"location":"CS61A/5-computer_programs/#restaurant","text":"def search(query, ranking=lambda r: -r.stars): results = [r for r in Restaurant.all if query in r.name] return sorted(results, key=ranking) def num_shared_reviewers(restaurant, other): # return fast_overlap(restaurant.reviewers, other.reviewers) return len([r for r in restaurant.reviewers if r in other.reviewers]) class Restaurant: \"\"\"A restaurant.\"\"\" all = [] def __init__(self, name, stars, reviewers): self.name = name self.stars = stars self.reviewers = reviewers Restaurant.all.append(self) def similar(self, k, similarity=num_shared_reviewers): \"Return the K most similar restaurants to SELF, using SIMILARITY for comparison.\" others = list(Restaurant.all) others.remove(self) return sorted(others, key=lambda r: -similarity(self, r))[:k] def __repr__(self): return '<' + self.name + '>' load data import json def load_reviews(reviews_file): reviewers_by_restaurant = {} for line in open(reviews_file): r = json.loads(line) business_id = r['business_id'] if business_id not in reviewers_by_restaurant: reviewers_by_restaurant[business_id] = [] reviewers_by_restaurant[business_id].append(r['user_id']) return reviewers_by_restaurant def load_restaurants(reviewers_by_restaurant, restaurants_file): for line in open(restaurants_file): b = json.loads(line) reviewers = reviewers_by_restaurant.get(b['business_id'], []) Restaurant(b['name'], b['stars'], sorted(reviewers)) load_restaurants(load_reviews('reviews.json'), 'restaurants.json') improve speed def fast_overlap(s, t): \"\"\"Return the overlap between sorted S and sorted T. >>> fast_overlap([2, 3, 5, 6, 7], [1, 4, 5, 6, 7, 8]) 3 \"\"\" count, i, j = 0, 0, 0 while i < len(s) and j < len(t): if s[i] == t[j]: count, i, j = count + 1, i + 1, j + 1 elif s[i] < t[j]: i += 1 else: j += 1 return count","title":"Restaurant"},{"location":"CS61A/5-computer_programs/#sql-python","text":"import sqlite3 # SQL Intro db = sqlite3.Connection(\"nums.db\") db.execute(\"CREATE TABLE nums AS SELECT 2 as n UNION SELECT 3;\") db.execute(\"INSERT INTO nums VALUES (?), (?), (?);\", range(4, 7)) print(db.execute(\"SELECT * FROM nums;\").fetchall()) db.commit() db.commit() will create nums.db Next time, execute sqlite3 n.db from command line","title":"SQL - Python"},{"location":"CS61A/5-computer_programs/#sql-injection","text":"import readline import sqlite3 db = sqlite3.Connection(\":memory:\") db.execute(\"CREATE TABLE Students(name);\") db.execute(\"INSERT INTO Students VALUES ('John');\") def add_name(name): cmd = \"INSERT INTO Students VALUES ('\" + name + \"');\" print(\"Executing:\", cmd) db.executescript(cmd) print(\"Students:\", db.execute(\"select * from Students\").fetchall()) def add_name_safe(name): db.execute(\"INSERT INTO Students VALUES (?)\", [name]) print(\"Students:\", db.execute(\"select * from Students\").fetchall()) add_name_safe(\"Jack\") add_name_safe(\"Jill\") add_name_safe(\"Robert'); DROP TABLE Students; --\");","title":"SQL Injection"},{"location":"CS61A/5-computer_programs/#blackjack","text":"import random import readline import sqlite3 points = {'A': 1, 'J': 10, 'Q': 10, 'K':10} points.update({n: n for n in range(2, 11)}) def hand_score(hand): \"\"\"Total score for a hand.\"\"\" total = sum([points[card] for card in hand]) if total <= 11 and 'A' in hand: return total + 10 return total db = sqlite3.Connection('cards.db') sql = db.execute sql('DROP TABLE IF EXISTS cards') sql('CREATE TABLE cards(card, place);') def play(card, place): \"\"\"Play a card so that the player can see it.\"\"\" sql('INSERT INTO cards VALUES (?, ?)', (card, place)) db.commit() def score(who): \"\"\"Compute the hand score for the player or dealer.\"\"\" cards = sql('SELECT * from cards where place = ?;', [who]) return hand_score([card for card, place in cards.fetchall()]) def bust(who): \"\"\"Check if the player or dealer went bust.\"\"\" return score(who) > 21 player, dealer = \"Player\", \"Dealer\" def play_hand(deck): \"\"\"Play a hand of Blackjack.\"\"\" play(deck.pop(), player) play(deck.pop(), dealer) play(deck.pop(), player) hidden = deck.pop() while 'y' in input(\"Hit? \").lower(): play(deck.pop(), player) if bust(player): print(player, \"went bust!\") return play(hidden, dealer) while score(dealer) < 17: play(deck.pop(), dealer) if bust(dealer): print(dealer, \"went bust!\") return print(player, score(player), \"and\", dealer, score(dealer)) deck = list(points.keys()) * 4 random.shuffle(deck) while len(deck) > 10: print('\\nDealing...') play_hand(deck) sql('UPDATE cards SET place=\"Discard\";')","title":"BlackJack"},{"location":"CS61A/ex-function/","text":"Function basic def signum(x): return 1 if x > 0 else -1 if x < 0 else 0 series def series(x, N): if N == 1: return x else: return N * x**N + series(x, N-1) default value def pressure(v, t, n=6.022e23): \"\"\"Compute the pressure in pascals of an ideal gas. v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas (default: one mole) \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v Lambda Function >>> square = lambda x: x * x >>> square(10) 100 >>> (lambda x: x * x)(3) 9 Newton's Method def newton_update(f, df): def update(x): return x - f(x) / df(x) return update def find_zero(f, df): def near_zero(x): return approx_eq(f(x), 0) return improve(newton_update(f, df), near_zero) def square_root_newton(a): def f(x): return x * x - a def df(x): return 2 * x return find_zero(f, df) def power(x, n): \"\"\"Return x * x * x * ... * x for x repeated n times.\"\"\" product, k = 1, 0 while k < n: product, k = product * x, k + 1 return product def nth_root_of_a(n, a): def f(x): return power(x, n) - a def df(x): return n * power(x, n-1) return find_zero(f, df) anonymous function from operator import sub, mul def make_anonymous_factorial(): \"\"\"Return the value of an expression that computes factorial. >>> make_anonymous_factorial()(5) 120 >>> from construct_check import check >>> # ban any assignments or recursion >>> check(HW_SOURCE_FILE, 'make_anonymous_factorial', ['Assign', 'AugAssign', 'FunctionDef', 'Recursion']) True \"\"\" return lambda x: (lambda f: f(f, x))(lambda f, n: 1 if n == 1 else mul(n, f(f, sub(n, 1)))) intersection of sorted list def fast_overlap(s, t): \"\"\"Return the overlap between sorted S and sorted T. >>> fast_overlap([2, 3, 5, 6, 7], [1, 4, 5, 6, 7, 8]) 3 \"\"\" count, i, j = 0, 0, 0 while i < len(s) and j < len(t): if s[i] == t[j]: count, i, j = count + 1, i + 1, j + 1 elif s[i] < t[j]: i += 1 else: j += 1 return count Higher-Order Function function repeater take in a one-argument function f and an integer x return another function which takes in one argument, another integer. This function returns the result of applying f to x this number of times. def make_func_repeater(f, x): def repeat(i): if i == 0: return i else: return f(repeat(i-1)) return repeat cycle functions n = 0 , return x n = 1 , apply f1 to x , or return f1(x) n = 2 , apply f1 to x and then f2 to the result of that, or return f2(f1(x)) n = 3 , apply f1 to x , f2 to the result of applying f1 , and then f3 to the result of applying f2 , or f3(f2(f1(x))) n = 4 , start the cycle again applying f1 , then f2 , then f3 , then f1 again, or f1(f3(f2(f1(x)))) And so forth. def cycle(f1, f2, f3): \"\"\"Returns a function that is itself a higher-order function. >>> def add1(x): ... return x + 1 >>> def times2(x): ... return x * 2 >>> def add3(x): ... return x + 3 >>> my_cycle = cycle(add1, times2, add3) >>> identity = my_cycle(0) >>> identity(5) 5 >>> add_one_then_double = my_cycle(2) >>> add_one_then_double(1) 4 >>> do_all_functions = my_cycle(3) >>> do_all_functions(2) 9 >>> do_more_than_a_cycle = my_cycle(4) >>> do_more_than_a_cycle(2) 10 >>> do_two_cycles = my_cycle(6) >>> do_two_cycles(1) 19 \"\"\" def cycle_n_times(n): def calculate(x): i = 0 while i < n: if i % 3 == 0: x = f1(x) elif i % 3 == 1: x = f2(x) elif i % 3 == 2: x = f3(x) i += 1 return x return calculate return cycle_n_times Divide and Conquer Tower of Hanoi def move_disk(disk_number, from_peg, to_peg): print(\"Move disk \" + str(dis_number) + \"from peg \" + from_peg + \"to peg \" + str(to_peg) + '.') def solve_hanoi(n, start_peg, end_peg): if n == 1: move_disk(n, start_peg, end_peg) else: spare_peg = 6 - start_peg - end_peg solve_hanoi(n-1, start_peg, spare_peg) move_disk(n, start_peg, end_peg) solve_hanoi(n-1, spare_peg, end_peg) walkthrough hanoi(3,1,2) hanoi(2,1,3) hanoi(1,1,2) move(2,1,3) solve(1,2,3) move_disk(3,1,2) hanoi(2,3,2) hanoi(1,3,1) move(2,3,2) hanoi(1,1,2) disc move - exponential growth 1 1 2 3 3 7 4 15 ... n solve (n-1) twice + 1","title":"function"},{"location":"CS61A/ex-function/#function","text":"","title":"Function"},{"location":"CS61A/ex-function/#basic","text":"def signum(x): return 1 if x > 0 else -1 if x < 0 else 0","title":"basic"},{"location":"CS61A/ex-function/#series","text":"def series(x, N): if N == 1: return x else: return N * x**N + series(x, N-1)","title":"series"},{"location":"CS61A/ex-function/#default-value","text":"def pressure(v, t, n=6.022e23): \"\"\"Compute the pressure in pascals of an ideal gas. v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas (default: one mole) \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v","title":"default value"},{"location":"CS61A/ex-function/#lambda-function","text":">>> square = lambda x: x * x >>> square(10) 100 >>> (lambda x: x * x)(3) 9","title":"Lambda Function"},{"location":"CS61A/ex-function/#newtons-method","text":"def newton_update(f, df): def update(x): return x - f(x) / df(x) return update def find_zero(f, df): def near_zero(x): return approx_eq(f(x), 0) return improve(newton_update(f, df), near_zero) def square_root_newton(a): def f(x): return x * x - a def df(x): return 2 * x return find_zero(f, df) def power(x, n): \"\"\"Return x * x * x * ... * x for x repeated n times.\"\"\" product, k = 1, 0 while k < n: product, k = product * x, k + 1 return product def nth_root_of_a(n, a): def f(x): return power(x, n) - a def df(x): return n * power(x, n-1) return find_zero(f, df)","title":"Newton's Method"},{"location":"CS61A/ex-function/#anonymous-function","text":"from operator import sub, mul def make_anonymous_factorial(): \"\"\"Return the value of an expression that computes factorial. >>> make_anonymous_factorial()(5) 120 >>> from construct_check import check >>> # ban any assignments or recursion >>> check(HW_SOURCE_FILE, 'make_anonymous_factorial', ['Assign', 'AugAssign', 'FunctionDef', 'Recursion']) True \"\"\" return lambda x: (lambda f: f(f, x))(lambda f, n: 1 if n == 1 else mul(n, f(f, sub(n, 1))))","title":"anonymous function"},{"location":"CS61A/ex-function/#intersection-of-sorted-list","text":"def fast_overlap(s, t): \"\"\"Return the overlap between sorted S and sorted T. >>> fast_overlap([2, 3, 5, 6, 7], [1, 4, 5, 6, 7, 8]) 3 \"\"\" count, i, j = 0, 0, 0 while i < len(s) and j < len(t): if s[i] == t[j]: count, i, j = count + 1, i + 1, j + 1 elif s[i] < t[j]: i += 1 else: j += 1 return count","title":"intersection of sorted list"},{"location":"CS61A/ex-function/#higher-order-function","text":"","title":"Higher-Order Function"},{"location":"CS61A/ex-function/#function-repeater","text":"take in a one-argument function f and an integer x return another function which takes in one argument, another integer. This function returns the result of applying f to x this number of times. def make_func_repeater(f, x): def repeat(i): if i == 0: return i else: return f(repeat(i-1)) return repeat","title":"function repeater"},{"location":"CS61A/ex-function/#cycle-functions","text":"n = 0 , return x n = 1 , apply f1 to x , or return f1(x) n = 2 , apply f1 to x and then f2 to the result of that, or return f2(f1(x)) n = 3 , apply f1 to x , f2 to the result of applying f1 , and then f3 to the result of applying f2 , or f3(f2(f1(x))) n = 4 , start the cycle again applying f1 , then f2 , then f3 , then f1 again, or f1(f3(f2(f1(x)))) And so forth. def cycle(f1, f2, f3): \"\"\"Returns a function that is itself a higher-order function. >>> def add1(x): ... return x + 1 >>> def times2(x): ... return x * 2 >>> def add3(x): ... return x + 3 >>> my_cycle = cycle(add1, times2, add3) >>> identity = my_cycle(0) >>> identity(5) 5 >>> add_one_then_double = my_cycle(2) >>> add_one_then_double(1) 4 >>> do_all_functions = my_cycle(3) >>> do_all_functions(2) 9 >>> do_more_than_a_cycle = my_cycle(4) >>> do_more_than_a_cycle(2) 10 >>> do_two_cycles = my_cycle(6) >>> do_two_cycles(1) 19 \"\"\" def cycle_n_times(n): def calculate(x): i = 0 while i < n: if i % 3 == 0: x = f1(x) elif i % 3 == 1: x = f2(x) elif i % 3 == 2: x = f3(x) i += 1 return x return calculate return cycle_n_times","title":"cycle functions"},{"location":"CS61A/ex-function/#divide-and-conquer","text":"","title":"Divide and Conquer"},{"location":"CS61A/ex-function/#tower-of-hanoi","text":"def move_disk(disk_number, from_peg, to_peg): print(\"Move disk \" + str(dis_number) + \"from peg \" + from_peg + \"to peg \" + str(to_peg) + '.') def solve_hanoi(n, start_peg, end_peg): if n == 1: move_disk(n, start_peg, end_peg) else: spare_peg = 6 - start_peg - end_peg solve_hanoi(n-1, start_peg, spare_peg) move_disk(n, start_peg, end_peg) solve_hanoi(n-1, spare_peg, end_peg) walkthrough hanoi(3,1,2) hanoi(2,1,3) hanoi(1,1,2) move(2,1,3) solve(1,2,3) move_disk(3,1,2) hanoi(2,3,2) hanoi(1,3,1) move(2,3,2) hanoi(1,1,2) disc move - exponential growth 1 1 2 3 3 7 4 15 ... n solve (n-1) twice + 1","title":"Tower of Hanoi"},{"location":"CS61A/ex-linked_list/","text":"Linked List A linked list is either empty or a first value and the rest of the linked list A linked list is a pair The first (zeroth) element is an attribute value The rest of the elements are stored in a linked list Link.empty - a class attribute represents an empty linked list Linked List Class Linked list class: attributes are passed to __init__ class Link: empty = () # tuple: some zero-length sequence def __init__(self, first, rest=empty): assert rest is Link.empty or isinstance(rest, Link) self.first = first self.rest = rest def __repr__(self): if self.rest: rest_repr = ', ' + repr(self.rest) else: rest_repr = '' return 'Link(' + repr(self.first) + rest_repr + ')' def __str__(self): string = '<' while self.rest is not Link.empty: string += str(self.first) + ' ' self = self.rest return string + str(self.first) + '>' def __getitem__(self, i): if i == 0: return self.first else: return self.rest[i-1] def __len__(self): return 1 + len(self.rest) Extend Link def extend_link(s, t): \"\"\" >>> extend_link(s, s) Link(3, Link(4, Link(5, Link(3, Link(4, Link(5)))))) \"\"\" if s is Link.empty: return t else: return Link(s.first, extend(s.rest, t)) Range Link def range_link(start, end): \"\"\"Return a Link containing consecutive integers from start to end. >>> range_link(3, 6) Link(3, Link(4, Link(5))) \"\"\" if start >= end: return Link.empty else: return Link(start, range_link(start + 1, end)) Map Link def map_link(f, s): \"\"\"Return a Link that contains f(x) for each x in Link s. >>> map_link(square, range_link(3, 6)) Link(9, Link(16, Link(25))) \"\"\" if s is Link.empty: return s else: return Link(f(s.first), map_link(f, s.rest)) Filter Link def filter_link(f, s): \"\"\"Return a Link that contains only the elements x of Link s for which f(x) is a true value. >>> filter_link(odd, range_link(3, 6)) Link(3, Link(5)) \"\"\" if s is Link.empty: return s filtered_rest = filter_link(f, s.rest) if f(s.first): return Link(s.first, filtered_rest) else: return filtered_rest or def filter_link(lnk, fn): \"\"\" >>> link = Link(1, Link(2, Link(3))) >>> g = filter_link(link, lambda x: x % 2 == 0) >>> next(g) 2 >>> next(g) StopIteration >>> list(filter_link(link, lambda x: x % 2 != 0)) [1, 3] \"\"\" while lnk is not Link.empty: if f(link.first): yield lnk.first lnk = lnk.rest Join Link def join_link(s, separator): \"\"\" >>> join_link(s, \", \") '3, 4, 5' \"\"\" if s is Link.empty: return \"\" elif s.rest is Link.empty: return str(s.first) else: return str(s.first) + separator + join_link(s.rest, separator) Add to an Ordered List def add(s, v): \"\"\" Add v to an ordered list s with no repeats, returning modified s. If v is already in s, then don't modify s, but still return it >>> s = Link(1, Link(3, Link(5))) >>> add(s, 0) Link(0, Link(1, Link(3, Link(5)))) >>> add(s, 3) Link(0, Link(1, Link(3, Link(5)))) >>> add(s, 4) Link(0, Link(1, Link(3, Link(4, Link(5))))) >>> add(s, 6) Link(0, Link(1, Link(3, Link(4, Link(5, Link(6)))) \"\"\" if v < s.first: s.first, s.rest = v, Link(s.first, s.rest) elif v > s.first and empty(s.rest): s.rest = Link(v) elif v > s.first: add(s.rest, v) return s Sum Nums def sum_nums(lnk): \"\"\" >>> a = Link(1, Link(6, Link(7))) >>> sum_nums(a) 14 \"\"\" if lnk is Link.empty: return 0 return lnk.first + sum_nums(lnk.rest) Multiply Link def multiply_lnks(lst_of_lnks): \"\"\" >>> a = Link(2, Link(3, Link(5))) >>> b = Link(6, Link(4, Link(2))) >>> c = Link(4, Link(1, Link(0, Link(2)))) >>> p = multiply_lnks([a, b, c]) >>> p.first 48 >>> p.rest.first 12 >>> p.rest.rest.rest is Link.empty True \"\"\" product = 1 for lnk in lst_of_lnks: if lnk is Link.empty: return Link.empty product *= lnk.first lst_of_lnks_rest = [lnk.rest for lnk in lst_of_lnks] return Link(product, multiply_lnks(lst_of_lnks_rest)) Convert to List def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. >>> link = Link(1, Link(2, Link(3, Link(4)))) >>> convert_link(link) [1, 2, 3, 4] >>> convert_link(Link.empty) [] \"\"\" output_list = [] while link != Link.empty: output_list.append(link.first) link = link.rest return output_list recursive def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. >>> link = Link(1, Link(2, Link(3, Link(4)))) >>> convert_link(link) [1, 2, 3, 4] >>> convert_link(Link.empty) [] \"\"\" if link == Link.empty: return [] else: return [link.first] + convert_link(link.rest) Flip Two def flip_two(lnk): \"\"\" >>> one_lnk = Link(1) >>> flip_two(one_lnk) >>> one_lnk Link(1) >>> lnk = Link(1, Link(2, Link(3, Link(4, Link(5))))) >>> flip_two(lnk) >>> lnk Link(2, Link(1, Link(4, Link(3, Link(5))))) \"\"\" if lnk is Link.empty: return elif lnk.rest is Link.empty: return else: tmp_first = lnk.first tmp_rest = lnk.rest.first lnk.first = tmp_rest lnk.rest = Link(tmp_first, lnk.rest.rest) lnk.rest = Link(tmp_first, lnk.rest.rest) flip_two(lnk.rest.rest) Every Other Element (Q) def every_other(s): \"\"\"Returns a new linked list that contains all the even-indiced elements of the original linked list (using 0-based indexing). \"\"\" if s is Link.empty: return Link.empty elif s.rest is Link.empty: return s return Link(s.first, every_other(s.rest.rest)) in-place mutation? def every_other(s): \"\"\"Mutates a linked list so that all the odd-indiced elements are removed (using 0-based indexing). >>> s = Link(1, Link(2, Link(3, Link(4)))) >>> every_other(s) >>> s Link(1, Link(3)) >>> odd_length = Link(5, Link(3, Link(1))) >>> every_other(odd_length) >>> odd_length Link(5, Link(1)) >>> singleton = Link(4) >>> every_other(singleton) >>> singleton Link(4) \"\"\" \"*** YOUR CODE HERE ***\" store digits def store_digits(n): \"\"\"Stores the digits of a positive number n in a linked list. >>> s = store_digits(1) >>> s Link(1) >>> store_digits(2345) Link(2, Link(3, Link(4, Link(5)))) >>> store_digits(876) Link(8, Link(7, Link(6))) >>> # a check for restricted functions >>> import inspect, re >>> cleaned = re.sub(r\"#.*\\\\n\", '', re.sub(r'\"{3}[\\s\\S]*?\"{3}', '', inspect.getsource(store_digits))) >>> print(\"Do not use str or reversed!\") if any([r in cleaned for r in [\"str\", \"reversed\"]]) else None \"\"\" l = Link.empty while n > 0: l = Link(n % 10, l) n = n // 10 Sorted def ordered(s, key=lambda x: x): \"\"\"Is Link s ordered? >>> ordered(Link(1, Link(3, Link(4)))) True >>> ordered(Link(1, Link(4, Link(3)))) False >>> ordered(Link(1, Link(-3, Link(4)))) False >>> ordered(Link(1, Link(-3, Link(4))), key=abs) True >>> ordered(Link(-4, Link(-1, Link(3)))) True >>> ordered(Link(-4, Link(-1, Link(3))), key=abs) False \"\"\" if s is Link.empty or s.rest is Link.empty: return True elif key(s.first) > key(s.rest.first): return False else: return ordered(s.rest) Merge def merge(s, t): \"\"\"Return a sorted Link containing the elements of sorted s & t. >>> a = Link(1, Link(5)) >>> b = Link(1, Link(4)) >>> merge(a, b) Link(1, Link(1, Link(4, Link(5)))) >>> a Link(1, Link(5)) >>> b Link(1, Link(4)) \"\"\" if s is Link.empty: return t elif t is Link.empty: return s elif s.first <= t.first: return Link(s.first, merge(s.rest, t)) else: return Link(t.first, merge(s, t.rest)) in-place def merge_in_place(s, t): \"\"\"Return a sorted Link containing the elements of sorted s & t. >>> a = Link(1, Link(5)) >>> b = Link(1, Link(4)) >>> merge_in_place(a, b) Link(1, Link(1, Link(4, Link(5)))) >>> a Link(1, Link(1, Link(4, Link(5)))) >>> b Link(1, Link(4, Link(5))) \"\"\" if s is Link.empty: return t elif t is Link.empty: return s elif s.first <= t.first: s.rest = merge_in_place(s.rest, t) return s else: t.rest = merge_in_place(s, t.rest) return t Partition (TBD) Has Cycle def has_cycle(link): \"\"\"Return whether link contains a cycle. >>> s = Link(1, Link(2, Link(3))) >>> s.rest.rest.rest = s >>> has_cycle(s) True >>> t = Link(1, Link(2, Link(3))) >>> has_cycle(t) False >>> u = Link(2, Link(2, Link(2))) >>> has_cycle(u) False \"\"\" links = [] while link is not Link.empty: if link in links: return True links.append(link) link = link.rest return False constant space def has_cycle_constant(link): \"\"\"Return whether link contains a cycle. (with constant space) >>> s = Link(1, Link(2, Link(3))) >>> s.rest.rest.rest = s >>> has_cycle_constant(s) True >>> t = Link(1, Link(2, Link(3))) >>> has_cycle_constant(t) False \"\"\" if link is Link.empty: return False slow, fast = link, link.rest while fast is not Link.empty: if fast.rest == Link.empty: return False elif fast is slow or fast.rest is slow: return True else: slow, fast = slow.rest, fast.rest.rest return False Deep Linked List Length A linked list that contains one or more linked lists as elements is called a deep linked list. Write a function deep_len that takes in a (possibly deep) linked list and returns the deep length of that linked list. The deep length of a linked list is the total number of non-link elements in the list, as well as the total number of elements contained in all contained lists. def deep_len(lnk): \"\"\" Returns the deep length of a possibly deep linked list. >>> deep_len(Link(1, Link(2, Link(3)))) 3 >>> deep_len(Link(Link(1, Link(2)), Link(3, Link(4)))) 4 >>> levels = Link(Link(Link(1, Link(2)), \\ Link(3)), Link(Link(4), Link(5))) >>> print(levels) <<<1 2> 3> <4> 5> >>> deep_len(levels) 5 \"\"\" if lnk is Link.empty: return 0 elif isinstance(lnk.first, Link): return deep_len(lnk.first) + deep_len(lnk.rest) else: return 1 + deep_len(lnk.rest) Make to String def make_to_string(front, mid, back, empty_repr): \"\"\" Returns a function that turns linked lists to strings. >>> kevins_to_string = make_to_string(\"[\", \"|-]-->\", \"\", \"[]\") >>> jerrys_to_string = make_to_string(\"(\", \" . \", \")\", \"()\") >>> lst = Link(1, Link(2, Link(3, Link(4)))) >>> kevins_to_string(lst) '[1|-]-->[2|-]-->[3|-]-->[4|-]-->[]' >>> kevins_to_string(Link.empty) '[]' >>> jerrys_to_string(lst) '(1 . (2 . (3 . (4 . ()))))' >>> jerrys_to_string(Link.empty) '()' \"\"\" def printer(lnk): if lnk is Link.empty: return empty_repr else: return front + str(lnk.first) + mid + printer(lnk.rest) + back return printer Remove Duplicates def remove_duplicates(lnk): \"\"\" >>> lnk = Link(1, Link(1, Link(1, Link(1, Link(5))))) >>> remove_duplicates(lnk) >>> lnk Link(1, Link(5)) \"\"\" if lnk == Link.empty or lnk.rest == Link.empty: return if lnk.first == lnk.rest.first: lnk.rest = lnk.rest.rest remove_duplicates(lnk) else: remove_duplicates(lnk.rest) Fold Left (TBD) def foldl(link, fn, z): \"\"\" Left fold >>> lst = Link(3, Link(2, Link(1))) >>> foldl(lst, sub, 0) # (((0 - 3) - 2) - 1) -6 >>> foldl(lst, add, 0) # (((0 + 3) + 2) + 1) 6 >>> foldl(lst, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" if link is Link.empty: return z \"*** YOUR CODE HERE ***\" return foldl(______, ______, ______) Filter with Fold (TBD) def filterl(lst, pred): \"\"\" Filters LST based on PRED >>> lst = Link(4, Link(3, Link(2, Link(1)))) >>> filterl(lst, lambda x: x % 2 == 0) Link(4, Link(2)) \"\"\" \"*** YOUR CODE HERE ***\" Reverse with Fold (TBD) def reverse(lst): \"\"\" Reverses LST with foldl >>> reverse(Link(3, Link(2, Link(1)))) Link(1, Link(2, Link(3))) >>> reverse(Link(1)) Link(1) >>> reversed = reverse(Link.empty) >>> reversed is Link.empty True \"\"\" \"*** YOUR CODE HERE ***\" Fold with Fold (TBD) identity = lambda x: x def foldl2(link, fn, z): \"\"\" Write foldl using foldr >>> list = Link(3, Link(2, Link(1))) >>> foldl2(list, sub, 0) # (((0 - 3) - 2) - 1) -6 >>> foldl2(list, add, 0) # (((0 + 3) + 2) + 1) 6 >>> foldl2(list, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" def step(x, g): \"*** YOUR CODE HERE ***\" return foldr(link, step, identity)(z)","title":"linked_list"},{"location":"CS61A/ex-linked_list/#linked-list","text":"A linked list is either empty or a first value and the rest of the linked list A linked list is a pair The first (zeroth) element is an attribute value The rest of the elements are stored in a linked list Link.empty - a class attribute represents an empty linked list","title":"Linked List"},{"location":"CS61A/ex-linked_list/#linked-list-class","text":"Linked list class: attributes are passed to __init__ class Link: empty = () # tuple: some zero-length sequence def __init__(self, first, rest=empty): assert rest is Link.empty or isinstance(rest, Link) self.first = first self.rest = rest def __repr__(self): if self.rest: rest_repr = ', ' + repr(self.rest) else: rest_repr = '' return 'Link(' + repr(self.first) + rest_repr + ')' def __str__(self): string = '<' while self.rest is not Link.empty: string += str(self.first) + ' ' self = self.rest return string + str(self.first) + '>' def __getitem__(self, i): if i == 0: return self.first else: return self.rest[i-1] def __len__(self): return 1 + len(self.rest)","title":"Linked List Class"},{"location":"CS61A/ex-linked_list/#extend-link","text":"def extend_link(s, t): \"\"\" >>> extend_link(s, s) Link(3, Link(4, Link(5, Link(3, Link(4, Link(5)))))) \"\"\" if s is Link.empty: return t else: return Link(s.first, extend(s.rest, t))","title":"Extend Link"},{"location":"CS61A/ex-linked_list/#range-link","text":"def range_link(start, end): \"\"\"Return a Link containing consecutive integers from start to end. >>> range_link(3, 6) Link(3, Link(4, Link(5))) \"\"\" if start >= end: return Link.empty else: return Link(start, range_link(start + 1, end))","title":"Range Link"},{"location":"CS61A/ex-linked_list/#map-link","text":"def map_link(f, s): \"\"\"Return a Link that contains f(x) for each x in Link s. >>> map_link(square, range_link(3, 6)) Link(9, Link(16, Link(25))) \"\"\" if s is Link.empty: return s else: return Link(f(s.first), map_link(f, s.rest))","title":"Map Link"},{"location":"CS61A/ex-linked_list/#filter-link","text":"def filter_link(f, s): \"\"\"Return a Link that contains only the elements x of Link s for which f(x) is a true value. >>> filter_link(odd, range_link(3, 6)) Link(3, Link(5)) \"\"\" if s is Link.empty: return s filtered_rest = filter_link(f, s.rest) if f(s.first): return Link(s.first, filtered_rest) else: return filtered_rest or def filter_link(lnk, fn): \"\"\" >>> link = Link(1, Link(2, Link(3))) >>> g = filter_link(link, lambda x: x % 2 == 0) >>> next(g) 2 >>> next(g) StopIteration >>> list(filter_link(link, lambda x: x % 2 != 0)) [1, 3] \"\"\" while lnk is not Link.empty: if f(link.first): yield lnk.first lnk = lnk.rest","title":"Filter Link"},{"location":"CS61A/ex-linked_list/#join-link","text":"def join_link(s, separator): \"\"\" >>> join_link(s, \", \") '3, 4, 5' \"\"\" if s is Link.empty: return \"\" elif s.rest is Link.empty: return str(s.first) else: return str(s.first) + separator + join_link(s.rest, separator)","title":"Join Link"},{"location":"CS61A/ex-linked_list/#add-to-an-ordered-list","text":"def add(s, v): \"\"\" Add v to an ordered list s with no repeats, returning modified s. If v is already in s, then don't modify s, but still return it >>> s = Link(1, Link(3, Link(5))) >>> add(s, 0) Link(0, Link(1, Link(3, Link(5)))) >>> add(s, 3) Link(0, Link(1, Link(3, Link(5)))) >>> add(s, 4) Link(0, Link(1, Link(3, Link(4, Link(5))))) >>> add(s, 6) Link(0, Link(1, Link(3, Link(4, Link(5, Link(6)))) \"\"\" if v < s.first: s.first, s.rest = v, Link(s.first, s.rest) elif v > s.first and empty(s.rest): s.rest = Link(v) elif v > s.first: add(s.rest, v) return s","title":"Add to an Ordered List"},{"location":"CS61A/ex-linked_list/#sum-nums","text":"def sum_nums(lnk): \"\"\" >>> a = Link(1, Link(6, Link(7))) >>> sum_nums(a) 14 \"\"\" if lnk is Link.empty: return 0 return lnk.first + sum_nums(lnk.rest)","title":"Sum Nums"},{"location":"CS61A/ex-linked_list/#multiply-link","text":"def multiply_lnks(lst_of_lnks): \"\"\" >>> a = Link(2, Link(3, Link(5))) >>> b = Link(6, Link(4, Link(2))) >>> c = Link(4, Link(1, Link(0, Link(2)))) >>> p = multiply_lnks([a, b, c]) >>> p.first 48 >>> p.rest.first 12 >>> p.rest.rest.rest is Link.empty True \"\"\" product = 1 for lnk in lst_of_lnks: if lnk is Link.empty: return Link.empty product *= lnk.first lst_of_lnks_rest = [lnk.rest for lnk in lst_of_lnks] return Link(product, multiply_lnks(lst_of_lnks_rest))","title":"Multiply Link"},{"location":"CS61A/ex-linked_list/#convert-to-list","text":"def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. >>> link = Link(1, Link(2, Link(3, Link(4)))) >>> convert_link(link) [1, 2, 3, 4] >>> convert_link(Link.empty) [] \"\"\" output_list = [] while link != Link.empty: output_list.append(link.first) link = link.rest return output_list recursive def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. >>> link = Link(1, Link(2, Link(3, Link(4)))) >>> convert_link(link) [1, 2, 3, 4] >>> convert_link(Link.empty) [] \"\"\" if link == Link.empty: return [] else: return [link.first] + convert_link(link.rest)","title":"Convert to List"},{"location":"CS61A/ex-linked_list/#flip-two","text":"def flip_two(lnk): \"\"\" >>> one_lnk = Link(1) >>> flip_two(one_lnk) >>> one_lnk Link(1) >>> lnk = Link(1, Link(2, Link(3, Link(4, Link(5))))) >>> flip_two(lnk) >>> lnk Link(2, Link(1, Link(4, Link(3, Link(5))))) \"\"\" if lnk is Link.empty: return elif lnk.rest is Link.empty: return else: tmp_first = lnk.first tmp_rest = lnk.rest.first lnk.first = tmp_rest lnk.rest = Link(tmp_first, lnk.rest.rest) lnk.rest = Link(tmp_first, lnk.rest.rest) flip_two(lnk.rest.rest)","title":"Flip Two"},{"location":"CS61A/ex-linked_list/#every-other-element-q","text":"def every_other(s): \"\"\"Returns a new linked list that contains all the even-indiced elements of the original linked list (using 0-based indexing). \"\"\" if s is Link.empty: return Link.empty elif s.rest is Link.empty: return s return Link(s.first, every_other(s.rest.rest)) in-place mutation? def every_other(s): \"\"\"Mutates a linked list so that all the odd-indiced elements are removed (using 0-based indexing). >>> s = Link(1, Link(2, Link(3, Link(4)))) >>> every_other(s) >>> s Link(1, Link(3)) >>> odd_length = Link(5, Link(3, Link(1))) >>> every_other(odd_length) >>> odd_length Link(5, Link(1)) >>> singleton = Link(4) >>> every_other(singleton) >>> singleton Link(4) \"\"\" \"*** YOUR CODE HERE ***\"","title":"Every Other Element (Q)"},{"location":"CS61A/ex-linked_list/#store-digits","text":"def store_digits(n): \"\"\"Stores the digits of a positive number n in a linked list. >>> s = store_digits(1) >>> s Link(1) >>> store_digits(2345) Link(2, Link(3, Link(4, Link(5)))) >>> store_digits(876) Link(8, Link(7, Link(6))) >>> # a check for restricted functions >>> import inspect, re >>> cleaned = re.sub(r\"#.*\\\\n\", '', re.sub(r'\"{3}[\\s\\S]*?\"{3}', '', inspect.getsource(store_digits))) >>> print(\"Do not use str or reversed!\") if any([r in cleaned for r in [\"str\", \"reversed\"]]) else None \"\"\" l = Link.empty while n > 0: l = Link(n % 10, l) n = n // 10","title":"store digits"},{"location":"CS61A/ex-linked_list/#sorted","text":"def ordered(s, key=lambda x: x): \"\"\"Is Link s ordered? >>> ordered(Link(1, Link(3, Link(4)))) True >>> ordered(Link(1, Link(4, Link(3)))) False >>> ordered(Link(1, Link(-3, Link(4)))) False >>> ordered(Link(1, Link(-3, Link(4))), key=abs) True >>> ordered(Link(-4, Link(-1, Link(3)))) True >>> ordered(Link(-4, Link(-1, Link(3))), key=abs) False \"\"\" if s is Link.empty or s.rest is Link.empty: return True elif key(s.first) > key(s.rest.first): return False else: return ordered(s.rest)","title":"Sorted"},{"location":"CS61A/ex-linked_list/#merge","text":"def merge(s, t): \"\"\"Return a sorted Link containing the elements of sorted s & t. >>> a = Link(1, Link(5)) >>> b = Link(1, Link(4)) >>> merge(a, b) Link(1, Link(1, Link(4, Link(5)))) >>> a Link(1, Link(5)) >>> b Link(1, Link(4)) \"\"\" if s is Link.empty: return t elif t is Link.empty: return s elif s.first <= t.first: return Link(s.first, merge(s.rest, t)) else: return Link(t.first, merge(s, t.rest)) in-place def merge_in_place(s, t): \"\"\"Return a sorted Link containing the elements of sorted s & t. >>> a = Link(1, Link(5)) >>> b = Link(1, Link(4)) >>> merge_in_place(a, b) Link(1, Link(1, Link(4, Link(5)))) >>> a Link(1, Link(1, Link(4, Link(5)))) >>> b Link(1, Link(4, Link(5))) \"\"\" if s is Link.empty: return t elif t is Link.empty: return s elif s.first <= t.first: s.rest = merge_in_place(s.rest, t) return s else: t.rest = merge_in_place(s, t.rest) return t","title":"Merge"},{"location":"CS61A/ex-linked_list/#partition-tbd","text":"","title":"Partition (TBD)"},{"location":"CS61A/ex-linked_list/#has-cycle","text":"def has_cycle(link): \"\"\"Return whether link contains a cycle. >>> s = Link(1, Link(2, Link(3))) >>> s.rest.rest.rest = s >>> has_cycle(s) True >>> t = Link(1, Link(2, Link(3))) >>> has_cycle(t) False >>> u = Link(2, Link(2, Link(2))) >>> has_cycle(u) False \"\"\" links = [] while link is not Link.empty: if link in links: return True links.append(link) link = link.rest return False constant space def has_cycle_constant(link): \"\"\"Return whether link contains a cycle. (with constant space) >>> s = Link(1, Link(2, Link(3))) >>> s.rest.rest.rest = s >>> has_cycle_constant(s) True >>> t = Link(1, Link(2, Link(3))) >>> has_cycle_constant(t) False \"\"\" if link is Link.empty: return False slow, fast = link, link.rest while fast is not Link.empty: if fast.rest == Link.empty: return False elif fast is slow or fast.rest is slow: return True else: slow, fast = slow.rest, fast.rest.rest return False","title":"Has Cycle"},{"location":"CS61A/ex-linked_list/#deep-linked-list-length","text":"A linked list that contains one or more linked lists as elements is called a deep linked list. Write a function deep_len that takes in a (possibly deep) linked list and returns the deep length of that linked list. The deep length of a linked list is the total number of non-link elements in the list, as well as the total number of elements contained in all contained lists. def deep_len(lnk): \"\"\" Returns the deep length of a possibly deep linked list. >>> deep_len(Link(1, Link(2, Link(3)))) 3 >>> deep_len(Link(Link(1, Link(2)), Link(3, Link(4)))) 4 >>> levels = Link(Link(Link(1, Link(2)), \\ Link(3)), Link(Link(4), Link(5))) >>> print(levels) <<<1 2> 3> <4> 5> >>> deep_len(levels) 5 \"\"\" if lnk is Link.empty: return 0 elif isinstance(lnk.first, Link): return deep_len(lnk.first) + deep_len(lnk.rest) else: return 1 + deep_len(lnk.rest)","title":"Deep Linked List Length"},{"location":"CS61A/ex-linked_list/#make-to-string","text":"def make_to_string(front, mid, back, empty_repr): \"\"\" Returns a function that turns linked lists to strings. >>> kevins_to_string = make_to_string(\"[\", \"|-]-->\", \"\", \"[]\") >>> jerrys_to_string = make_to_string(\"(\", \" . \", \")\", \"()\") >>> lst = Link(1, Link(2, Link(3, Link(4)))) >>> kevins_to_string(lst) '[1|-]-->[2|-]-->[3|-]-->[4|-]-->[]' >>> kevins_to_string(Link.empty) '[]' >>> jerrys_to_string(lst) '(1 . (2 . (3 . (4 . ()))))' >>> jerrys_to_string(Link.empty) '()' \"\"\" def printer(lnk): if lnk is Link.empty: return empty_repr else: return front + str(lnk.first) + mid + printer(lnk.rest) + back return printer","title":"Make to String"},{"location":"CS61A/ex-linked_list/#remove-duplicates","text":"def remove_duplicates(lnk): \"\"\" >>> lnk = Link(1, Link(1, Link(1, Link(1, Link(5))))) >>> remove_duplicates(lnk) >>> lnk Link(1, Link(5)) \"\"\" if lnk == Link.empty or lnk.rest == Link.empty: return if lnk.first == lnk.rest.first: lnk.rest = lnk.rest.rest remove_duplicates(lnk) else: remove_duplicates(lnk.rest)","title":"Remove Duplicates"},{"location":"CS61A/ex-linked_list/#fold-left-tbd","text":"def foldl(link, fn, z): \"\"\" Left fold >>> lst = Link(3, Link(2, Link(1))) >>> foldl(lst, sub, 0) # (((0 - 3) - 2) - 1) -6 >>> foldl(lst, add, 0) # (((0 + 3) + 2) + 1) 6 >>> foldl(lst, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" if link is Link.empty: return z \"*** YOUR CODE HERE ***\" return foldl(______, ______, ______)","title":"Fold Left (TBD)"},{"location":"CS61A/ex-linked_list/#filter-with-fold-tbd","text":"def filterl(lst, pred): \"\"\" Filters LST based on PRED >>> lst = Link(4, Link(3, Link(2, Link(1)))) >>> filterl(lst, lambda x: x % 2 == 0) Link(4, Link(2)) \"\"\" \"*** YOUR CODE HERE ***\"","title":"Filter with Fold (TBD)"},{"location":"CS61A/ex-linked_list/#reverse-with-fold-tbd","text":"def reverse(lst): \"\"\" Reverses LST with foldl >>> reverse(Link(3, Link(2, Link(1)))) Link(1, Link(2, Link(3))) >>> reverse(Link(1)) Link(1) >>> reversed = reverse(Link.empty) >>> reversed is Link.empty True \"\"\" \"*** YOUR CODE HERE ***\"","title":"Reverse with Fold (TBD)"},{"location":"CS61A/ex-linked_list/#fold-with-fold-tbd","text":"identity = lambda x: x def foldl2(link, fn, z): \"\"\" Write foldl using foldr >>> list = Link(3, Link(2, Link(1))) >>> foldl2(list, sub, 0) # (((0 - 3) - 2) - 1) -6 >>> foldl2(list, add, 0) # (((0 + 3) + 2) + 1) 6 >>> foldl2(list, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" def step(x, g): \"*** YOUR CODE HERE ***\" return foldr(link, step, identity)(z)","title":"Fold with Fold (TBD)"},{"location":"CS61A/ex-recursion/","text":"Recursions sum(n) built-in sum() for a list >>> sum <built-in function sum> >>> sum([3,4,5]) 12 >>> 0 + 3 + 4 + 5 12 >>> sum([]) 0 >>> [3] + [4, 5][3, 4, 5] takes input n and returns the sum of the first n integers sum(5) returns 1+2+3+4+5 def sum_itr(n): i, total = 0, 0 while i < n: i += 1 total += i return total def sum_itr(n): sum = 0 for i in range(0, n+1): sum = sum + i return sum def sum(n): if n == 0: return 0 else: return n + sum(n-1) sum digits def sum_digits(y): \"\"\"Sum all the digits of y. >>> sum_digits(10) # 1 + 0 = 1 1 >>> sum_digits(4224) # 4 + 2 + 2 + 4 = 12 12 >>> sum_digits(1234567890) 45 >>> a = sum_digits(123) # make sure that you are using return rather than print >>> a 6 \"\"\" if y <= 0: return \"need to input a nonnegative number\" else: sum = 0 while y > 0: sum = sum + y % 10 y = y // 10 return sum recursively def sum_digits(n): \"\"\"Return the sum of the digits of positive integer n.\"\"\" if n < 10: return n else: all_but_last, last = n // 10, n % 10 return sum_digits(all_but_last) + last sum of first n terms def summation(n, term): \"\"\"Return the sum of the first n terms in the sequence defined by term. Implement using recursion! >>> summation(5, lambda x: x * x * x) # 1^3 + 2^3 + 3^3 + 4^3 + 5^3 225 >>> summation(9, lambda x: x + 1) # 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 54 >>> summation(5, lambda x: 2**x) # 2^1 + 2^2 + 2^3 + 2^4 + 2^5 62 \"\"\" assert n >= 1 if n == 1: return term(n) else: return term(n) + summation(n-1, term) cascade def cascade(n): if n < 10: print(n) else: print(n) cascade(n//10) print(n) alternatively def cascade(n): print(n) if n > 10: cascade(n//10) print(n) results >>> print(123) 123 12 1 12 123 inverse cascade hint grow prints out: 1, 12, 123 print prints out 123 shrink prints out 123, 12, 12 def inverse_cascade(n): grow(n) print(n) shrink(n) def f_then_g(f, g, n): if n: f(n) g(n) grow = lambda n: f_then_g() shrink = lambda n: f_then_g() solution grow = lambda n: f_then_g(grow, print, n//10) shrink = lambda n: f_then_g(print, shrink, n//10) hailstone Douglas Hofstadter's Pulitzer-prize-winning book, G\u00f6del, Escher, Bach , poses the following mathematical puzzle. Pick a positive integer n as the start. If n is even, divide it by 2. If n is odd, multiply it by 3 and add 1. Continue this process until n is 1. def hailstone(n): count = 1 if n <= 0: print('pick a positive number') return 0 else: print(n) while n != 1: if n % 2 == 0: n = n / 2 else: n = n * 3 + 1 print(n) count += 1 return count recursive def hailstone(n): print(n) if n == 1: return n elif n % 2 == 0: return 1 + hailstone(n // 2) else: return 1 + hailstone(3 * n + 1) merge digits take s numbers with digits in decreasing order returns a single number with all of the digits of the two in decreasing order def merge(n1, n2): if n1 == 0: return n2 elif n2 == 0: return n1 elif n1 % 10 < n2 % 10: return merge(n1 // 10, n2) * 10 + n1 % 10 else: return merge(n1, n2 // 10) * 10 + n2 % 10 missing digits def missing_digits(n): \"\"\"Given a number a that is in sorted, increasing order, return the number of missing digits in n. A missing digit is a number between the first and last digit of a that is not in n. >>> missing_digits(1248) # 3, 5, 6, 7 4 >>> missing_digits(1122) # No missing numbers 0 >>> missing_digits(123456) # No missing numbers 0 >>> missing_digits(3558) # 4, 6, 7 3 >>> missing_digits(35578) # 4, 6 2 >>> missing_digits(12456) # 3 1 >>> missing_digits(16789) # 2, 3, 4, 5 4 >>> missing_digits(19) # 2, 3, 4, 5, 6, 7, 8 7 >>> missing_digits(4) # No missing numbers between 4 and 4 0 \"\"\" def missing_digits(n): if n < 10: return 0 else: last_digit = n % 10 second_to_last_digit = n // 10 % 10 if last_digit == second_to_last_digit: return missing_digits(n // 10) else: return (last_digit - second_to_last_digit - 1) + missing_digits(n // 10) skip add def skip_add(n): \"\"\" Takes a number n and returns n + n-2 + n-4 + n-6 + ... + 0. >>> skip_add(5) # 5 + 3 + 1 + 0 9 >>> skip_add(10) # 10 + 8 + 6 + 4 + 2 + 0 30 \"\"\" if n <= 0: return 0 else: return n + skip_add(n-2) factorial def fact(n): if n == 0: return 1 else: return n * fact(n-1) def fact_iter(n): total, k = 1, 1 while k <= n: total, k = total * k, k + 1 return total prime number while loop def is_prime(n): \"\"\" >>> is_prime(10) False >>> is_prime(7) True \"\"\" if n == 1: return False else: i = 2 while i < n: if n % i == 0: return False break else: i += 1 return True for loop def is_prime(n): \"\"\" >>> is_prime(10) False >>> is_prime(7) True \"\"\" if n == 1: return False else: for i in range(2, n): if n % i == 0: return False break else: return True recursive def is_prime(n): def prime_helper(i): if i == n: return True elif n % i == 0 or n == 1: return False else: return prime_helper(i+1) return prime_helper(2) # i starts from 2 pingpong def pingpong(n): \"\"\"Return the nth element of the ping-pong sequence. >>> pingpong(8) 8 >>> pingpong(10) 6 >>> pingpong(15) 1 >>> pingpong(21) -1 >>> pingpong(22) -2 >>> pingpong(30) -2 >>> pingpong(68) 0 >>> pingpong(69) -1 >>> pingpong(80) 0 >>> pingpong(81) 1 >>> pingpong(82) 0 >>> pingpong(100) -6 \"\"\" def pingpong_helper(x, direction, base): if x == n: return base + direction elif x % 8 == 0 or num_eights(x)>0: return pingpong_helper(x+1, -direction, base + direction) else: return pingpong_helper(x+1, direction, base + direction) return pingpong_helper(1, 1, 0) iterative def pingpong_itr(n): i, value, direction = 1, 1, 1 while i < n: if i % 8 == 0 or num_eights(i)>0: direction = -direction value += direction i += 1 return value count coins def next_largest_coin(coin): \"\"\"Return the next coin. >>> next_largest_coin(1) 5 >>> next_largest_coin(5) 10 >>> next_largest_coin(10) 25 >>> next_largest_coin(2) # Other values return None \"\"\" if coin == 1: return 5 elif coin == 5: return 10 elif coin == 10: return 25 def count_coins(total): \"\"\"Return the number of ways to make change for total using coins of value of 1, 5, 10, 25. >>> count_coins(15) 6 >>> count_coins(10) 4 >>> count_coins(20) 9 >>> count_coins(100) # How many ways to make change for a dollar? 242 \"\"\" def count_coins(total): def coin_helper(total, coin): if total < 0: return 0 elif total == 0: return 1 elif coin is None: return 0 else: cur_coin = coin_helper(total - coin, coin) next_coin = coin_helper(total, next_largest_coin(coin)) return cur_coin + next_coin return coin_helper(total, 1) # doesn't work for count_coins(100), why? count paths in grid def paths(m, n): \"\"\"Return the number of paths from one corner of an M by N grid to the opposite corner. >>> paths(2, 2) 2 >>> paths(5, 7) 210 >>> paths(117, 1) 1 >>> paths(1, 157) 1 \"\"\" if m == 1 and n == 1: # start return 1 elif m == 1: # left edge return paths(m, n-1) elif n == 1: # bottom edge return paths(m-1, n) else: return paths(m, n-1) + paths(m-1, n) count stairs for n steps take 1 or 2 steps each time # my sln def count_stair_ways(n): if n == 1: return 1 elif n == 2: return 2 else: return count_stair_ways(n-1) + count_stair_ways(n-2) # don't need else def count_stair_ways(n): if n == 1: return 1 elif n == 2: return 2 return count_stair_ways(n-1) + count_stair_ways(n-2) take up to k steps at a time def count_k(n, k): \"\"\" >>> count_k(3, 3) # 3, 2 + 1, 1 + 2, 1 + 1 + 1 4 >>> count_k(4, 4) 8 >>> count_k(10, 3) 274 >>> count_k(300, 1) # Only one step at a time 1 \"\"\" if n == 0: return 1 elif n < 0: return 0 else: # count_k(n-1, k) + count_k(n-2, k) + ... + count_k(n-k, k) total = 0 i = 1 while i <= k: total += count_k(n-i, k) i += 1 return total max product of nonconsecutive elements def max_product(s): \"\"\"Return the maximum product that can be formed using non-consecutive elements of s. >>> max_product([10,3,1,9,2]) # 10 * 9 90 >>> max_product([5,10,5,10,5]) # 5 * 5 * 5 125 >>> max_product([]) 1 \"\"\" if len(s) == 0: return 1 elif len(s) == 1: return s[0] else: return max(max_product(s[1:]), s[0] * max_product(s[2:])) insert into all def insert_into_all(item, nested_list): \"\"\"Assuming that nested_list is a list of lists, return a new list consisting of all the lists in nested_list, but with item added to the front of each. >>> nl = [[], [1, 2], [3]] >>> insert_into_all(0, nl) [[0], [0, 1, 2], [0, 3]] \"\"\" return [[item] + i for i in nested_list] subsequence def subseqs(s): \"\"\" >>> seqs = subseqs([1, 2, 3]) >>> sorted(seqs) [[], [1], [1, 2], [1, 2, 3], [1, 3], [2], [2, 3], [3]] >>> subseqs([]) [[]] \"\"\" if len(s) == 0: return [[]] else: exclude_first = subseqs(s[1:]) include_first = [[s[0]] + e for e in exclude_first] # include_first = insert_into_all([s[0]], exclude_first) return exclude_first + include_first increasing subsequence def inc_subseqs(s): \"\"\" >>> seqs = inc_subseqs([1, 3, 2]) >>> sorted(seqs) [[], [1], [1, 2], [1, 3], [2], [3]] >>> inc_subseqs([]) [[]] >>> seqs2 = inc_subseqs([1, 1, 2]) >>> sorted(seqs2) [[], [1], [1], [1, 1], [1, 1, 2], [1, 2], [1, 2], [2]] \"\"\" def subseq_helper(s, prev): if not s: return [[]] elif s[0] < prev: return subseq_helper(s[1:], prev) else: include = subseq_helper(s[1:], s[0]) exclude = subseq_helper(s[1:], prev) return insert_into_all(s[0], include) + exclude return subseq_helper(s, 0) max subsequence def max_subseq(n, t): \"\"\" Return the maximum subsequence of length at most t that can be found in the given number n. For example, for n = 20125 and t = 3, we have that the subsequences are 2 0 1 2 5 20 21 22 25 01 02 05 12 15 25 201 202 205 212 215 225 012 015 025 125 and of these, the maxumum number is 225, so our answer is 225. >>> max_subseq(20125, 3) 225 >>> max_subseq(20125, 5) 20125 >>> max_subseq(20125, 6) # note that 20125 == 020125 20125 >>> max_subseq(12345, 3) 345 >>> max_subseq(12345, 0) # 0 is of length 0 0 >>> max_subseq(12345, 1) 5 \"\"\" if t == 0 or n == 0: return 0 last_digit = n % 10 rest = n // 10 keep_last_digit = max_subseq(rest, t-1) * 10 + last_digit drop_last_digit = max_subseq(rest, t) return max(keep_last_digit, drop_last_digit) add characters def add_chars(w1, w2): \"\"\" Return a string containing the characters you need to add to w1 to get w2. You may assume that w1 is a subsequence of w2. >>> add_chars(\"owl\", \"howl\") 'h' >>> add_chars(\"want\", \"wanton\") 'on' >>> add_chars(\"rat\", \"radiate\") 'diae' >>> add_chars(\"a\", \"prepare\") 'prepre' >>> add_chars(\"resin\", \"recursion\") 'curo' >>> add_chars(\"fin\", \"effusion\") 'efuso' >>> add_chars(\"coy\", \"cacophony\") 'acphon' \"\"\" if len(w1) == 0: return w2 if w1[0] == w2[0]: return add_chars(w1[1:], w2[1:]) else: return w2[0] + add_chars(w1, w2[1:]) reverse string def reverse(s): if len(s) == 1: return s else: return reverse(s[1:]) + s[0] def reverse(s): if len(s) == 0: return '' else: return reverse(s[1:]) + s[0] sequence iteration def mysum(L): if L == []: return 0 else: return L[0] + mysum(L[1:]) iterations # index def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total, index = 0, 0 while index < len(s): if s[index] == value: total = total + 1 index = index + 1 return total # element def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total = 0 for elem in s: if elem == value: total = total + 1 return total Pascal's Triangle 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 def pascal(row, column): \"\"\"Returns the value of the item in Pascal's Triangle whose position is specified by row and column. >>> pascal(0, 0) 1 >>> pascal(0, 5) # Empty entry; outside of Pascal's Triangle 0 >>> pascal(3, 2) # Row 3 (1 3 3 1), Column 2 3 >>> pascal(4, 2) # Row 4 (1 4 6 4 1), Column 2 6 \"\"\" if column == 0: return 1 elif row == 0: return 0 else: return pascal(row - 1, column) + pascal(row - 1, column - 1) Knapsack def knapsack(weights, values, c): \"\"\" takes a list weights, list values and a capacity c return that max value >>> w = [2, 6, 3, 3] >>> v = [1, 5, 3, 3] >>> knapsack(w, v, 6) 6 \"\"\" \"*** YOUR CODE HERE ***\" if len(weights) == 0: return 0 else: first_weight, rest_weight = weights[0], weights[1:] first_value, rest_value = values[0], values[1:] with_first = first_value + knapsack(rest_weight, rest_value, c - first_weight) without_first = knapsack(rest_weight, rest_value, c) if first_weight <= c: return max(with_first, without_first) else: return without_first Mutual Recursion luhn sum - credit card validation checksum = a multiple of 10 def luhn_sum(n): if n < 10: return n else: all_but_last, last = n // 10, n % 10 return luhn_sum_double(all_but_last) + last def luhn_sum_double(n): all_but_last, last = n // 10, n % 10 luhn_digit = sum_digits(2 * last) if n < 10: return n else: return luhn_sum(all_but_last) + luhn_digit even or odd def is_even(n): if n == 0: return True else: return is_odd(n-1) def is_odd(n): if n == 0: return False else: return is_even(n-1) result = is_even(4) all-in-one def is_even(n): if n == 0: return True else: if (n-1) == 0: return False else: return is_even((n-1)-1) subpaths def paths(x, y): \"\"\"Return a list of ways to reach y from x by repeated incrementing or doubling. >>> paths(3, 5) [[3, 4, 5]] >>> sorted(paths(3, 6)) [[3, 4, 5, 6], [3, 6]] >>> sorted(paths(3, 9)) [[3, 4, 5, 6, 7, 8, 9], [3, 4, 8, 9], [3, 6, 7, 8, 9]] >>> paths(3, 3) # No calls is a valid path [[3]] \"\"\" if x > y: return [] elif x == y: return [[x]] else: a = paths(x+1, y) b = paths(2*x, y) return [[x] + subpath for subpath in a+b]","title":"recursion"},{"location":"CS61A/ex-recursion/#recursions","text":"","title":"Recursions"},{"location":"CS61A/ex-recursion/#sumn","text":"built-in sum() for a list >>> sum <built-in function sum> >>> sum([3,4,5]) 12 >>> 0 + 3 + 4 + 5 12 >>> sum([]) 0 >>> [3] + [4, 5][3, 4, 5] takes input n and returns the sum of the first n integers sum(5) returns 1+2+3+4+5 def sum_itr(n): i, total = 0, 0 while i < n: i += 1 total += i return total def sum_itr(n): sum = 0 for i in range(0, n+1): sum = sum + i return sum def sum(n): if n == 0: return 0 else: return n + sum(n-1)","title":"sum(n)"},{"location":"CS61A/ex-recursion/#sum-digits","text":"def sum_digits(y): \"\"\"Sum all the digits of y. >>> sum_digits(10) # 1 + 0 = 1 1 >>> sum_digits(4224) # 4 + 2 + 2 + 4 = 12 12 >>> sum_digits(1234567890) 45 >>> a = sum_digits(123) # make sure that you are using return rather than print >>> a 6 \"\"\" if y <= 0: return \"need to input a nonnegative number\" else: sum = 0 while y > 0: sum = sum + y % 10 y = y // 10 return sum recursively def sum_digits(n): \"\"\"Return the sum of the digits of positive integer n.\"\"\" if n < 10: return n else: all_but_last, last = n // 10, n % 10 return sum_digits(all_but_last) + last","title":"sum digits"},{"location":"CS61A/ex-recursion/#sum-of-first-n-terms","text":"def summation(n, term): \"\"\"Return the sum of the first n terms in the sequence defined by term. Implement using recursion! >>> summation(5, lambda x: x * x * x) # 1^3 + 2^3 + 3^3 + 4^3 + 5^3 225 >>> summation(9, lambda x: x + 1) # 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 54 >>> summation(5, lambda x: 2**x) # 2^1 + 2^2 + 2^3 + 2^4 + 2^5 62 \"\"\" assert n >= 1 if n == 1: return term(n) else: return term(n) + summation(n-1, term)","title":"sum of first n terms"},{"location":"CS61A/ex-recursion/#cascade","text":"def cascade(n): if n < 10: print(n) else: print(n) cascade(n//10) print(n) alternatively def cascade(n): print(n) if n > 10: cascade(n//10) print(n) results >>> print(123) 123 12 1 12 123","title":"cascade"},{"location":"CS61A/ex-recursion/#inverse-cascade","text":"hint grow prints out: 1, 12, 123 print prints out 123 shrink prints out 123, 12, 12 def inverse_cascade(n): grow(n) print(n) shrink(n) def f_then_g(f, g, n): if n: f(n) g(n) grow = lambda n: f_then_g() shrink = lambda n: f_then_g() solution grow = lambda n: f_then_g(grow, print, n//10) shrink = lambda n: f_then_g(print, shrink, n//10)","title":"inverse cascade"},{"location":"CS61A/ex-recursion/#hailstone","text":"Douglas Hofstadter's Pulitzer-prize-winning book, G\u00f6del, Escher, Bach , poses the following mathematical puzzle. Pick a positive integer n as the start. If n is even, divide it by 2. If n is odd, multiply it by 3 and add 1. Continue this process until n is 1. def hailstone(n): count = 1 if n <= 0: print('pick a positive number') return 0 else: print(n) while n != 1: if n % 2 == 0: n = n / 2 else: n = n * 3 + 1 print(n) count += 1 return count recursive def hailstone(n): print(n) if n == 1: return n elif n % 2 == 0: return 1 + hailstone(n // 2) else: return 1 + hailstone(3 * n + 1)","title":"hailstone"},{"location":"CS61A/ex-recursion/#merge-digits","text":"take s numbers with digits in decreasing order returns a single number with all of the digits of the two in decreasing order def merge(n1, n2): if n1 == 0: return n2 elif n2 == 0: return n1 elif n1 % 10 < n2 % 10: return merge(n1 // 10, n2) * 10 + n1 % 10 else: return merge(n1, n2 // 10) * 10 + n2 % 10","title":"merge digits"},{"location":"CS61A/ex-recursion/#missing-digits","text":"def missing_digits(n): \"\"\"Given a number a that is in sorted, increasing order, return the number of missing digits in n. A missing digit is a number between the first and last digit of a that is not in n. >>> missing_digits(1248) # 3, 5, 6, 7 4 >>> missing_digits(1122) # No missing numbers 0 >>> missing_digits(123456) # No missing numbers 0 >>> missing_digits(3558) # 4, 6, 7 3 >>> missing_digits(35578) # 4, 6 2 >>> missing_digits(12456) # 3 1 >>> missing_digits(16789) # 2, 3, 4, 5 4 >>> missing_digits(19) # 2, 3, 4, 5, 6, 7, 8 7 >>> missing_digits(4) # No missing numbers between 4 and 4 0 \"\"\" def missing_digits(n): if n < 10: return 0 else: last_digit = n % 10 second_to_last_digit = n // 10 % 10 if last_digit == second_to_last_digit: return missing_digits(n // 10) else: return (last_digit - second_to_last_digit - 1) + missing_digits(n // 10)","title":"missing digits"},{"location":"CS61A/ex-recursion/#skip-add","text":"def skip_add(n): \"\"\" Takes a number n and returns n + n-2 + n-4 + n-6 + ... + 0. >>> skip_add(5) # 5 + 3 + 1 + 0 9 >>> skip_add(10) # 10 + 8 + 6 + 4 + 2 + 0 30 \"\"\" if n <= 0: return 0 else: return n + skip_add(n-2)","title":"skip add"},{"location":"CS61A/ex-recursion/#factorial","text":"def fact(n): if n == 0: return 1 else: return n * fact(n-1) def fact_iter(n): total, k = 1, 1 while k <= n: total, k = total * k, k + 1 return total","title":"factorial"},{"location":"CS61A/ex-recursion/#prime-number","text":"while loop def is_prime(n): \"\"\" >>> is_prime(10) False >>> is_prime(7) True \"\"\" if n == 1: return False else: i = 2 while i < n: if n % i == 0: return False break else: i += 1 return True for loop def is_prime(n): \"\"\" >>> is_prime(10) False >>> is_prime(7) True \"\"\" if n == 1: return False else: for i in range(2, n): if n % i == 0: return False break else: return True recursive def is_prime(n): def prime_helper(i): if i == n: return True elif n % i == 0 or n == 1: return False else: return prime_helper(i+1) return prime_helper(2) # i starts from 2","title":"prime number"},{"location":"CS61A/ex-recursion/#pingpong","text":"def pingpong(n): \"\"\"Return the nth element of the ping-pong sequence. >>> pingpong(8) 8 >>> pingpong(10) 6 >>> pingpong(15) 1 >>> pingpong(21) -1 >>> pingpong(22) -2 >>> pingpong(30) -2 >>> pingpong(68) 0 >>> pingpong(69) -1 >>> pingpong(80) 0 >>> pingpong(81) 1 >>> pingpong(82) 0 >>> pingpong(100) -6 \"\"\" def pingpong_helper(x, direction, base): if x == n: return base + direction elif x % 8 == 0 or num_eights(x)>0: return pingpong_helper(x+1, -direction, base + direction) else: return pingpong_helper(x+1, direction, base + direction) return pingpong_helper(1, 1, 0) iterative def pingpong_itr(n): i, value, direction = 1, 1, 1 while i < n: if i % 8 == 0 or num_eights(i)>0: direction = -direction value += direction i += 1 return value","title":"pingpong"},{"location":"CS61A/ex-recursion/#count-coins","text":"def next_largest_coin(coin): \"\"\"Return the next coin. >>> next_largest_coin(1) 5 >>> next_largest_coin(5) 10 >>> next_largest_coin(10) 25 >>> next_largest_coin(2) # Other values return None \"\"\" if coin == 1: return 5 elif coin == 5: return 10 elif coin == 10: return 25 def count_coins(total): \"\"\"Return the number of ways to make change for total using coins of value of 1, 5, 10, 25. >>> count_coins(15) 6 >>> count_coins(10) 4 >>> count_coins(20) 9 >>> count_coins(100) # How many ways to make change for a dollar? 242 \"\"\" def count_coins(total): def coin_helper(total, coin): if total < 0: return 0 elif total == 0: return 1 elif coin is None: return 0 else: cur_coin = coin_helper(total - coin, coin) next_coin = coin_helper(total, next_largest_coin(coin)) return cur_coin + next_coin return coin_helper(total, 1) # doesn't work for count_coins(100), why?","title":"count coins"},{"location":"CS61A/ex-recursion/#count-paths-in-grid","text":"def paths(m, n): \"\"\"Return the number of paths from one corner of an M by N grid to the opposite corner. >>> paths(2, 2) 2 >>> paths(5, 7) 210 >>> paths(117, 1) 1 >>> paths(1, 157) 1 \"\"\" if m == 1 and n == 1: # start return 1 elif m == 1: # left edge return paths(m, n-1) elif n == 1: # bottom edge return paths(m-1, n) else: return paths(m, n-1) + paths(m-1, n)","title":"count paths in grid"},{"location":"CS61A/ex-recursion/#count-stairs-for-n-steps","text":"take 1 or 2 steps each time # my sln def count_stair_ways(n): if n == 1: return 1 elif n == 2: return 2 else: return count_stair_ways(n-1) + count_stair_ways(n-2) # don't need else def count_stair_ways(n): if n == 1: return 1 elif n == 2: return 2 return count_stair_ways(n-1) + count_stair_ways(n-2) take up to k steps at a time def count_k(n, k): \"\"\" >>> count_k(3, 3) # 3, 2 + 1, 1 + 2, 1 + 1 + 1 4 >>> count_k(4, 4) 8 >>> count_k(10, 3) 274 >>> count_k(300, 1) # Only one step at a time 1 \"\"\" if n == 0: return 1 elif n < 0: return 0 else: # count_k(n-1, k) + count_k(n-2, k) + ... + count_k(n-k, k) total = 0 i = 1 while i <= k: total += count_k(n-i, k) i += 1 return total","title":"count stairs for n steps"},{"location":"CS61A/ex-recursion/#max-product-of-nonconsecutive-elements","text":"def max_product(s): \"\"\"Return the maximum product that can be formed using non-consecutive elements of s. >>> max_product([10,3,1,9,2]) # 10 * 9 90 >>> max_product([5,10,5,10,5]) # 5 * 5 * 5 125 >>> max_product([]) 1 \"\"\" if len(s) == 0: return 1 elif len(s) == 1: return s[0] else: return max(max_product(s[1:]), s[0] * max_product(s[2:]))","title":"max product of nonconsecutive elements"},{"location":"CS61A/ex-recursion/#insert-into-all","text":"def insert_into_all(item, nested_list): \"\"\"Assuming that nested_list is a list of lists, return a new list consisting of all the lists in nested_list, but with item added to the front of each. >>> nl = [[], [1, 2], [3]] >>> insert_into_all(0, nl) [[0], [0, 1, 2], [0, 3]] \"\"\" return [[item] + i for i in nested_list]","title":"insert into all"},{"location":"CS61A/ex-recursion/#subsequence","text":"def subseqs(s): \"\"\" >>> seqs = subseqs([1, 2, 3]) >>> sorted(seqs) [[], [1], [1, 2], [1, 2, 3], [1, 3], [2], [2, 3], [3]] >>> subseqs([]) [[]] \"\"\" if len(s) == 0: return [[]] else: exclude_first = subseqs(s[1:]) include_first = [[s[0]] + e for e in exclude_first] # include_first = insert_into_all([s[0]], exclude_first) return exclude_first + include_first","title":"subsequence"},{"location":"CS61A/ex-recursion/#increasing-subsequence","text":"def inc_subseqs(s): \"\"\" >>> seqs = inc_subseqs([1, 3, 2]) >>> sorted(seqs) [[], [1], [1, 2], [1, 3], [2], [3]] >>> inc_subseqs([]) [[]] >>> seqs2 = inc_subseqs([1, 1, 2]) >>> sorted(seqs2) [[], [1], [1], [1, 1], [1, 1, 2], [1, 2], [1, 2], [2]] \"\"\" def subseq_helper(s, prev): if not s: return [[]] elif s[0] < prev: return subseq_helper(s[1:], prev) else: include = subseq_helper(s[1:], s[0]) exclude = subseq_helper(s[1:], prev) return insert_into_all(s[0], include) + exclude return subseq_helper(s, 0)","title":"increasing subsequence"},{"location":"CS61A/ex-recursion/#max-subsequence","text":"def max_subseq(n, t): \"\"\" Return the maximum subsequence of length at most t that can be found in the given number n. For example, for n = 20125 and t = 3, we have that the subsequences are 2 0 1 2 5 20 21 22 25 01 02 05 12 15 25 201 202 205 212 215 225 012 015 025 125 and of these, the maxumum number is 225, so our answer is 225. >>> max_subseq(20125, 3) 225 >>> max_subseq(20125, 5) 20125 >>> max_subseq(20125, 6) # note that 20125 == 020125 20125 >>> max_subseq(12345, 3) 345 >>> max_subseq(12345, 0) # 0 is of length 0 0 >>> max_subseq(12345, 1) 5 \"\"\" if t == 0 or n == 0: return 0 last_digit = n % 10 rest = n // 10 keep_last_digit = max_subseq(rest, t-1) * 10 + last_digit drop_last_digit = max_subseq(rest, t) return max(keep_last_digit, drop_last_digit)","title":"max subsequence"},{"location":"CS61A/ex-recursion/#add-characters","text":"def add_chars(w1, w2): \"\"\" Return a string containing the characters you need to add to w1 to get w2. You may assume that w1 is a subsequence of w2. >>> add_chars(\"owl\", \"howl\") 'h' >>> add_chars(\"want\", \"wanton\") 'on' >>> add_chars(\"rat\", \"radiate\") 'diae' >>> add_chars(\"a\", \"prepare\") 'prepre' >>> add_chars(\"resin\", \"recursion\") 'curo' >>> add_chars(\"fin\", \"effusion\") 'efuso' >>> add_chars(\"coy\", \"cacophony\") 'acphon' \"\"\" if len(w1) == 0: return w2 if w1[0] == w2[0]: return add_chars(w1[1:], w2[1:]) else: return w2[0] + add_chars(w1, w2[1:])","title":"add characters"},{"location":"CS61A/ex-recursion/#reverse-string","text":"def reverse(s): if len(s) == 1: return s else: return reverse(s[1:]) + s[0] def reverse(s): if len(s) == 0: return '' else: return reverse(s[1:]) + s[0]","title":"reverse string"},{"location":"CS61A/ex-recursion/#sequence-iteration","text":"def mysum(L): if L == []: return 0 else: return L[0] + mysum(L[1:]) iterations # index def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total, index = 0, 0 while index < len(s): if s[index] == value: total = total + 1 index = index + 1 return total # element def count(s, value): \"\"\"Count the number of occurrences of value in sequence s.\"\"\" total = 0 for elem in s: if elem == value: total = total + 1 return total","title":"sequence iteration"},{"location":"CS61A/ex-recursion/#pascals-triangle","text":"1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 def pascal(row, column): \"\"\"Returns the value of the item in Pascal's Triangle whose position is specified by row and column. >>> pascal(0, 0) 1 >>> pascal(0, 5) # Empty entry; outside of Pascal's Triangle 0 >>> pascal(3, 2) # Row 3 (1 3 3 1), Column 2 3 >>> pascal(4, 2) # Row 4 (1 4 6 4 1), Column 2 6 \"\"\" if column == 0: return 1 elif row == 0: return 0 else: return pascal(row - 1, column) + pascal(row - 1, column - 1)","title":"Pascal's Triangle"},{"location":"CS61A/ex-recursion/#knapsack","text":"def knapsack(weights, values, c): \"\"\" takes a list weights, list values and a capacity c return that max value >>> w = [2, 6, 3, 3] >>> v = [1, 5, 3, 3] >>> knapsack(w, v, 6) 6 \"\"\" \"*** YOUR CODE HERE ***\" if len(weights) == 0: return 0 else: first_weight, rest_weight = weights[0], weights[1:] first_value, rest_value = values[0], values[1:] with_first = first_value + knapsack(rest_weight, rest_value, c - first_weight) without_first = knapsack(rest_weight, rest_value, c) if first_weight <= c: return max(with_first, without_first) else: return without_first","title":"Knapsack"},{"location":"CS61A/ex-recursion/#mutual-recursion","text":"","title":"Mutual Recursion"},{"location":"CS61A/ex-recursion/#luhn-sum-credit-card-validation","text":"checksum = a multiple of 10 def luhn_sum(n): if n < 10: return n else: all_but_last, last = n // 10, n % 10 return luhn_sum_double(all_but_last) + last def luhn_sum_double(n): all_but_last, last = n // 10, n % 10 luhn_digit = sum_digits(2 * last) if n < 10: return n else: return luhn_sum(all_but_last) + luhn_digit","title":"luhn sum - credit card validation"},{"location":"CS61A/ex-recursion/#even-or-odd","text":"def is_even(n): if n == 0: return True else: return is_odd(n-1) def is_odd(n): if n == 0: return False else: return is_even(n-1) result = is_even(4) all-in-one def is_even(n): if n == 0: return True else: if (n-1) == 0: return False else: return is_even((n-1)-1)","title":"even or odd"},{"location":"CS61A/ex-recursion/#subpaths","text":"def paths(x, y): \"\"\"Return a list of ways to reach y from x by repeated incrementing or doubling. >>> paths(3, 5) [[3, 4, 5]] >>> sorted(paths(3, 6)) [[3, 4, 5, 6], [3, 6]] >>> sorted(paths(3, 9)) [[3, 4, 5, 6, 7, 8, 9], [3, 4, 8, 9], [3, 6, 7, 8, 9]] >>> paths(3, 3) # No calls is a valid path [[3]] \"\"\" if x > y: return [] elif x == y: return [[x]] else: a = paths(x+1, y) b = paths(2*x, y) return [[x] + subpath for subpath in a+b]","title":"subpaths"},{"location":"CS61A/ex-sequence/","text":"Sequence list basics append >>> [2, 7] + digits * 2 [2, 7, 1, 8, 2, 8, 1, 8, 2, 8] make a copy s = [1, 2, 3] t = list(s) append vs extend >>> l = [1, 2, 3] >>> l.append(4) >>> l [1, 2, 3, 4] >>> l.append([5,6]) >>> l [1, 2, 3, 4, [5, 6]] >>> l.extend([7,8]) >>> l [1, 2, 3, 4, [5, 6], 7, 8] >>> l.extend(9) !ERROR! list comprehension >>> odds = [1, 3, 5, 7, 9] >>> [x+1 for x in odds] [2, 4, 6, 8, 10] >>> [x for x in odds if 25 % x == 0] [1, 5] even weighted def even_weighted(s): \"\"\" >>> x = [1, 2, 3, 4, 5, 6] >>> even_weighted(x) [0, 6, 20] \"\"\" return [s[i] * i for i in range(len(s)) if i % 2 == 0] closest in the list the number in the list, whose square is closest to 24 >>> min([3, 2, 5, 6], key=lambda x: abs(x*x - 24)) 5 call another function >>> def f(x, y): ... return abs(x * x - y) ... >>> min([3, 2, 5, 6], key=lambda x: f(x, 24)) 5 messy way >>> f = lambda x: abs(x*x - 24) >>> [f(x) for x in [3,2,5,6]] [15, 20, 1, 12] >>> [[f(x),x] for x in [3,2,5,6]] [[15, 3], [20, 2], [1, 5], [12, 6]] >>> min([[f(x),x] for x in [3,2,5,6]]) [1, 5] >>> min([[f(x),x] for x in [3,2,5,6]])[1] 5 couple list def couple(s, t): \"\"\"Return a list of two-element lists in which the i-th element is [s[i], t[i]].\"\"\" assert len(s) == len(t) return [[s[i], t[i]] for i in range(len(s))] add matrices def add_matrices(x, y): \"\"\" >>> matrix1 = [[1, 3], ... [2, 0]] >>> matrix2 = [[-3, 0], ... [1, 2]] >>> add_matrices(matrix1, matrix2) [[-2, 3], [3, 2]] \"\"\" return [[x[i][j] + y[i][j] for j in range(len(x[0]))] for i in range(len(x))] riffle deck def riffle(deck): \"\"\"Produces a single, perfect riffle shuffle of DECK, consisting of DECK[0], DECK[M], DECK[1], DECK[M+1], ... where M is position of the second half of the deck. Assume that len(DECK) is even. >>> riffle([3, 4, 5, 6]) [3, 5, 4, 6] >>> riffle(range(20)) [0, 10, 1, 11, 2, 12, 3, 13, 4, 14, 5, 15, 6, 16, 7, 17, 8, 18, 9, 19] \"\"\" return [ deck[(i % 2) * len(deck)//2 + i // 2] for i in range(len(deck)) ] if this not that def if_this_not_that(i_list, this): \"\"\"Define a function which takes a list of integers `i_list` and an integer `this`. For each element in `i_list`, print the element if it is larger than `this`; otherwise, print the word \"that\". >>> original_list = [1, 2, 3, 4, 5] >>> if_this_not_that(original_list, 3) that that that 4 5 \"\"\" [print(i_list[i]) if i_list[i] > this else print('that') for i in range(len(i_list))] insert item after element def insert_items(lst, entry, elem): \"\"\" >>> test_lst = [1, 5, 8, 5, 2, 3] >>> new_lst = insert_items(test_lst, 5, 7) >>> new_lst [1, 5, 7, 8, 5, 7, 2, 3] >>> large_lst = [1, 4, 8] >>> large_lst2 = insert_items(large_lst, 4, 4) >>> large_lst2 [1, 4, 4, 8] >>> large_lst3 = insert_items(large_lst2, 4, 6) >>> large_lst3 [1, 4, 6, 4, 6, 8] >>> large_lst3 is large_lst True \"\"\" \"*** YOUR CODE HERE ***\" # for i in range(len(lst)): # if lst[i] == entry: # lst.insert(i+1, elem) # return lst # does not satisfy large_lst2 = insert_items(large_lst, 4, 4) index_lst = [] for i in range(len(lst)): if lst[i] == entry: index_lst.append(i) for i1, i2 in zip(index_lst, range(len(index_lst))): lst.insert(i1+i2+1, elem) return lst countdown def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k yield from countdown(k-1) otherwise, it will be def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k for x in countdown(k-1): yield x prefix of string yield vs yield from def prefixes(s): \"\"\" >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: yield from prefixes(s[:-1]) yield s yield from , a shortcut, can be replaced by a for statement. def prefixes(s): \"\"\" >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s changing the order of yield s def prefixes2(s): \"\"\" >>> result = prefixes2('dogs') >>> list(result) ['dogs', 'dog', 'do', 'd'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s merge (TBD) flatten (TBD) permutation def permutations(seq): \"\"\"Generates all permutations of the given sequence. Each permutation is a list of the elements in SEQ in a different order. The permutations may be yielded in any order. >>> perms = permutations([100]) >>> type(perms) <class 'generator'> >>> next(perms) [100] >>> try: #this piece of code prints \"No more permutations!\" if calling next would cause an error ... next(perms) ... except StopIteration: ... print('No more permutations!') No more permutations! >>> sorted(permutations([1, 2, 3])) # Returns a sorted list containing elements of the generator [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] >>> sorted(permutations((10, 20, 30))) [[10, 20, 30], [10, 30, 20], [20, 10, 30], [20, 30, 10], [30, 10, 20], [30, 20, 10]] >>> sorted(permutations(\"ab\")) [['a', 'b'], ['b', 'a']] \"\"\" if not seq: yield [] else: for perm in permutations([x for x in seq if x != seq[0]]): for k in range(len(perm) + 1): yield perm[:k] + [seq[0]] + perm[k:] or def permutations(s): \"\"\" yield permutations of list s >>> list(permutations([1, 2, 3])) [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] \"\"\" if len(s) == 0: yield [] for i in range(len(s)): start = s[i] # 2 rest = [s[j] for j in range(len(s)) if j != i] # [1, 3] for rest_permutation in permutations(rest): yield [start] + rest_permutation # [2, 1, 3] or [2, 3, 1] or def permutations(s): \"\"\" yield permutations of list s >>> list(permutations([1, 2, 3])) [[1, 2, 3], [2, 1, 3], [2, 3, 1], [1, 3, 2], [3, 1, 2], [3, 2, 1]] \"\"\" if len(s) == 0: yield [] else: first = s[0] # 1 rest = s[1:] # [2, 3] for rest_permutation in permutations(rest): for i in range(len(s)): result = list(rest_permutation) result.insert(i, first) yield result modification to work with string def permutations(s): \"\"\" yield permutations of list s >>> list(permutations('abc')) ['abc', 'bac', 'bca', 'acb', 'cab', 'cba'] \"\"\" if len(s) == 0: yield '' else: first = s[0] rest = s[1:] for rest_permutations in permutations(rest): for i in range(len(s)): yield rest_permutations[:i] + first + rest_permutations[i:] remainder generator def naturals(): \"\"\"A generator function that yields the infinite sequence of natural numbers, starting at 1. >>> m = naturals() >>> type(m) <class 'generator'> >>> [next(m) for _ in range(10)] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \"\"\" i = 1 while True: yield i i += 1 def remainders_generator(m): \"\"\" Yields m generators. The ith yielded generator yields natural numbers whose remainder is i when divided by m. >>> import types >>> [isinstance(gen, types.GeneratorType) for gen in remainders_generator(5)] [True, True, True, True, True] >>> remainders_four = remainders_generator(4) >>> for i in range(4): ... print(\"First 3 natural numbers with remainder {0} when divided by 4:\".format(i)) ... gen = next(remainders_four) ... for _ in range(3): ... print(next(gen)) First 3 natural numbers with remainder 0 when divided by 4: 4 8 12 First 3 natural numbers with remainder 1 when divided by 4: 1 5 9 First 3 natural numbers with remainder 2 when divided by 4: 2 6 10 First 3 natural numbers with remainder 3 when divided by 4: 3 7 11 \"\"\" def generator(n): while True: yield n n += m for n in naturals(): yield generator(n) filter, map on range square, odd = lambda x: x * x, lambda x: x % 2 == 1 list(map(square, filter(odd, range(1,6)))) # [1, 9, 25] scale iterable def scale(it, multiplier): \"\"\"Yield elements of the iterable it scaled by a number multiplier. >>> m = scale([1, 5, 2], 5) >>> type(m) <class 'generator'> >>> list(m) [5, 25, 10] >>> m = scale(naturals(), 2) >>> [next(m) for _ in range(5)] [2, 4, 6, 8, 10] \"\"\" yield from map(lambda x: x * multiplier, it) min abs indices def min_abs_indices(s): \"\"\" Indices of all elements in list that equal to the smallest absolute value. >>> min_abs_indices([-4, -3, -2, 3, 2, 4]) [2, 4] >>> min_abs_indices([1, 2, 3, 4, 5]) [0] \"\"\" min_abs = min(map(abs, s)) return [i for i in range(len(s)) if abs(s[i]) == min_abs] largest adjacent sum def largest_adj_sum(s): \"\"\" Largest sum of the two adjacent elements in a list s. >>> largest_adj_sum([-4, -3, -2, -3, 2, 4]) 6 >>> largest_adj_sum([-4, 3, -2, -3, 2, -4]) 1 \"\"\" return max([s[i] + s[i+1] for i in range(len(s)-1)]) zip def largest_adj_sum(s): \"\"\" Largest sum of the two adjacent elements in a list s. >>> largest_adj_sum([-4, -3, -2, -3, 2, 4]) 6 >>> largest_adj_sum([-4, 3, -2, -3, 2, -4]) 1 \"\"\" return max([a + b for a, b in zip(s[:-1], s[1:])]) all have an equal def all_have_an_equal(s): \"\"\" Does every element equal to some other element in s? >>> all_have_an_equal([-4, -3, -2, 3, 2, 4]) False >>> all_have_an_equal([4, 3, 2, 3, 2, 4]) True \"\"\" return all([s[i] in s[:i] + s[i+i:] for i in range(len(s))]) alternatively def all_have_an_equal(s): \"\"\" Does every element equal to some other element in s? >>> all_have_an_equal([-4, -3, -2, 3, 2, 4]) False >>> all_have_an_equal([4, 3, 2, 3, 2, 4]) True \"\"\" return min([sum(1 for y in s if y == x) for x in s]) > 1 alternatively def all_have_an_equal(s): \"\"\" Does every element equal to some other element in s? >>> all_have_an_equal([-4, -3, -2, 3, 2, 4]) False >>> all_have_an_equal([4, 3, 2, 3, 2, 4]) True \"\"\" return min([s.count(x) for x in s]) > 1 trade equal prefix (TBD) shuffle cards def card(n): \"\"\"Return the playing card numeral as a string for a positive n <= 13.\"\"\" assert type(n) == int and n > 0 and n <= 13, \"Bad card n\" specials = {1: 'A', 11: 'J', 12: 'Q', 13: 'K'} return specials.get(n, str(n)) def shuffle(cards): \"\"\"Return a shuffled list that interleaves the two halves of cards. >>> shuffle(range(6)) [0, 3, 1, 4, 2, 5] >>> suits = ['\u2661', '\u2662', '\u2664', '\u2667'] >>> cards = [card(n) + suit for n in range(1,14) for suit in suits] >>> cards[:12] ['A\u2661', 'A\u2662', 'A\u2664', 'A\u2667', '2\u2661', '2\u2662', '2\u2664', '2\u2667', '3\u2661', '3\u2662', '3\u2664', '3\u2667'] >>> cards[26:30] ['7\u2664', '7\u2667', '8\u2661', '8\u2662'] >>> shuffle(cards)[:12] ['A\u2661', '7\u2664', 'A\u2662', '7\u2667', 'A\u2664', '8\u2661', 'A\u2667', '8\u2662', '2\u2661', '8\u2664', '2\u2662', '8\u2667'] >>> shuffle(shuffle(cards))[:12] ['A\u2661', '4\u2662', '7\u2664', '10\u2667', 'A\u2662', '4\u2664', '7\u2667', 'J\u2661', 'A\u2664', '4\u2667', '8\u2661', 'J\u2662'] >>> cards[:12] # Should not be changed ['A\u2661', 'A\u2662', 'A\u2664', 'A\u2667', '2\u2661', '2\u2662', '2\u2664', '2\u2667', '3\u2661', '3\u2662', '3\u2664', '3\u2667'] \"\"\" assert len(cards) % 2 == 0, 'len(cards) must be even' half = len(cards) // 2 shuffled = [] for i in range(half): shuffled += [cards[i], cards[half + i]] return shuffled Dictionary dict comprehension >>> squares = {x:x*x for x in range(10)} >>> squares {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81} >>> squares[7] 49 digit dict def digit_dict(s): \"\"\" Map each digit d to the lists of elements in s that end with d. >>> digit_dict([5, 8, 13, 21, 34, 55, 89]) {1: [21], [3]: [14],} \"\"\" last_digits = [x % 10 for x in s] return {d: [x for x in s if x % 10 == d] for d in range(len(s)) if d in last_digits} my solution def digit_dict(s): \"\"\" Map each digit d to the lists of elements in s that end with d. \"\"\" digit_dict = {} for d in s: last_digit = d % 10 if last_digit not in digit_dict: digit_dict[last_digit] = [d] else: digit_dict[last_digit].append(d) return digit_dict successor table def build_successors_table(tokens): \"\"\"Return a dictionary: keys are words; values are lists of successors. >>> text = ['We', 'came', 'to', 'investigate', ',', 'catch', 'bad', 'guys', 'and', 'to', 'eat', 'pie', '.'] >>> table = build_successors_table(text) >>> sorted(table) [',', '.', 'We', 'and', 'bad', 'came', 'catch', 'eat', 'guys', 'investigate', 'pie', 'to'] >>> table['to'] ['investigate', 'eat'] >>> table['pie'] ['.'] >>> table['.'] ['We'] \"\"\" table = {} prev = '.' for word in tokens: if prev not in table: table[prev] = [] table[prev] += [word] prev = word return table construct sentence def construct_sent(word, table): \"\"\"Prints a random sentence starting with word, sampling from table. >>> table = {'Wow': ['!'], 'Sentences': ['are'], 'are': ['cool'], 'cool': ['.']} >>> construct_sent('Wow', table) 'Wow!' >>> construct_sent('Sentences', table) 'Sentences are cool.' \"\"\" import random result = '' while word not in ['.', '!', '?']: result = result + ' ' + word word = random.choice(table[word]) return result.strip() + word decrypt alanturing def decrypt(s , d): \"\"\" List all possible decoded strings of s. >>> codes = { 'alan': 'spooky', 'al': 'drink', 'antu': 'your', 'turing': 'ghosts', 'tur': 'scary', 'ing': 'skeletons', 'ring': 'ovaltine' } >>> decrypt('alanturing', codes) ['drink your ovaltine', 'spooky ghosts', 'spooky scary skeletons'] \"\"\" if s == '': return [] messeges = [] if s in d: messeges.append(d[s]) for k in range(1, len(s)+1): first, suffix = s[:k], s[k:] if first in d: for rest in decrypt(suffix, d): messeges.append(d[first] + ' ' + rest) return messeges","title":"sequence"},{"location":"CS61A/ex-sequence/#sequence","text":"","title":"Sequence"},{"location":"CS61A/ex-sequence/#list-basics","text":"append >>> [2, 7] + digits * 2 [2, 7, 1, 8, 2, 8, 1, 8, 2, 8] make a copy s = [1, 2, 3] t = list(s) append vs extend >>> l = [1, 2, 3] >>> l.append(4) >>> l [1, 2, 3, 4] >>> l.append([5,6]) >>> l [1, 2, 3, 4, [5, 6]] >>> l.extend([7,8]) >>> l [1, 2, 3, 4, [5, 6], 7, 8] >>> l.extend(9) !ERROR!","title":"list basics"},{"location":"CS61A/ex-sequence/#list-comprehension","text":">>> odds = [1, 3, 5, 7, 9] >>> [x+1 for x in odds] [2, 4, 6, 8, 10] >>> [x for x in odds if 25 % x == 0] [1, 5]","title":"list comprehension"},{"location":"CS61A/ex-sequence/#even-weighted","text":"def even_weighted(s): \"\"\" >>> x = [1, 2, 3, 4, 5, 6] >>> even_weighted(x) [0, 6, 20] \"\"\" return [s[i] * i for i in range(len(s)) if i % 2 == 0]","title":"even weighted"},{"location":"CS61A/ex-sequence/#closest-in-the-list","text":"the number in the list, whose square is closest to 24 >>> min([3, 2, 5, 6], key=lambda x: abs(x*x - 24)) 5 call another function >>> def f(x, y): ... return abs(x * x - y) ... >>> min([3, 2, 5, 6], key=lambda x: f(x, 24)) 5 messy way >>> f = lambda x: abs(x*x - 24) >>> [f(x) for x in [3,2,5,6]] [15, 20, 1, 12] >>> [[f(x),x] for x in [3,2,5,6]] [[15, 3], [20, 2], [1, 5], [12, 6]] >>> min([[f(x),x] for x in [3,2,5,6]]) [1, 5] >>> min([[f(x),x] for x in [3,2,5,6]])[1] 5","title":"closest in the list"},{"location":"CS61A/ex-sequence/#couple-list","text":"def couple(s, t): \"\"\"Return a list of two-element lists in which the i-th element is [s[i], t[i]].\"\"\" assert len(s) == len(t) return [[s[i], t[i]] for i in range(len(s))]","title":"couple list"},{"location":"CS61A/ex-sequence/#add-matrices","text":"def add_matrices(x, y): \"\"\" >>> matrix1 = [[1, 3], ... [2, 0]] >>> matrix2 = [[-3, 0], ... [1, 2]] >>> add_matrices(matrix1, matrix2) [[-2, 3], [3, 2]] \"\"\" return [[x[i][j] + y[i][j] for j in range(len(x[0]))] for i in range(len(x))]","title":"add matrices"},{"location":"CS61A/ex-sequence/#riffle-deck","text":"def riffle(deck): \"\"\"Produces a single, perfect riffle shuffle of DECK, consisting of DECK[0], DECK[M], DECK[1], DECK[M+1], ... where M is position of the second half of the deck. Assume that len(DECK) is even. >>> riffle([3, 4, 5, 6]) [3, 5, 4, 6] >>> riffle(range(20)) [0, 10, 1, 11, 2, 12, 3, 13, 4, 14, 5, 15, 6, 16, 7, 17, 8, 18, 9, 19] \"\"\" return [ deck[(i % 2) * len(deck)//2 + i // 2] for i in range(len(deck)) ]","title":"riffle deck"},{"location":"CS61A/ex-sequence/#if-this-not-that","text":"def if_this_not_that(i_list, this): \"\"\"Define a function which takes a list of integers `i_list` and an integer `this`. For each element in `i_list`, print the element if it is larger than `this`; otherwise, print the word \"that\". >>> original_list = [1, 2, 3, 4, 5] >>> if_this_not_that(original_list, 3) that that that 4 5 \"\"\" [print(i_list[i]) if i_list[i] > this else print('that') for i in range(len(i_list))]","title":"if this not that"},{"location":"CS61A/ex-sequence/#insert-item-after-element","text":"def insert_items(lst, entry, elem): \"\"\" >>> test_lst = [1, 5, 8, 5, 2, 3] >>> new_lst = insert_items(test_lst, 5, 7) >>> new_lst [1, 5, 7, 8, 5, 7, 2, 3] >>> large_lst = [1, 4, 8] >>> large_lst2 = insert_items(large_lst, 4, 4) >>> large_lst2 [1, 4, 4, 8] >>> large_lst3 = insert_items(large_lst2, 4, 6) >>> large_lst3 [1, 4, 6, 4, 6, 8] >>> large_lst3 is large_lst True \"\"\" \"*** YOUR CODE HERE ***\" # for i in range(len(lst)): # if lst[i] == entry: # lst.insert(i+1, elem) # return lst # does not satisfy large_lst2 = insert_items(large_lst, 4, 4) index_lst = [] for i in range(len(lst)): if lst[i] == entry: index_lst.append(i) for i1, i2 in zip(index_lst, range(len(index_lst))): lst.insert(i1+i2+1, elem) return lst","title":"insert item after element"},{"location":"CS61A/ex-sequence/#countdown","text":"def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k yield from countdown(k-1) otherwise, it will be def countdown(k): \"\"\"Count down to zero. >>> list(countdown(5)) [5, 4, 3, 2, 1] \"\"\" if k > 0: yield k for x in countdown(k-1): yield x","title":"countdown"},{"location":"CS61A/ex-sequence/#prefix-of-string","text":"yield vs yield from def prefixes(s): \"\"\" >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: yield from prefixes(s[:-1]) yield s yield from , a shortcut, can be replaced by a for statement. def prefixes(s): \"\"\" >>> result = prefixes('dogs') >>> list(result) ['d', 'do', 'dog', 'dogs'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s changing the order of yield s def prefixes2(s): \"\"\" >>> result = prefixes2('dogs') >>> list(result) ['dogs', 'dog', 'do', 'd'] \"\"\" if s: for x in prefixes(s[:-1]): yield x yield s","title":"prefix of string"},{"location":"CS61A/ex-sequence/#merge-tbd","text":"","title":"merge (TBD)"},{"location":"CS61A/ex-sequence/#flatten-tbd","text":"","title":"flatten (TBD)"},{"location":"CS61A/ex-sequence/#permutation","text":"def permutations(seq): \"\"\"Generates all permutations of the given sequence. Each permutation is a list of the elements in SEQ in a different order. The permutations may be yielded in any order. >>> perms = permutations([100]) >>> type(perms) <class 'generator'> >>> next(perms) [100] >>> try: #this piece of code prints \"No more permutations!\" if calling next would cause an error ... next(perms) ... except StopIteration: ... print('No more permutations!') No more permutations! >>> sorted(permutations([1, 2, 3])) # Returns a sorted list containing elements of the generator [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] >>> sorted(permutations((10, 20, 30))) [[10, 20, 30], [10, 30, 20], [20, 10, 30], [20, 30, 10], [30, 10, 20], [30, 20, 10]] >>> sorted(permutations(\"ab\")) [['a', 'b'], ['b', 'a']] \"\"\" if not seq: yield [] else: for perm in permutations([x for x in seq if x != seq[0]]): for k in range(len(perm) + 1): yield perm[:k] + [seq[0]] + perm[k:] or def permutations(s): \"\"\" yield permutations of list s >>> list(permutations([1, 2, 3])) [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] \"\"\" if len(s) == 0: yield [] for i in range(len(s)): start = s[i] # 2 rest = [s[j] for j in range(len(s)) if j != i] # [1, 3] for rest_permutation in permutations(rest): yield [start] + rest_permutation # [2, 1, 3] or [2, 3, 1] or def permutations(s): \"\"\" yield permutations of list s >>> list(permutations([1, 2, 3])) [[1, 2, 3], [2, 1, 3], [2, 3, 1], [1, 3, 2], [3, 1, 2], [3, 2, 1]] \"\"\" if len(s) == 0: yield [] else: first = s[0] # 1 rest = s[1:] # [2, 3] for rest_permutation in permutations(rest): for i in range(len(s)): result = list(rest_permutation) result.insert(i, first) yield result modification to work with string def permutations(s): \"\"\" yield permutations of list s >>> list(permutations('abc')) ['abc', 'bac', 'bca', 'acb', 'cab', 'cba'] \"\"\" if len(s) == 0: yield '' else: first = s[0] rest = s[1:] for rest_permutations in permutations(rest): for i in range(len(s)): yield rest_permutations[:i] + first + rest_permutations[i:]","title":"permutation"},{"location":"CS61A/ex-sequence/#remainder-generator","text":"def naturals(): \"\"\"A generator function that yields the infinite sequence of natural numbers, starting at 1. >>> m = naturals() >>> type(m) <class 'generator'> >>> [next(m) for _ in range(10)] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \"\"\" i = 1 while True: yield i i += 1 def remainders_generator(m): \"\"\" Yields m generators. The ith yielded generator yields natural numbers whose remainder is i when divided by m. >>> import types >>> [isinstance(gen, types.GeneratorType) for gen in remainders_generator(5)] [True, True, True, True, True] >>> remainders_four = remainders_generator(4) >>> for i in range(4): ... print(\"First 3 natural numbers with remainder {0} when divided by 4:\".format(i)) ... gen = next(remainders_four) ... for _ in range(3): ... print(next(gen)) First 3 natural numbers with remainder 0 when divided by 4: 4 8 12 First 3 natural numbers with remainder 1 when divided by 4: 1 5 9 First 3 natural numbers with remainder 2 when divided by 4: 2 6 10 First 3 natural numbers with remainder 3 when divided by 4: 3 7 11 \"\"\" def generator(n): while True: yield n n += m for n in naturals(): yield generator(n)","title":"remainder generator"},{"location":"CS61A/ex-sequence/#filter-map-on-range","text":"square, odd = lambda x: x * x, lambda x: x % 2 == 1 list(map(square, filter(odd, range(1,6)))) # [1, 9, 25]","title":"filter, map on range"},{"location":"CS61A/ex-sequence/#scale-iterable","text":"def scale(it, multiplier): \"\"\"Yield elements of the iterable it scaled by a number multiplier. >>> m = scale([1, 5, 2], 5) >>> type(m) <class 'generator'> >>> list(m) [5, 25, 10] >>> m = scale(naturals(), 2) >>> [next(m) for _ in range(5)] [2, 4, 6, 8, 10] \"\"\" yield from map(lambda x: x * multiplier, it)","title":"scale iterable"},{"location":"CS61A/ex-sequence/#min-abs-indices","text":"def min_abs_indices(s): \"\"\" Indices of all elements in list that equal to the smallest absolute value. >>> min_abs_indices([-4, -3, -2, 3, 2, 4]) [2, 4] >>> min_abs_indices([1, 2, 3, 4, 5]) [0] \"\"\" min_abs = min(map(abs, s)) return [i for i in range(len(s)) if abs(s[i]) == min_abs]","title":"min abs indices"},{"location":"CS61A/ex-sequence/#largest-adjacent-sum","text":"def largest_adj_sum(s): \"\"\" Largest sum of the two adjacent elements in a list s. >>> largest_adj_sum([-4, -3, -2, -3, 2, 4]) 6 >>> largest_adj_sum([-4, 3, -2, -3, 2, -4]) 1 \"\"\" return max([s[i] + s[i+1] for i in range(len(s)-1)]) zip def largest_adj_sum(s): \"\"\" Largest sum of the two adjacent elements in a list s. >>> largest_adj_sum([-4, -3, -2, -3, 2, 4]) 6 >>> largest_adj_sum([-4, 3, -2, -3, 2, -4]) 1 \"\"\" return max([a + b for a, b in zip(s[:-1], s[1:])])","title":"largest adjacent sum"},{"location":"CS61A/ex-sequence/#all-have-an-equal","text":"def all_have_an_equal(s): \"\"\" Does every element equal to some other element in s? >>> all_have_an_equal([-4, -3, -2, 3, 2, 4]) False >>> all_have_an_equal([4, 3, 2, 3, 2, 4]) True \"\"\" return all([s[i] in s[:i] + s[i+i:] for i in range(len(s))]) alternatively def all_have_an_equal(s): \"\"\" Does every element equal to some other element in s? >>> all_have_an_equal([-4, -3, -2, 3, 2, 4]) False >>> all_have_an_equal([4, 3, 2, 3, 2, 4]) True \"\"\" return min([sum(1 for y in s if y == x) for x in s]) > 1 alternatively def all_have_an_equal(s): \"\"\" Does every element equal to some other element in s? >>> all_have_an_equal([-4, -3, -2, 3, 2, 4]) False >>> all_have_an_equal([4, 3, 2, 3, 2, 4]) True \"\"\" return min([s.count(x) for x in s]) > 1","title":"all have an equal"},{"location":"CS61A/ex-sequence/#trade-equal-prefix-tbd","text":"","title":"trade equal prefix (TBD)"},{"location":"CS61A/ex-sequence/#shuffle-cards","text":"def card(n): \"\"\"Return the playing card numeral as a string for a positive n <= 13.\"\"\" assert type(n) == int and n > 0 and n <= 13, \"Bad card n\" specials = {1: 'A', 11: 'J', 12: 'Q', 13: 'K'} return specials.get(n, str(n)) def shuffle(cards): \"\"\"Return a shuffled list that interleaves the two halves of cards. >>> shuffle(range(6)) [0, 3, 1, 4, 2, 5] >>> suits = ['\u2661', '\u2662', '\u2664', '\u2667'] >>> cards = [card(n) + suit for n in range(1,14) for suit in suits] >>> cards[:12] ['A\u2661', 'A\u2662', 'A\u2664', 'A\u2667', '2\u2661', '2\u2662', '2\u2664', '2\u2667', '3\u2661', '3\u2662', '3\u2664', '3\u2667'] >>> cards[26:30] ['7\u2664', '7\u2667', '8\u2661', '8\u2662'] >>> shuffle(cards)[:12] ['A\u2661', '7\u2664', 'A\u2662', '7\u2667', 'A\u2664', '8\u2661', 'A\u2667', '8\u2662', '2\u2661', '8\u2664', '2\u2662', '8\u2667'] >>> shuffle(shuffle(cards))[:12] ['A\u2661', '4\u2662', '7\u2664', '10\u2667', 'A\u2662', '4\u2664', '7\u2667', 'J\u2661', 'A\u2664', '4\u2667', '8\u2661', 'J\u2662'] >>> cards[:12] # Should not be changed ['A\u2661', 'A\u2662', 'A\u2664', 'A\u2667', '2\u2661', '2\u2662', '2\u2664', '2\u2667', '3\u2661', '3\u2662', '3\u2664', '3\u2667'] \"\"\" assert len(cards) % 2 == 0, 'len(cards) must be even' half = len(cards) // 2 shuffled = [] for i in range(half): shuffled += [cards[i], cards[half + i]] return shuffled","title":"shuffle cards"},{"location":"CS61A/ex-sequence/#dictionary","text":"","title":"Dictionary"},{"location":"CS61A/ex-sequence/#dict-comprehension","text":">>> squares = {x:x*x for x in range(10)} >>> squares {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81} >>> squares[7] 49","title":"dict comprehension"},{"location":"CS61A/ex-sequence/#digit-dict","text":"def digit_dict(s): \"\"\" Map each digit d to the lists of elements in s that end with d. >>> digit_dict([5, 8, 13, 21, 34, 55, 89]) {1: [21], [3]: [14],} \"\"\" last_digits = [x % 10 for x in s] return {d: [x for x in s if x % 10 == d] for d in range(len(s)) if d in last_digits} my solution def digit_dict(s): \"\"\" Map each digit d to the lists of elements in s that end with d. \"\"\" digit_dict = {} for d in s: last_digit = d % 10 if last_digit not in digit_dict: digit_dict[last_digit] = [d] else: digit_dict[last_digit].append(d) return digit_dict","title":"digit dict"},{"location":"CS61A/ex-sequence/#successor-table","text":"def build_successors_table(tokens): \"\"\"Return a dictionary: keys are words; values are lists of successors. >>> text = ['We', 'came', 'to', 'investigate', ',', 'catch', 'bad', 'guys', 'and', 'to', 'eat', 'pie', '.'] >>> table = build_successors_table(text) >>> sorted(table) [',', '.', 'We', 'and', 'bad', 'came', 'catch', 'eat', 'guys', 'investigate', 'pie', 'to'] >>> table['to'] ['investigate', 'eat'] >>> table['pie'] ['.'] >>> table['.'] ['We'] \"\"\" table = {} prev = '.' for word in tokens: if prev not in table: table[prev] = [] table[prev] += [word] prev = word return table","title":"successor table"},{"location":"CS61A/ex-sequence/#construct-sentence","text":"def construct_sent(word, table): \"\"\"Prints a random sentence starting with word, sampling from table. >>> table = {'Wow': ['!'], 'Sentences': ['are'], 'are': ['cool'], 'cool': ['.']} >>> construct_sent('Wow', table) 'Wow!' >>> construct_sent('Sentences', table) 'Sentences are cool.' \"\"\" import random result = '' while word not in ['.', '!', '?']: result = result + ' ' + word word = random.choice(table[word]) return result.strip() + word","title":"construct sentence"},{"location":"CS61A/ex-sequence/#decrypt-alanturing","text":"def decrypt(s , d): \"\"\" List all possible decoded strings of s. >>> codes = { 'alan': 'spooky', 'al': 'drink', 'antu': 'your', 'turing': 'ghosts', 'tur': 'scary', 'ing': 'skeletons', 'ring': 'ovaltine' } >>> decrypt('alanturing', codes) ['drink your ovaltine', 'spooky ghosts', 'spooky scary skeletons'] \"\"\" if s == '': return [] messeges = [] if s in d: messeges.append(d[s]) for k in range(1, len(s)+1): first, suffix = s[:k], s[k:] if first in d: for rest in decrypt(suffix, d): messeges.append(d[first] + ' ' + rest) return messeges","title":"decrypt alanturing"},{"location":"CS61A/ex-tree/","text":"Tree (object) Tree Class class Tree: \"\"\"A tree is a label and a list of branches.\"\"\" def __init__(self, label, branches=[]): self.label = label for branch in branches: assert isinstance(branch, Tree) self.branches = list(branches) def __repr__(self): if self.branches: branch_str = ', ' + repr(self.branches) else: branch_str = '' return 'Tree({0}{1})'.format(repr(self.label), branch_str) def __str__(self): return '\\n'.join(self.indented()) def indented(self): lines = [] for b in self.branches: for line in b.indented(): lines.append(' ' + line) return [str(self.label)] + lines def is_leaf(self): return not self.branches def map(self, fn): \"\"\" Apply a function `fn` to each node in the tree and mutate the tree. >>> t1 = Tree(1) >>> t1.map(lambda x: x + 2) >>> t1.map(lambda x : x * 4) >>> t1.label 12 >>> t2 = Tree(3, [Tree(2, [Tree(5)]), Tree(4)]) >>> t2.map(lambda x: x * x) >>> t2 Tree(9, [Tree(4, [Tree(25)]), Tree(16)]) \"\"\" self.label = fn(self.label) for b in self.branches: b.map(fn) def __contains__(self, e): \"\"\" Determine whether an element exists in the tree. >>> t1 = Tree(1) >>> 1 in t1 True >>> 8 in t1 False >>> t2 = Tree(3, [Tree(2, [Tree(5)]), Tree(4)]) >>> 6 in t2 False >>> 5 in t2 True \"\"\" if self.label == e: return True for b in self.branches: if e in b: return True return False Fibonacci Tree def fib_tree(n): \"\"\"A Fibonacci tree. >>> print(fib_tree(4)) 3 1 0 1 2 1 1 0 1 \"\"\" if n == 0 or n == 1: return Tree(n) else: left = fib_tree(n-2) right = fib_tree(n-1) fib_n = left.label + right.label return Tree(fib_n, [left, right]) if using data abstraction: def fib_tree(n): if n <= 1: return tree(n) else: left, right = fib_tree(n-2), fib_tree(n-1) return tree(label(left) + label(right), [left, right]) Create a Tree >>> t = Tree(1, [Tree(3), Tree(4)]) >>> t Tree(1, [Tree(3), Tree(4)]) >>> print(t) 1 3 4 Sum Lables def sum_labels(t): \"\"\" Sum the labels of a Tree instance, which may be None. >>> sum_labels(fib_tree(5)) 10 \"\"\" return t.label + sum([sum_labels(b) for b in t.branches]) Leaves def leaves(tree): \"\"\"Return the leaf values of a tree. >>> leaves(fib_tree(4)) [0, 1, 1, 0, 1] \"\"\" if tree.is_leaf(): return [tree.label] else: return sum([leaves(b) for b in tree.branches], []) # all_leaves = [] # for b in t.branches: # all_leaves.extend(leaves(b)) # return all_leaves Height def height(tree): \"\"\"The height of a tree.\"\"\" if tree.is_leaf(): return 0 else: return 1 + max([height(b) for b in tree.branches]) Prune def prune(t, n): \"\"\"Prune sub-trees whose label value is n. >>> t = fib_tree(5) >>> prune(t, 1) >>> print(t) 5 2 3 2 \"\"\" t.branches = [b for b in t.branches if b.label != n] for b in t.branches: prune(b, n) In-Order (TBD) Pre-Order def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). >>> numbers = Tree(1, [Tree(2), Tree(3, [Tree(4), Tree(5)]), Tree(6, [Tree(7)])]) >>> preorder(numbers) [1, 2, 3, 4, 5, 6, 7] >>> preorder(Tree(2, [Tree(4, [Tree(6)])])) [2, 4, 6] \"\"\" # if t.is_leaf(): # return Tree(t.label) # else: # res_tree = Tree(t.label) # for b in t.branches: # res_tree.branches = preorder(b) # return res_tree if t.is_leaf(): return [t.label] else: res_tree = [t.label] for b in t.branches: res_tree += preorder(b) return res_tree Post-Order (TBD) Path Yielder def path_yielder(t, value): \"\"\"Yields all possible paths from the root of t to a node with the label value as a list. >>> t1 = Tree(1, [Tree(2, [Tree(3), Tree(4, [Tree(6)]), Tree(5)]), Tree(5)]) >>> print(t1) 1 2 3 4 6 5 5 >>> next(path_yielder(t1, 6)) [1, 2, 4, 6] >>> path_to_5 = path_yielder(t1, 5) >>> sorted(list(path_to_5)) [[1, 2, 5], [1, 5]] >>> t2 = Tree(0, [Tree(2, [t1])]) >>> print(t2) 0 2 1 2 3 4 6 5 5 >>> path_to_2 = path_yielder(t2, 2) >>> sorted(list(path_to_2)) [[0, 2], [0, 2, 1, 2]] \"\"\" if t.label == value: yield [t.label] for b in t.branches: for path in path_yielder(b, value): yield [t.label] + path is BST? def is_bst(t): \"\"\"Returns True if the Tree t has the structure of a valid BST. >>> t1 = Tree(6, [Tree(2, [Tree(1), Tree(4)]), Tree(7, [Tree(7), Tree(8)])]) >>> is_bst(t1) True >>> t2 = Tree(8, [Tree(2, [Tree(9), Tree(1)]), Tree(3, [Tree(6)]), Tree(5)]) >>> is_bst(t2) False >>> t3 = Tree(6, [Tree(2, [Tree(4), Tree(1)]), Tree(7, [Tree(7), Tree(8)])]) >>> is_bst(t3) False >>> t4 = Tree(1, [Tree(2, [Tree(3, [Tree(4)])])]) >>> is_bst(t4) True >>> t5 = Tree(1, [Tree(0, [Tree(-1, [Tree(-2)])])]) >>> is_bst(t5) True >>> t6 = Tree(1, [Tree(4, [Tree(2, [Tree(3)])])]) >>> is_bst(t6) True >>> t7 = Tree(2, [Tree(1, [Tree(5)]), Tree(4)]) >>> is_bst(t7) False \"\"\" def bst_max(t): if t.is_leaf(): return t.label return max(t.label, bst_max(t.branches[-1])) def bst_min(t): if t.is_leaf(): return t.label return min(t.label, bst_min(t.branches[0])) if t.is_leaf(): return True elif len(t.branches) == 1: left = t.branches[0] return is_bst(left) and (t.label >= bst_min(left) or t.label < bst_max(left)) elif len(t.branches) == 2: left, right = t.branches[0], t.branches[1] return is_bst(left) and is_bst(right) and t.label >= bst_max(left) and t.label <= bst_min(right) else: return False Prune Small def prune_small(t, n): \"\"\"Prune the tree mutatively, keeping only the n branches of each node with the smallest label. >>> t1 = Tree(6) >>> prune_small(t1, 2) >>> t1 Tree(6) >>> t2 = Tree(6, [Tree(3), Tree(4)]) >>> prune_small(t2, 1) >>> t2 Tree(6, [Tree(3)]) >>> t3 = Tree(6, [Tree(1), Tree(3, [Tree(1), Tree(2), Tree(3)]), Tree(5, [Tree(3), Tree(4)])]) >>> prune_small(t3, 2) >>> t3 Tree(6, [Tree(1), Tree(3, [Tree(1), Tree(2)])]) \"\"\" while len(t.branches) > n: largest = max(t.branches, key=lambda b: b.label) t.branches.remove(largest) for b in t.branches: prune_small(b, n) Widest Level (TBD) def widest_level(t): \"\"\" >>> sum([[1], [2]], []) [1, 2] >>> t = Tree(3, [Tree(1, [Tree(1), Tree(5)]), ... Tree(4, [Tree(9, [Tree(2)])])]) >>> widest_level(t) [1, 5, 9] \"\"\" levels = [] x = [t] while x: levels.append([b.root for b in x]) x = sum([b.branches for b in x], []) # return max(levels, key=len) Tree (function) Tree definition def tree(label, branches=[]): for branch in branches: assert is_tree(branch) # check: each branch is a tree return [label] + branches def label(tree): return tree[0] def branches(tree): return tree[1:] def is_tree(tree): if type(tree) != list or len(tree) < 1: return False for branch in branches (tree): if not is_tree(branch): return False return True def is_leaf(tree): return not branches(tree) # check branches are empty Fibonacci Tree def fib_tree(n): if n <= 1: return tree(n) else: left, right = fib_tree(n-2), fib_tree(n-1) return tree(label(left) + label(right), [left, right]) >>> fib_tree(0) [0] >>> fib_tree(1) [1] >>> fib_tree(2) [1, [0], [1]] >>> fib_tree(3) [2, [1], [1, [0], [1]]] >>> fib_tree(4) [3, [1, [0], [1]], [2, [1], [1, [0], [1]]]] Count Partitions def count_partitions(n, m): \"\"\" number of positive integer n using parts up to size m possibility 1: use at least one 4 possibility 2: don't use any 4 \"\"\" if n == 0: return 1 elif n < 0: return 0 elif m == 0: return 0 else: with_m = count_partitions(n-m, m) without_m = count_partitions(n, m-1) return with_m + without_m Leaves Implement leaves, which returns a list of the leaf labels of a tree hint: if sum a list of lists, you get a list containing the elements of those lists >>> sum([ [1], [2, 3], [4] ], []) [1, 2, 3, 4] >>> sum([ [[1]], [2] ], []) [[1], 2] sum only gets rid of one level, doesn't remove all the nested def leaves(tree): if is_leaf(tree): return [label(tree)] else: return sum(_____________, []) # need the sum(list of leaf labels for each branch) # so, it will be [leaves(b) for b in branches(tree)] finally def leaves(tree): \"\"\"Return a list containing the leaf labels of tree.\"\"\" if is_leaf(tree): return [label(tree)] else: return sum([leaves(b) for b in branches(tree)], []) Count Leaves def count_leaves(t): if is_leaf(t): return 1 else: return ([count_leaves(b) for b in branches(t)]) Increment Leaves a function that creates a tree from another tree is also recursive def increment_leaves(t): \"\"\"Return a tree like t but with leaf labels incremented.\"\"\" if is_leaf(t): return tree(label(t) + 1) else: # increment all the leaves in the branch bs = [increment_leaves(b) for b in branches(t)] return tree(label(t), bs) def increment(t): \"\"\"Return a tree like t but with all labels incremented.\"\"\" # don't need base case return tree(label(t) + 1, [increment(b) for b in branches(t)]) Print Trees cannot see the structure def print_tree(t): print(label(t)) for b in branches(t): print_tree(b) indent to see the structure def print_tree(t, indent=0): print(' ' * indent + str(label(t))) for b in branches(t): print_tree(b, indent+1) Print All Paths def print_all_paths(t): \"\"\" Print all the paths from the root to a leaf. >>> t = tree(1, [tree(2, [tree(3), tree(5)]), tree(4)]) >>> print_all_paths(t) [1, 2, 3] [1, 4] \"\"\" for path in all_paths(t): print(path) def all_paths(t): if is_leaf(t): yield [label(t)] for b in branches(t): for path in all_paths(b): yield [label(t)] + path Summing Paths referring back to factorial def fact(n): if n == 0: return 1 else: return n * fact(n-1) def fact_times(n, k): \"\"\"Return k * n * (n-1) * ... * 1\"\"\" if n == 0: return k else: return fact_times(n-1, k*n) # k*n*(n-1)! def fact(n): return fact_times(n, 1) define print function def print_sums(t, so_far): so_far = so_far + label(t) if is_leaf(t): print(so_far) else: for b in branches(t): print_sums(b, so_far) test with examples numbers = tree(3, [tree(4), tree(5, [tree(6)])]) haste = tree('h', [tree('a', [tree('s'), tree('t')]), tree('e')]) results >>> print_sums(numbers, 0) 7 14 >>> print_sums(haste, '') has hat he Copy Tree def copy_tree(t): \"\"\"Returns a copy of t. Only for testing purposes. >>> t = tree(5) >>> copy = copy_tree(t) >>> t = tree(6) >>> print_tree(copy) 5 \"\"\" return tree(label(t), [copy_tree(b) for b in branches(t)]) Tree Height def height(t): \"\"\"Return the height of a tree. hint: height of a tree is the length of the longest path from root to a leaf. >>> t = tree(3, [tree(5, [tree(1)]), tree(2)]) >>> height(t) 2 \"\"\" if is_leaf(t): return 0 else: return 1 + max([height(branch) for branch in branches(t)]) # alternatively # return 1 + max([0] + [height(branch) for branch in branches(t)]) Tree Max Path def max_path(t): \"\"\"Return the maximum path of the tree. >>> t = tree(1, [tree(5, [tree(1), tree(3)]), tree(10)]) >>> max_path(t) 11 \"\"\" if is_leaf(t): return [t[0]] else: return [t[0]] + max([max_path(branch) for branch in branches(t)]) Max Path Sum def max_path_sum(t): \"\"\"Return the maximum path sum of the tree. >>> t = tree(1, [tree(5, [tree(1), tree(3)]), tree(10)]) >>> max_path_sum(t) 11 \"\"\" if is_leaf(t): return t[0] else: return max([max_path_sum(branch) for branch in branches(t)]) + t[0] Square Tree def square_tree(t): \"\"\"Return a tree with the square of every element in t \"\"\" sq_branches = [square_tree(branch) for branch in branches(t)] return tree(label(t)**2, sq_branches) Find Element in Tree def berry_finder(t): \"\"\"Returns True if t contains a node with the value 'berry' and False otherwise. \"\"\" assert is_tree(t) if label(t) == 'berry': return True else: for b in branches(t): if berry_finder(b): return True return False Tree Find Path def find_path(tree, x): \"\"\" find the path from the parent to the node contains x >>> t = tree(2, [tree(7, [tree(3), tree(6, [tree(5), tree(11)])] ), tree(15)]) >>> find_path(t, 5) [2, 7, 6, 5] >>> find_path(t, 10) # returns None \"\"\" if label(tree) == x: return [label(tree)] for b in branches(tree): path = find_path(b, x) if path: return [label(tree)] + path Prune Tree def prune_tree(t, k): \"\"\" k = depth take in a tree and return a new tree that only contains the first k levels of the original tree \"\"\" assert is_tree(t) if k == 0: return tree(label(t)) else: return tree(label(t) + [prune_tree(b, k-1) for b in branches(t)]) Prune Leaves def prune_leaves(t, vals): \"\"\"Return a modified copy of t with all leaves that have a label that appears in vals removed. Return None if the entire tree is pruned away. >>> t = tree(2) >>> print(prune_leaves(t, (1, 2))) None >>> numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) >>> print_tree(numbers) 1 2 3 4 5 6 7 >>> print_tree(prune_leaves(numbers, (3, 4, 6, 7))) 1 2 3 5 6 \"\"\" if is_leaf(t): if label(t) in vals: return None else: return t pruned = [prune_leaves(b, vals) for b in branches(t)] return tree(label(t), [b for b in pruned if b is not None]) Sprout Leaves def sprout_leaves(t, leaves): \"\"\"Sprout new leaves containing the data in leaves at each leaf in the original tree t and return the resulting tree. >>> t1 = tree(1, [tree(2), tree(3)]) >>> print_tree(t1) 1 2 3 >>> new1 = sprout_leaves(t1, [4, 5]) >>> print_tree(new1) 1 2 4 5 3 4 5 \"\"\" if is_leaf(t): return tree(label(t), [tree(leaf) for leaf in leaves]) else: return tree(label(t), [sprout_leaves(b, leaves) for b in branches(t)]) Replace Leaf def replace_leaf(t, find_value, replace_value): \"\"\"Returns a new tree where every leaf value equal to find_value has been replaced with replace_value. >>> yggdrasil = tree('odin', ... [tree('balder', ... [tree('thor'), ... tree('freya')]), ... tree('frigg', ... [tree('thor')]), ... tree('thor', ... [tree('sif'), ... tree('thor')]), ... tree('thor')]) >>> laerad = copy_tree(yggdrasil) # copy yggdrasil for testing purposes >>> print_tree(replace_leaf(yggdrasil, 'thor', 'freya')) odin balder freya freya frigg freya thor sif freya freya >>> laerad == yggdrasil # Make sure original tree is unmodified True \"\"\" if is_leaf(t) and label(t) == find_value: return tree(replace_value) else: return tree(label(t), [replace_leaf(b, find_value, replace_value) for b in branches(t)]) Add Tree iterative def add_trees(t1, t2): result_label = label(t1) + label(t2) result_branches = [] i = 0 while i < min(len(branches(t1)), len(branches(t2))): b1, b2 = branches(t1)[i], branches(t2)[i] new_branch = add(tree(b1, b2)) result_branches = result_branches + [new_branch] i += 1 result_branches = result_branches + branches(t1)[i:] result_branches = result_branches + branches(t2)[i:] return tree(result_label, result_branches) use zip to tidy up def add_trees(t1, t2): result_label = label(t1) + label(t2) result_branches = [] i = 0 for b1, b2 in zip(branches(t1), branches(t2)): new_branch = add(tree(b1, b2)) result_branches = result_branches + [new_branch] i = len(result_branches) result_branches = result_branches + branches(t1)[i:] result_branches = result_branches + branches(t2)[i:] return tree(result_label, result_branches) list comprehension def add_trees(t1, t2): \"\"\" >>> numbers = tree(1, ... [tree(2, ... [tree(3), ... tree(4)]), ... tree(5, ... [tree(6, ... [tree(7)]), ... tree(8)])]) >>> print_tree(add_trees(numbers, numbers)) 2 4 6 8 10 12 14 16 >>> print_tree(add_trees(tree(2), tree(3, [tree(4), tree(5)]))) 5 4 5 >>> print_tree(add_trees(tree(2, [tree(3)]), tree(2, [tree(3), tree(4)]))) 4 6 4 >>> print_tree(add_trees(tree(2, [tree(3, [tree(4), tree(5)])]), \\ tree(2, [tree(3, [tree(4)]), tree(5)]))) 4 6 8 5 5 \"\"\" result_label = label(t1) + label(t2) result_branches = [add_tree(b1, b2) for b1, b2 in zip(branches(t1), branches(t2))] i = len(result_branches) result_branches = result_branches + branches(t1)[i:] result_branches = result_branches + branches(t2)[i:] return tree(result_label, result_branches) Tree Map def tree_map(fn, t): \"\"\"Maps the function fn over the entries of t and returns the result in a new tree. >>> numbers = Tree(1, ... [Tree(2, ... [Tree(3), ... Tree(4)]), ... Tree(5, ... [Tree(6, ... [Tree(7)]), ... Tree(8)])]) >>> print(tree_map(lambda x: 2**x, numbers)) 2 4 8 16 32 64 128 256 \"\"\" \"*** YOUR CODE HERE ***\" if is_leaf(t): return tree(fn(label(t))) else: return tree(fn(label(t)), [tree_map(fn, b) for b in branches(t)]) Collect Words def collect_words(t): \"\"\"\"Return a list of all the words contained in the tree where the value of each node in the tree is an individual letter. Words terminate at the leaf of a tree. >>> greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) >>> collect_words(greetings) ['hi', 'hello', 'hey'] \"\"\" if is_leaf(t): return [label(t)] else: words = [] for b in branches(t): words += [label(t) + w for w in collect_words(b)] return words Word in Path def has_path(t, word): \"\"\"Return whether there is a path in a tree where the entries along the path spell out a particular word. >>> greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) >>> has_path(greetings, 'h') True >>> has_path(greetings, 'i') False >>> has_path(greetings, 'hi') True >>> has_path(greetings, 'hello') True >>> has_path(greetings, 'hey') True >>> has_path(greetings, 'bye') False \"\"\" assert len(word) > 0, 'no path for empty word.' if label(t) != word[0]: return False elif len(word) == 1: return True else: for b in branches(t): if has_path(b, word[1:]): return True return False Non-consecutive Trade Profit maximum profit to make on trades: if execute S, then cannot execute trades; that have an edge directly connected to S. def profit(t): \"\"\"Return the max profit. >>> t = tree(2, [tree(3), tree(4, [tree(5)])]) >>> profit(t) 8 \"\"\" return helper(t, False) def helper(t, used_parent): if used_parent: return sum([helper(b, False) for b in branches(t)]) else: use_label_total = label(t) labelsum([helper(b, True) for b in branches(t)]) skip_label_total = 0 + sum([helper(b, False) for b in branches(t)]) return max(use_label_total, skip_label_total) W","title":"tree"},{"location":"CS61A/ex-tree/#tree-object","text":"","title":"Tree (object)"},{"location":"CS61A/ex-tree/#tree-class","text":"class Tree: \"\"\"A tree is a label and a list of branches.\"\"\" def __init__(self, label, branches=[]): self.label = label for branch in branches: assert isinstance(branch, Tree) self.branches = list(branches) def __repr__(self): if self.branches: branch_str = ', ' + repr(self.branches) else: branch_str = '' return 'Tree({0}{1})'.format(repr(self.label), branch_str) def __str__(self): return '\\n'.join(self.indented()) def indented(self): lines = [] for b in self.branches: for line in b.indented(): lines.append(' ' + line) return [str(self.label)] + lines def is_leaf(self): return not self.branches def map(self, fn): \"\"\" Apply a function `fn` to each node in the tree and mutate the tree. >>> t1 = Tree(1) >>> t1.map(lambda x: x + 2) >>> t1.map(lambda x : x * 4) >>> t1.label 12 >>> t2 = Tree(3, [Tree(2, [Tree(5)]), Tree(4)]) >>> t2.map(lambda x: x * x) >>> t2 Tree(9, [Tree(4, [Tree(25)]), Tree(16)]) \"\"\" self.label = fn(self.label) for b in self.branches: b.map(fn) def __contains__(self, e): \"\"\" Determine whether an element exists in the tree. >>> t1 = Tree(1) >>> 1 in t1 True >>> 8 in t1 False >>> t2 = Tree(3, [Tree(2, [Tree(5)]), Tree(4)]) >>> 6 in t2 False >>> 5 in t2 True \"\"\" if self.label == e: return True for b in self.branches: if e in b: return True return False","title":"Tree Class"},{"location":"CS61A/ex-tree/#fibonacci-tree","text":"def fib_tree(n): \"\"\"A Fibonacci tree. >>> print(fib_tree(4)) 3 1 0 1 2 1 1 0 1 \"\"\" if n == 0 or n == 1: return Tree(n) else: left = fib_tree(n-2) right = fib_tree(n-1) fib_n = left.label + right.label return Tree(fib_n, [left, right]) if using data abstraction: def fib_tree(n): if n <= 1: return tree(n) else: left, right = fib_tree(n-2), fib_tree(n-1) return tree(label(left) + label(right), [left, right])","title":"Fibonacci Tree"},{"location":"CS61A/ex-tree/#create-a-tree","text":">>> t = Tree(1, [Tree(3), Tree(4)]) >>> t Tree(1, [Tree(3), Tree(4)]) >>> print(t) 1 3 4","title":"Create a Tree"},{"location":"CS61A/ex-tree/#sum-lables","text":"def sum_labels(t): \"\"\" Sum the labels of a Tree instance, which may be None. >>> sum_labels(fib_tree(5)) 10 \"\"\" return t.label + sum([sum_labels(b) for b in t.branches])","title":"Sum Lables"},{"location":"CS61A/ex-tree/#leaves","text":"def leaves(tree): \"\"\"Return the leaf values of a tree. >>> leaves(fib_tree(4)) [0, 1, 1, 0, 1] \"\"\" if tree.is_leaf(): return [tree.label] else: return sum([leaves(b) for b in tree.branches], []) # all_leaves = [] # for b in t.branches: # all_leaves.extend(leaves(b)) # return all_leaves","title":"Leaves"},{"location":"CS61A/ex-tree/#height","text":"def height(tree): \"\"\"The height of a tree.\"\"\" if tree.is_leaf(): return 0 else: return 1 + max([height(b) for b in tree.branches])","title":"Height"},{"location":"CS61A/ex-tree/#prune","text":"def prune(t, n): \"\"\"Prune sub-trees whose label value is n. >>> t = fib_tree(5) >>> prune(t, 1) >>> print(t) 5 2 3 2 \"\"\" t.branches = [b for b in t.branches if b.label != n] for b in t.branches: prune(b, n)","title":"Prune"},{"location":"CS61A/ex-tree/#in-order-tbd","text":"","title":"In-Order (TBD)"},{"location":"CS61A/ex-tree/#pre-order","text":"def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). >>> numbers = Tree(1, [Tree(2), Tree(3, [Tree(4), Tree(5)]), Tree(6, [Tree(7)])]) >>> preorder(numbers) [1, 2, 3, 4, 5, 6, 7] >>> preorder(Tree(2, [Tree(4, [Tree(6)])])) [2, 4, 6] \"\"\" # if t.is_leaf(): # return Tree(t.label) # else: # res_tree = Tree(t.label) # for b in t.branches: # res_tree.branches = preorder(b) # return res_tree if t.is_leaf(): return [t.label] else: res_tree = [t.label] for b in t.branches: res_tree += preorder(b) return res_tree","title":"Pre-Order"},{"location":"CS61A/ex-tree/#post-order-tbd","text":"","title":"Post-Order (TBD)"},{"location":"CS61A/ex-tree/#path-yielder","text":"def path_yielder(t, value): \"\"\"Yields all possible paths from the root of t to a node with the label value as a list. >>> t1 = Tree(1, [Tree(2, [Tree(3), Tree(4, [Tree(6)]), Tree(5)]), Tree(5)]) >>> print(t1) 1 2 3 4 6 5 5 >>> next(path_yielder(t1, 6)) [1, 2, 4, 6] >>> path_to_5 = path_yielder(t1, 5) >>> sorted(list(path_to_5)) [[1, 2, 5], [1, 5]] >>> t2 = Tree(0, [Tree(2, [t1])]) >>> print(t2) 0 2 1 2 3 4 6 5 5 >>> path_to_2 = path_yielder(t2, 2) >>> sorted(list(path_to_2)) [[0, 2], [0, 2, 1, 2]] \"\"\" if t.label == value: yield [t.label] for b in t.branches: for path in path_yielder(b, value): yield [t.label] + path","title":"Path Yielder"},{"location":"CS61A/ex-tree/#is-bst","text":"def is_bst(t): \"\"\"Returns True if the Tree t has the structure of a valid BST. >>> t1 = Tree(6, [Tree(2, [Tree(1), Tree(4)]), Tree(7, [Tree(7), Tree(8)])]) >>> is_bst(t1) True >>> t2 = Tree(8, [Tree(2, [Tree(9), Tree(1)]), Tree(3, [Tree(6)]), Tree(5)]) >>> is_bst(t2) False >>> t3 = Tree(6, [Tree(2, [Tree(4), Tree(1)]), Tree(7, [Tree(7), Tree(8)])]) >>> is_bst(t3) False >>> t4 = Tree(1, [Tree(2, [Tree(3, [Tree(4)])])]) >>> is_bst(t4) True >>> t5 = Tree(1, [Tree(0, [Tree(-1, [Tree(-2)])])]) >>> is_bst(t5) True >>> t6 = Tree(1, [Tree(4, [Tree(2, [Tree(3)])])]) >>> is_bst(t6) True >>> t7 = Tree(2, [Tree(1, [Tree(5)]), Tree(4)]) >>> is_bst(t7) False \"\"\" def bst_max(t): if t.is_leaf(): return t.label return max(t.label, bst_max(t.branches[-1])) def bst_min(t): if t.is_leaf(): return t.label return min(t.label, bst_min(t.branches[0])) if t.is_leaf(): return True elif len(t.branches) == 1: left = t.branches[0] return is_bst(left) and (t.label >= bst_min(left) or t.label < bst_max(left)) elif len(t.branches) == 2: left, right = t.branches[0], t.branches[1] return is_bst(left) and is_bst(right) and t.label >= bst_max(left) and t.label <= bst_min(right) else: return False","title":"is BST?"},{"location":"CS61A/ex-tree/#prune-small","text":"def prune_small(t, n): \"\"\"Prune the tree mutatively, keeping only the n branches of each node with the smallest label. >>> t1 = Tree(6) >>> prune_small(t1, 2) >>> t1 Tree(6) >>> t2 = Tree(6, [Tree(3), Tree(4)]) >>> prune_small(t2, 1) >>> t2 Tree(6, [Tree(3)]) >>> t3 = Tree(6, [Tree(1), Tree(3, [Tree(1), Tree(2), Tree(3)]), Tree(5, [Tree(3), Tree(4)])]) >>> prune_small(t3, 2) >>> t3 Tree(6, [Tree(1), Tree(3, [Tree(1), Tree(2)])]) \"\"\" while len(t.branches) > n: largest = max(t.branches, key=lambda b: b.label) t.branches.remove(largest) for b in t.branches: prune_small(b, n)","title":"Prune Small"},{"location":"CS61A/ex-tree/#widest-level-tbd","text":"def widest_level(t): \"\"\" >>> sum([[1], [2]], []) [1, 2] >>> t = Tree(3, [Tree(1, [Tree(1), Tree(5)]), ... Tree(4, [Tree(9, [Tree(2)])])]) >>> widest_level(t) [1, 5, 9] \"\"\" levels = [] x = [t] while x: levels.append([b.root for b in x]) x = sum([b.branches for b in x], []) # return max(levels, key=len)","title":"Widest Level (TBD)"},{"location":"CS61A/ex-tree/#tree-function","text":"","title":"Tree (function)"},{"location":"CS61A/ex-tree/#tree-definition","text":"def tree(label, branches=[]): for branch in branches: assert is_tree(branch) # check: each branch is a tree return [label] + branches def label(tree): return tree[0] def branches(tree): return tree[1:] def is_tree(tree): if type(tree) != list or len(tree) < 1: return False for branch in branches (tree): if not is_tree(branch): return False return True def is_leaf(tree): return not branches(tree) # check branches are empty","title":"Tree definition"},{"location":"CS61A/ex-tree/#fibonacci-tree_1","text":"def fib_tree(n): if n <= 1: return tree(n) else: left, right = fib_tree(n-2), fib_tree(n-1) return tree(label(left) + label(right), [left, right]) >>> fib_tree(0) [0] >>> fib_tree(1) [1] >>> fib_tree(2) [1, [0], [1]] >>> fib_tree(3) [2, [1], [1, [0], [1]]] >>> fib_tree(4) [3, [1, [0], [1]], [2, [1], [1, [0], [1]]]]","title":"Fibonacci Tree"},{"location":"CS61A/ex-tree/#count-partitions","text":"def count_partitions(n, m): \"\"\" number of positive integer n using parts up to size m possibility 1: use at least one 4 possibility 2: don't use any 4 \"\"\" if n == 0: return 1 elif n < 0: return 0 elif m == 0: return 0 else: with_m = count_partitions(n-m, m) without_m = count_partitions(n, m-1) return with_m + without_m","title":"Count Partitions"},{"location":"CS61A/ex-tree/#leaves_1","text":"Implement leaves, which returns a list of the leaf labels of a tree hint: if sum a list of lists, you get a list containing the elements of those lists >>> sum([ [1], [2, 3], [4] ], []) [1, 2, 3, 4] >>> sum([ [[1]], [2] ], []) [[1], 2] sum only gets rid of one level, doesn't remove all the nested def leaves(tree): if is_leaf(tree): return [label(tree)] else: return sum(_____________, []) # need the sum(list of leaf labels for each branch) # so, it will be [leaves(b) for b in branches(tree)] finally def leaves(tree): \"\"\"Return a list containing the leaf labels of tree.\"\"\" if is_leaf(tree): return [label(tree)] else: return sum([leaves(b) for b in branches(tree)], [])","title":"Leaves"},{"location":"CS61A/ex-tree/#count-leaves","text":"def count_leaves(t): if is_leaf(t): return 1 else: return ([count_leaves(b) for b in branches(t)])","title":"Count Leaves"},{"location":"CS61A/ex-tree/#increment-leaves","text":"a function that creates a tree from another tree is also recursive def increment_leaves(t): \"\"\"Return a tree like t but with leaf labels incremented.\"\"\" if is_leaf(t): return tree(label(t) + 1) else: # increment all the leaves in the branch bs = [increment_leaves(b) for b in branches(t)] return tree(label(t), bs) def increment(t): \"\"\"Return a tree like t but with all labels incremented.\"\"\" # don't need base case return tree(label(t) + 1, [increment(b) for b in branches(t)])","title":"Increment Leaves"},{"location":"CS61A/ex-tree/#print-trees","text":"cannot see the structure def print_tree(t): print(label(t)) for b in branches(t): print_tree(b) indent to see the structure def print_tree(t, indent=0): print(' ' * indent + str(label(t))) for b in branches(t): print_tree(b, indent+1)","title":"Print Trees"},{"location":"CS61A/ex-tree/#print-all-paths","text":"def print_all_paths(t): \"\"\" Print all the paths from the root to a leaf. >>> t = tree(1, [tree(2, [tree(3), tree(5)]), tree(4)]) >>> print_all_paths(t) [1, 2, 3] [1, 4] \"\"\" for path in all_paths(t): print(path) def all_paths(t): if is_leaf(t): yield [label(t)] for b in branches(t): for path in all_paths(b): yield [label(t)] + path","title":"Print All Paths"},{"location":"CS61A/ex-tree/#summing-paths","text":"referring back to factorial def fact(n): if n == 0: return 1 else: return n * fact(n-1) def fact_times(n, k): \"\"\"Return k * n * (n-1) * ... * 1\"\"\" if n == 0: return k else: return fact_times(n-1, k*n) # k*n*(n-1)! def fact(n): return fact_times(n, 1) define print function def print_sums(t, so_far): so_far = so_far + label(t) if is_leaf(t): print(so_far) else: for b in branches(t): print_sums(b, so_far) test with examples numbers = tree(3, [tree(4), tree(5, [tree(6)])]) haste = tree('h', [tree('a', [tree('s'), tree('t')]), tree('e')]) results >>> print_sums(numbers, 0) 7 14 >>> print_sums(haste, '') has hat he","title":"Summing Paths"},{"location":"CS61A/ex-tree/#copy-tree","text":"def copy_tree(t): \"\"\"Returns a copy of t. Only for testing purposes. >>> t = tree(5) >>> copy = copy_tree(t) >>> t = tree(6) >>> print_tree(copy) 5 \"\"\" return tree(label(t), [copy_tree(b) for b in branches(t)])","title":"Copy Tree"},{"location":"CS61A/ex-tree/#tree-height","text":"def height(t): \"\"\"Return the height of a tree. hint: height of a tree is the length of the longest path from root to a leaf. >>> t = tree(3, [tree(5, [tree(1)]), tree(2)]) >>> height(t) 2 \"\"\" if is_leaf(t): return 0 else: return 1 + max([height(branch) for branch in branches(t)]) # alternatively # return 1 + max([0] + [height(branch) for branch in branches(t)])","title":"Tree Height"},{"location":"CS61A/ex-tree/#tree-max-path","text":"def max_path(t): \"\"\"Return the maximum path of the tree. >>> t = tree(1, [tree(5, [tree(1), tree(3)]), tree(10)]) >>> max_path(t) 11 \"\"\" if is_leaf(t): return [t[0]] else: return [t[0]] + max([max_path(branch) for branch in branches(t)]) Max Path Sum def max_path_sum(t): \"\"\"Return the maximum path sum of the tree. >>> t = tree(1, [tree(5, [tree(1), tree(3)]), tree(10)]) >>> max_path_sum(t) 11 \"\"\" if is_leaf(t): return t[0] else: return max([max_path_sum(branch) for branch in branches(t)]) + t[0]","title":"Tree Max Path"},{"location":"CS61A/ex-tree/#square-tree","text":"def square_tree(t): \"\"\"Return a tree with the square of every element in t \"\"\" sq_branches = [square_tree(branch) for branch in branches(t)] return tree(label(t)**2, sq_branches)","title":"Square Tree"},{"location":"CS61A/ex-tree/#find-element-in-tree","text":"def berry_finder(t): \"\"\"Returns True if t contains a node with the value 'berry' and False otherwise. \"\"\" assert is_tree(t) if label(t) == 'berry': return True else: for b in branches(t): if berry_finder(b): return True return False","title":"Find Element in Tree"},{"location":"CS61A/ex-tree/#tree-find-path","text":"def find_path(tree, x): \"\"\" find the path from the parent to the node contains x >>> t = tree(2, [tree(7, [tree(3), tree(6, [tree(5), tree(11)])] ), tree(15)]) >>> find_path(t, 5) [2, 7, 6, 5] >>> find_path(t, 10) # returns None \"\"\" if label(tree) == x: return [label(tree)] for b in branches(tree): path = find_path(b, x) if path: return [label(tree)] + path","title":"Tree Find Path"},{"location":"CS61A/ex-tree/#prune-tree","text":"def prune_tree(t, k): \"\"\" k = depth take in a tree and return a new tree that only contains the first k levels of the original tree \"\"\" assert is_tree(t) if k == 0: return tree(label(t)) else: return tree(label(t) + [prune_tree(b, k-1) for b in branches(t)])","title":"Prune Tree"},{"location":"CS61A/ex-tree/#prune-leaves","text":"def prune_leaves(t, vals): \"\"\"Return a modified copy of t with all leaves that have a label that appears in vals removed. Return None if the entire tree is pruned away. >>> t = tree(2) >>> print(prune_leaves(t, (1, 2))) None >>> numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) >>> print_tree(numbers) 1 2 3 4 5 6 7 >>> print_tree(prune_leaves(numbers, (3, 4, 6, 7))) 1 2 3 5 6 \"\"\" if is_leaf(t): if label(t) in vals: return None else: return t pruned = [prune_leaves(b, vals) for b in branches(t)] return tree(label(t), [b for b in pruned if b is not None])","title":"Prune Leaves"},{"location":"CS61A/ex-tree/#sprout-leaves","text":"def sprout_leaves(t, leaves): \"\"\"Sprout new leaves containing the data in leaves at each leaf in the original tree t and return the resulting tree. >>> t1 = tree(1, [tree(2), tree(3)]) >>> print_tree(t1) 1 2 3 >>> new1 = sprout_leaves(t1, [4, 5]) >>> print_tree(new1) 1 2 4 5 3 4 5 \"\"\" if is_leaf(t): return tree(label(t), [tree(leaf) for leaf in leaves]) else: return tree(label(t), [sprout_leaves(b, leaves) for b in branches(t)])","title":"Sprout Leaves"},{"location":"CS61A/ex-tree/#replace-leaf","text":"def replace_leaf(t, find_value, replace_value): \"\"\"Returns a new tree where every leaf value equal to find_value has been replaced with replace_value. >>> yggdrasil = tree('odin', ... [tree('balder', ... [tree('thor'), ... tree('freya')]), ... tree('frigg', ... [tree('thor')]), ... tree('thor', ... [tree('sif'), ... tree('thor')]), ... tree('thor')]) >>> laerad = copy_tree(yggdrasil) # copy yggdrasil for testing purposes >>> print_tree(replace_leaf(yggdrasil, 'thor', 'freya')) odin balder freya freya frigg freya thor sif freya freya >>> laerad == yggdrasil # Make sure original tree is unmodified True \"\"\" if is_leaf(t) and label(t) == find_value: return tree(replace_value) else: return tree(label(t), [replace_leaf(b, find_value, replace_value) for b in branches(t)])","title":"Replace Leaf"},{"location":"CS61A/ex-tree/#add-tree","text":"iterative def add_trees(t1, t2): result_label = label(t1) + label(t2) result_branches = [] i = 0 while i < min(len(branches(t1)), len(branches(t2))): b1, b2 = branches(t1)[i], branches(t2)[i] new_branch = add(tree(b1, b2)) result_branches = result_branches + [new_branch] i += 1 result_branches = result_branches + branches(t1)[i:] result_branches = result_branches + branches(t2)[i:] return tree(result_label, result_branches) use zip to tidy up def add_trees(t1, t2): result_label = label(t1) + label(t2) result_branches = [] i = 0 for b1, b2 in zip(branches(t1), branches(t2)): new_branch = add(tree(b1, b2)) result_branches = result_branches + [new_branch] i = len(result_branches) result_branches = result_branches + branches(t1)[i:] result_branches = result_branches + branches(t2)[i:] return tree(result_label, result_branches) list comprehension def add_trees(t1, t2): \"\"\" >>> numbers = tree(1, ... [tree(2, ... [tree(3), ... tree(4)]), ... tree(5, ... [tree(6, ... [tree(7)]), ... tree(8)])]) >>> print_tree(add_trees(numbers, numbers)) 2 4 6 8 10 12 14 16 >>> print_tree(add_trees(tree(2), tree(3, [tree(4), tree(5)]))) 5 4 5 >>> print_tree(add_trees(tree(2, [tree(3)]), tree(2, [tree(3), tree(4)]))) 4 6 4 >>> print_tree(add_trees(tree(2, [tree(3, [tree(4), tree(5)])]), \\ tree(2, [tree(3, [tree(4)]), tree(5)]))) 4 6 8 5 5 \"\"\" result_label = label(t1) + label(t2) result_branches = [add_tree(b1, b2) for b1, b2 in zip(branches(t1), branches(t2))] i = len(result_branches) result_branches = result_branches + branches(t1)[i:] result_branches = result_branches + branches(t2)[i:] return tree(result_label, result_branches)","title":"Add Tree"},{"location":"CS61A/ex-tree/#tree-map","text":"def tree_map(fn, t): \"\"\"Maps the function fn over the entries of t and returns the result in a new tree. >>> numbers = Tree(1, ... [Tree(2, ... [Tree(3), ... Tree(4)]), ... Tree(5, ... [Tree(6, ... [Tree(7)]), ... Tree(8)])]) >>> print(tree_map(lambda x: 2**x, numbers)) 2 4 8 16 32 64 128 256 \"\"\" \"*** YOUR CODE HERE ***\" if is_leaf(t): return tree(fn(label(t))) else: return tree(fn(label(t)), [tree_map(fn, b) for b in branches(t)])","title":"Tree Map"},{"location":"CS61A/ex-tree/#collect-words","text":"def collect_words(t): \"\"\"\"Return a list of all the words contained in the tree where the value of each node in the tree is an individual letter. Words terminate at the leaf of a tree. >>> greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) >>> collect_words(greetings) ['hi', 'hello', 'hey'] \"\"\" if is_leaf(t): return [label(t)] else: words = [] for b in branches(t): words += [label(t) + w for w in collect_words(b)] return words","title":"Collect Words"},{"location":"CS61A/ex-tree/#word-in-path","text":"def has_path(t, word): \"\"\"Return whether there is a path in a tree where the entries along the path spell out a particular word. >>> greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) >>> has_path(greetings, 'h') True >>> has_path(greetings, 'i') False >>> has_path(greetings, 'hi') True >>> has_path(greetings, 'hello') True >>> has_path(greetings, 'hey') True >>> has_path(greetings, 'bye') False \"\"\" assert len(word) > 0, 'no path for empty word.' if label(t) != word[0]: return False elif len(word) == 1: return True else: for b in branches(t): if has_path(b, word[1:]): return True return False","title":"Word in Path"},{"location":"CS61A/ex-tree/#non-consecutive-trade-profit","text":"maximum profit to make on trades: if execute S, then cannot execute trades; that have an edge directly connected to S. def profit(t): \"\"\"Return the max profit. >>> t = tree(2, [tree(3), tree(4, [tree(5)])]) >>> profit(t) 8 \"\"\" return helper(t, False) def helper(t, used_parent): if used_parent: return sum([helper(b, False) for b in branches(t)]) else: use_label_total = label(t) labelsum([helper(b, True) for b in branches(t)]) skip_label_total = 0 + sum([helper(b, False) for b in branches(t)]) return max(use_label_total, skip_label_total) W","title":"Non-consecutive Trade Profit"},{"location":"devops/cron/","text":"cron basics crontab -e to open editor crontab -l [-u user] to list cron jobs Reference: wikipedia \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 * * * command to execute (7 is also Sunday on some systems) example * * * * * starts the job every minute. 0 0 * * * starts the job at 00:00 every day. 50 * * * * starts the job at the 50th minute of every hour. */15 * * * * starts the job at every 15 minues (running at 0, 14, 30, 45 of the hour). run cron job 5 * * * * /test.sh 5 * * * * /test.sh -v enables logging details check logs vi /var/log/cron cron job change log vi /var/spool/mail/d_pbp cron job error log sudo vi /var/spool/mail/d_pbp to force view job error log setup PySpark in cron Add the following in the bash that calls the PySpark script export JAVA_HOME=/home/gs/java/current export HADOOP_CONF_DIR=/home/gs/conf/current","title":"cron"},{"location":"devops/cron/#cron-basics","text":"crontab -e to open editor crontab -l [-u user] to list cron jobs Reference: wikipedia \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 * * * command to execute (7 is also Sunday on some systems) example * * * * * starts the job every minute. 0 0 * * * starts the job at 00:00 every day. 50 * * * * starts the job at the 50th minute of every hour. */15 * * * * starts the job at every 15 minues (running at 0, 14, 30, 45 of the hour).","title":"cron basics"},{"location":"devops/cron/#run-cron-job","text":"5 * * * * /test.sh 5 * * * * /test.sh -v enables logging details","title":"run cron job"},{"location":"devops/cron/#check-logs","text":"vi /var/log/cron cron job change log vi /var/spool/mail/d_pbp cron job error log sudo vi /var/spool/mail/d_pbp to force view job error log","title":"check logs"},{"location":"devops/cron/#setup-pyspark-in-cron","text":"Add the following in the bash that calls the PySpark script export JAVA_HOME=/home/gs/java/current export HADOOP_CONF_DIR=/home/gs/conf/current","title":"setup PySpark in cron"},{"location":"devops/dev_env/","text":"Operating System Windows Mac OS Linux Unix Software Package Management System APT Advanced Package Tool Homebrew for MacOS or Linux, written in Ruby, initiated in 2009 PIP RPM Snappy Steam Others List of software package management systems Software Packages Developer Tool IntelliJ Anaconda","title":"Operating System"},{"location":"devops/dev_env/#operating-system","text":"","title":"Operating System"},{"location":"devops/dev_env/#windows","text":"","title":"Windows"},{"location":"devops/dev_env/#mac-os","text":"","title":"Mac OS"},{"location":"devops/dev_env/#linux","text":"","title":"Linux"},{"location":"devops/dev_env/#unix","text":"","title":"Unix"},{"location":"devops/dev_env/#software-package-management-system","text":"","title":"Software Package Management System"},{"location":"devops/dev_env/#apt","text":"Advanced Package Tool","title":"APT"},{"location":"devops/dev_env/#homebrew","text":"for MacOS or Linux, written in Ruby, initiated in 2009","title":"Homebrew"},{"location":"devops/dev_env/#pip","text":"","title":"PIP"},{"location":"devops/dev_env/#rpm","text":"","title":"RPM"},{"location":"devops/dev_env/#snappy","text":"","title":"Snappy"},{"location":"devops/dev_env/#steam","text":"","title":"Steam"},{"location":"devops/dev_env/#others","text":"List of software package management systems","title":"Others"},{"location":"devops/dev_env/#software-packages","text":"","title":"Software Packages"},{"location":"devops/dev_env/#developer-tool","text":"","title":"Developer Tool"},{"location":"devops/dev_env/#intellij","text":"","title":"IntelliJ"},{"location":"devops/dev_env/#anaconda","text":"","title":"Anaconda"},{"location":"devops/git/","text":"config git config -l git config --global --edit clone a repo git clone $@git git remote -v # add/delete upstream git remote add upstream $git:.git git remote rm upstream # rename git remote set-url origin $.git git remote set-url upstream $.git create a branch git checkout -b $branch git branch -d basic commands git branch git remote -v git status git diff $file git clean -n # check which files will be deleted before actually deleting git clean -f # delete untracked files create pull request git add $file git add . git commit -m \"message\" git push origin $branch git push origin $current_branch:remote_branch resolve a conflict to be validated git checkout master git remote -v git pull upstream master git push origin master git checkout $branch # get back to the working branch git rebase master git am --show-current-patch vi $file git add $file git rebase --continue git push origin $branch -f rebase git checkout master git fetch origin git reset --hard origin/master git checkout my_branch # add work on top of the branch vf git rebase -i master # IntelliJ: VCF - Resolve Conflicts git rebase --continue # until all conflicts are resolved git push -f origin my_branch origin vs upstream in general upstream = original repo origin = fork git fetch alone would fetch from origin by default What is the difference between origin and upstream on GitHub?","title":"git"},{"location":"devops/git/#config","text":"git config -l git config --global --edit","title":"config"},{"location":"devops/git/#clone-a-repo","text":"git clone $@git git remote -v # add/delete upstream git remote add upstream $git:.git git remote rm upstream # rename git remote set-url origin $.git git remote set-url upstream $.git","title":"clone a repo"},{"location":"devops/git/#create-a-branch","text":"git checkout -b $branch git branch -d","title":"create a branch"},{"location":"devops/git/#basic-commands","text":"git branch git remote -v git status git diff $file git clean -n # check which files will be deleted before actually deleting git clean -f # delete untracked files","title":"basic commands"},{"location":"devops/git/#create-pull-request","text":"git add $file git add . git commit -m \"message\" git push origin $branch git push origin $current_branch:remote_branch","title":"create pull request"},{"location":"devops/git/#resolve-a-conflict","text":"to be validated git checkout master git remote -v git pull upstream master git push origin master git checkout $branch # get back to the working branch git rebase master git am --show-current-patch vi $file git add $file git rebase --continue git push origin $branch -f rebase git checkout master git fetch origin git reset --hard origin/master git checkout my_branch # add work on top of the branch vf git rebase -i master # IntelliJ: VCF - Resolve Conflicts git rebase --continue # until all conflicts are resolved git push -f origin my_branch","title":"resolve a conflict"},{"location":"devops/git/#origin-vs-upstream","text":"in general upstream = original repo origin = fork git fetch alone would fetch from origin by default What is the difference between origin and upstream on GitHub?","title":"origin vs upstream"},{"location":"devops/unix/","text":"Useful Unix commands for data science Basic Unix Shell Commands for the Data Scientist basics hostname pwd # current working directory ls # list files ls -l # list files with details ls -a # list all files (including hidden) ls -la # list all files (including hidden) with details man $command control + R # find history chmod +x $file # make file executable chmod 755 -R $folder # change folder rights alias vi ~/.bash_profile source ~/.bash_profile edit file mv $old_file_name $new_file_name # rename cp $file_name $new_folder # copy rm $file_name # delete file rm -R $folder_name # delete folder find . -type f -name \".*.swp\" -exec rm -f {} \\; # remove .swp hidden file check file diff diff $file1 $file2 path1=/Users/git/project_folder1 path2=/Users/git/project_folder2 file=script.py file=coordinator.xml file=workflow.xml diff $path1/$file.py $path2/$file check file extension if [[ $file == *.txt ]] check dates date # local time date -u # utc time vim vi $filename esc: wq! # write and quit esc: q! # quit w/o saving esc: /$keyword # find keyword in file esc: 100dd # delete 100 rows :1 # go to the beginning of file :20 # go to line 20 :$ # go to the end of file grep grep \"jessie\" result.csv > jessie_res.csv # grep all lines with \"jessie\" into file cat cat $file_name # print content to terminal cat $file_name | less # open file neatly cat $file_name | wc -l # check rows of data in file awk count unique values in the 2nd column in file.csv cut -f2 file.csv | sort | uniq | wc -l display all unique values in the 2nd column in file.csv awk '{ a[$2]++ } END { for (b in a) { print b } }' file.csv others echo \"(copy paste)\" | sed 's/ //g' | awk -F'|' '{print $2 \", \" $3}' echo \"(copy paste)\" | sed 's/ //g' | awk -F'|' '{print $2 \"\\t\" $3}' remote screen screen # create a remote screen screen -ls # list all remote screens screen -d # detach screen -r # resume screen -S $screen_name -X quit","title":"unix"},{"location":"devops/unix/#basics","text":"hostname pwd # current working directory ls # list files ls -l # list files with details ls -a # list all files (including hidden) ls -la # list all files (including hidden) with details man $command control + R # find history chmod +x $file # make file executable chmod 755 -R $folder # change folder rights","title":"basics"},{"location":"devops/unix/#alias","text":"vi ~/.bash_profile source ~/.bash_profile","title":"alias"},{"location":"devops/unix/#edit-file","text":"mv $old_file_name $new_file_name # rename cp $file_name $new_folder # copy rm $file_name # delete file rm -R $folder_name # delete folder find . -type f -name \".*.swp\" -exec rm -f {} \\; # remove .swp hidden file","title":"edit file"},{"location":"devops/unix/#check-file-diff","text":"diff $file1 $file2 path1=/Users/git/project_folder1 path2=/Users/git/project_folder2 file=script.py file=coordinator.xml file=workflow.xml diff $path1/$file.py $path2/$file","title":"check file diff"},{"location":"devops/unix/#check-file-extension","text":"if [[ $file == *.txt ]]","title":"check file extension"},{"location":"devops/unix/#check-dates","text":"date # local time date -u # utc time","title":"check dates"},{"location":"devops/unix/#vim","text":"vi $filename esc: wq! # write and quit esc: q! # quit w/o saving esc: /$keyword # find keyword in file esc: 100dd # delete 100 rows :1 # go to the beginning of file :20 # go to line 20 :$ # go to the end of file","title":"vim"},{"location":"devops/unix/#grep","text":"grep \"jessie\" result.csv > jessie_res.csv # grep all lines with \"jessie\" into file","title":"grep"},{"location":"devops/unix/#cat","text":"cat $file_name # print content to terminal cat $file_name | less # open file neatly cat $file_name | wc -l # check rows of data in file","title":"cat"},{"location":"devops/unix/#awk","text":"count unique values in the 2nd column in file.csv cut -f2 file.csv | sort | uniq | wc -l display all unique values in the 2nd column in file.csv awk '{ a[$2]++ } END { for (b in a) { print b } }' file.csv others echo \"(copy paste)\" | sed 's/ //g' | awk -F'|' '{print $2 \", \" $3}' echo \"(copy paste)\" | sed 's/ //g' | awk -F'|' '{print $2 \"\\t\" $3}'","title":"awk"},{"location":"devops/unix/#remote-screen","text":"screen # create a remote screen screen -ls # list all remote screens screen -d # detach screen -r # resume screen -S $screen_name -X quit","title":"remote screen"},{"location":"python/UDF/","text":"basic array to string def array2str(x): r = ','.join(str(e) for e in x) if r == '': r = str(0) return r dataframe proportion def getSumKey(key): return 'sum(' + key + ')' def getProportion(df, grpByKey, prptnKey): tmp = df.groupBy(*grpByKey).sum() df_j_tmp = df.join(tmp, *grpByKey) for key in prptnKey: df_j_tmp = df_j_tmp.withColumn(key+'_p', 100*df_j_tmp[key]/df_j_tmp[getSumKey(key)]) df_j_tmp = df_j_tmp.drop(getSumKey(key)) return df_j_tmp args optional arg def foo(a, b = None): if b is not None: print(a+b) else: print(a) foo(3) #3 foo(3, 5) #8 multiple args def multi_add(*args): result = 0 for x in args: result = result + x return result multi_add(1,2,3,4,5) format number to B/M/K def convert_big_num_smart(num): if num >= 1e9: big_num = str(round(num / 1e9, 1)) + 'B' elif num >= 1e6: big_num = str(round(num / 1e6, 1)) + 'M' elif num >= 1e3: big_num = str(round(num / 1e3, 1)) + 'K' else: big_num = str(round(num, 1)) return big_num","title":"UDF"},{"location":"python/UDF/#basic","text":"","title":"basic"},{"location":"python/UDF/#array-to-string","text":"def array2str(x): r = ','.join(str(e) for e in x) if r == '': r = str(0) return r","title":"array to string"},{"location":"python/UDF/#dataframe","text":"","title":"dataframe"},{"location":"python/UDF/#proportion","text":"def getSumKey(key): return 'sum(' + key + ')' def getProportion(df, grpByKey, prptnKey): tmp = df.groupBy(*grpByKey).sum() df_j_tmp = df.join(tmp, *grpByKey) for key in prptnKey: df_j_tmp = df_j_tmp.withColumn(key+'_p', 100*df_j_tmp[key]/df_j_tmp[getSumKey(key)]) df_j_tmp = df_j_tmp.drop(getSumKey(key)) return df_j_tmp","title":"proportion"},{"location":"python/UDF/#args","text":"","title":"args"},{"location":"python/UDF/#optional-arg","text":"def foo(a, b = None): if b is not None: print(a+b) else: print(a) foo(3) #3 foo(3, 5) #8","title":"optional arg"},{"location":"python/UDF/#multiple-args","text":"def multi_add(*args): result = 0 for x in args: result = result + x return result multi_add(1,2,3,4,5)","title":"multiple args"},{"location":"python/UDF/#format","text":"","title":"format"},{"location":"python/UDF/#number-to-bmk","text":"def convert_big_num_smart(num): if num >= 1e9: big_num = str(round(num / 1e9, 1)) + 'B' elif num >= 1e6: big_num = str(round(num / 1e6, 1)) + 'M' elif num >= 1e3: big_num = str(round(num / 1e3, 1)) + 'K' else: big_num = str(round(num, 1)) return big_num","title":"number to B/M/K"},{"location":"python/basics/","text":"nan count number of nan in list np.count_nonzero(~np.isnan(data)) OS path import sys import os from os import path os.getcwd() sys.path.append('/home/user') check item existence print(\"Item exists: \" + str(path.exists(\"textfile.txt\"))) check item types print(\"Item is a file: \" + str(path.isfile(\"textfile.txt\"))) print(\"Item is a directory: \" + str(path.isdir(\"textfile.txt\"))) check item path print(\"Item path: \" + str(path.realpath(\"textfile.txt\"))) style number formats '${:,.2f}'.format(114) '${:,d}'.format(int(reve)) scientific notation suppress scientific notation data structure string reverse string def reverseString(s): l = s.split(' ') out = [] for ll in l: out.append(ll[::-1]) return ' '.join(out) a = 'this is an apple' at = reverseString(a) at list list to string weekdays = ['sun','mon','tue','wed','thu','fri','sat'] listAsString = ' '.join(weekdays) print(listAsString) list to tuple weekdays = ['sun','mon','tue','wed','thu','fri','sat'] listAsTuple = tuple(weekdays) print(listAsTuple) list to set weekdays = ['sun','mon','tue','wed','thu','fri','sat'] listAsSet = set(weekdays) print(listAsSet) count element weekdays = ['sun','mon','tue','wed','thu','fri','sun','mon','mon'] print(weekdays.count('mon')) print([[x,weekdays.count(x)] for x in set(weekdays)]) flatten list input_list = [1, [2, 3, [4, 5, [6, 7]]]] expected_output_list = [1, 2, 3, 4, 5, 6, 7] def flatten_list(input_list): output_list = [] if len(input_list)>0: for i in input_list: if isinstance(i, int): output_list.append(i) else: output_list += flatten_list(i) return output_list enumerate subjects = ['Python', 'Interview', 'Questions'] for i, subject in enumerate(subjects): print(i, subject) array generate an array of numbers import numpy as np np.linspace(0, 100, num=21) np.linspace(0, 100, num=20, endpoint=False)","title":"basics"},{"location":"python/basics/#nan","text":"count number of nan in list np.count_nonzero(~np.isnan(data))","title":"nan"},{"location":"python/basics/#os-path","text":"import sys import os from os import path os.getcwd() sys.path.append('/home/user') check item existence print(\"Item exists: \" + str(path.exists(\"textfile.txt\"))) check item types print(\"Item is a file: \" + str(path.isfile(\"textfile.txt\"))) print(\"Item is a directory: \" + str(path.isdir(\"textfile.txt\"))) check item path print(\"Item path: \" + str(path.realpath(\"textfile.txt\")))","title":"OS path"},{"location":"python/basics/#style","text":"","title":"style"},{"location":"python/basics/#number-formats","text":"'${:,.2f}'.format(114) '${:,d}'.format(int(reve))","title":"number formats"},{"location":"python/basics/#scientific-notation","text":"suppress scientific notation","title":"scientific notation"},{"location":"python/basics/#data-structure","text":"","title":"data structure"},{"location":"python/basics/#string","text":"reverse string def reverseString(s): l = s.split(' ') out = [] for ll in l: out.append(ll[::-1]) return ' '.join(out) a = 'this is an apple' at = reverseString(a) at","title":"string"},{"location":"python/basics/#list","text":"list to string weekdays = ['sun','mon','tue','wed','thu','fri','sat'] listAsString = ' '.join(weekdays) print(listAsString) list to tuple weekdays = ['sun','mon','tue','wed','thu','fri','sat'] listAsTuple = tuple(weekdays) print(listAsTuple) list to set weekdays = ['sun','mon','tue','wed','thu','fri','sat'] listAsSet = set(weekdays) print(listAsSet) count element weekdays = ['sun','mon','tue','wed','thu','fri','sun','mon','mon'] print(weekdays.count('mon')) print([[x,weekdays.count(x)] for x in set(weekdays)]) flatten list input_list = [1, [2, 3, [4, 5, [6, 7]]]] expected_output_list = [1, 2, 3, 4, 5, 6, 7] def flatten_list(input_list): output_list = [] if len(input_list)>0: for i in input_list: if isinstance(i, int): output_list.append(i) else: output_list += flatten_list(i) return output_list enumerate subjects = ['Python', 'Interview', 'Questions'] for i, subject in enumerate(subjects): print(i, subject)","title":"list"},{"location":"python/basics/#array","text":"generate an array of numbers import numpy as np np.linspace(0, 100, num=21) np.linspace(0, 100, num=20, endpoint=False)","title":"array"},{"location":"python/dataIO/","text":"data I/O txt \"w+\" to create f = open(\"textfile.txt\", \"w+\") for i in range(10): f.write(\"This is line \" + str(i) + \"\\r\\n\") f.close() \"a\" to append f = open(\"textfile.txt\", \"a\") for i in range(10): f.write(\"This is line \" + str(i) + \"\\r\\n\") f.close() \"r\" to read f = open(\"textfile.txt\", \"r\") if f.mode == 'r': contents = f.read() print(contents) if f.mode == 'r': fl = f.readlines() for x in fl: print(x) csv read files ending with .csv import os import pandas as pd DATA_PATH = 'data' file_list = os.listdir(DATA_PATH) csv_list = [pd.read_csv(os.path.join(DATA_PATH, file_name)) for file_name in filename_list if filename.endswith('.csv')] json file_input = 'file.json' with open(file_input) as f: d = json.load(f) df = pd.json_normalize(data=d, record_path='result', meta='timestamp') process data def parseJson(x): keys = list(json.loads(x).keys()) if 'app' in keys: return 'app' elif 'web' in keys: return 'web' else: return 'unknown' df['app_web_status'] = df['info'].apply(getAppWebStatus) df['out1'] = df['in_arr'].apply(lambda x: x[0]) df['out1'] = df['in_arr'].apply(lambda x: ','.join(map(str, sorted(x[1])))) display json data json.loads(df_raw['json'][0]) unstructured data import pandas as pd import re filename = 'asr.txt' with open(filename) as fn: ln = fn.readline() # read each line cnt = 1 # Keep count of lines d = dict() output = pd.DataFrame() while ln: elm = re.findall(r'{(.+?)}', ln) for e in elm: d['id'] = cnt d['recognition'] = e.split(':')[1] d['score'] = e.split(':')[2] output = output.append(d, ignore_index=True) ln = fn.readline() cnt += 1 output complex data web import urllib.request webUrl = urllib.request.urlopen(\"http://www.google.com\") print(\"result code: \" + str(webUrl.getcode())) html from html.parser import HTMLParser class MyHTMLParser(HTMLParser): def handle_comment(self, data): print(\"Encountered comment: \", data) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) def handle_starttag(self, tag, attrs): global metacount if tag == 'meta': metacount += 1 print(\"Encountered tag: \", tag) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) if attrs.__len__() > 0: print (\"\\tAttributes:\") for a in attrs: print (\"\\t\", a[0],\"=\",a[1]) def handle_endtag(self, tag): print(\"Encountered tag: \", tag) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) def handle_data(self, data): if (data.isspace()): return print(\"Encountered data: \", data) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) metacount = 0 parser = MyHTMLParser() f = open(\"samplehtml.html\") if f.mode == 'r': contents = f.read() parser.feed(contents) xml import xml.dom.minidom doc = xml.dom.minidom.parse(\"samplexml.xml\") print (doc.nodeName) print (doc.firstChild.tagName) parse tags out skills = doc.getElementsByTagName(\"skill\") print (\"%d skills:\" % skills.length) for skill in skills: print (skill.getAttribute(\"name\")) create new tags newSkill = doc.createElement(\"skill\") newSkill.setAttribute(\"name\", \"jQuery\") doc.firstChild.appendChild(newSkill) skills = doc.getElementsByTagName(\"skill\") print (\"%d skills:\" % skills.length) for skill in skills: print (skill.getAttribute(\"name\"))","title":"dataIO"},{"location":"python/dataIO/#data-io","text":"","title":"data I/O"},{"location":"python/dataIO/#txt","text":"\"w+\" to create f = open(\"textfile.txt\", \"w+\") for i in range(10): f.write(\"This is line \" + str(i) + \"\\r\\n\") f.close() \"a\" to append f = open(\"textfile.txt\", \"a\") for i in range(10): f.write(\"This is line \" + str(i) + \"\\r\\n\") f.close() \"r\" to read f = open(\"textfile.txt\", \"r\") if f.mode == 'r': contents = f.read() print(contents) if f.mode == 'r': fl = f.readlines() for x in fl: print(x)","title":"txt"},{"location":"python/dataIO/#csv","text":"read files ending with .csv import os import pandas as pd DATA_PATH = 'data' file_list = os.listdir(DATA_PATH) csv_list = [pd.read_csv(os.path.join(DATA_PATH, file_name)) for file_name in filename_list if filename.endswith('.csv')]","title":"csv"},{"location":"python/dataIO/#json","text":"file_input = 'file.json' with open(file_input) as f: d = json.load(f) df = pd.json_normalize(data=d, record_path='result', meta='timestamp') process data def parseJson(x): keys = list(json.loads(x).keys()) if 'app' in keys: return 'app' elif 'web' in keys: return 'web' else: return 'unknown' df['app_web_status'] = df['info'].apply(getAppWebStatus) df['out1'] = df['in_arr'].apply(lambda x: x[0]) df['out1'] = df['in_arr'].apply(lambda x: ','.join(map(str, sorted(x[1])))) display json data json.loads(df_raw['json'][0])","title":"json"},{"location":"python/dataIO/#unstructured-data","text":"import pandas as pd import re filename = 'asr.txt' with open(filename) as fn: ln = fn.readline() # read each line cnt = 1 # Keep count of lines d = dict() output = pd.DataFrame() while ln: elm = re.findall(r'{(.+?)}', ln) for e in elm: d['id'] = cnt d['recognition'] = e.split(':')[1] d['score'] = e.split(':')[2] output = output.append(d, ignore_index=True) ln = fn.readline() cnt += 1 output","title":"unstructured data"},{"location":"python/dataIO/#complex-data","text":"","title":"complex data"},{"location":"python/dataIO/#web","text":"import urllib.request webUrl = urllib.request.urlopen(\"http://www.google.com\") print(\"result code: \" + str(webUrl.getcode()))","title":"web"},{"location":"python/dataIO/#html","text":"from html.parser import HTMLParser class MyHTMLParser(HTMLParser): def handle_comment(self, data): print(\"Encountered comment: \", data) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) def handle_starttag(self, tag, attrs): global metacount if tag == 'meta': metacount += 1 print(\"Encountered tag: \", tag) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) if attrs.__len__() > 0: print (\"\\tAttributes:\") for a in attrs: print (\"\\t\", a[0],\"=\",a[1]) def handle_endtag(self, tag): print(\"Encountered tag: \", tag) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) def handle_data(self, data): if (data.isspace()): return print(\"Encountered data: \", data) pos = self.getpos() print(\"\\tAt line: \", pos[0], \" position \", pos[1]) metacount = 0 parser = MyHTMLParser() f = open(\"samplehtml.html\") if f.mode == 'r': contents = f.read() parser.feed(contents)","title":"html"},{"location":"python/dataIO/#xml","text":"import xml.dom.minidom doc = xml.dom.minidom.parse(\"samplexml.xml\") print (doc.nodeName) print (doc.firstChild.tagName) parse tags out skills = doc.getElementsByTagName(\"skill\") print (\"%d skills:\" % skills.length) for skill in skills: print (skill.getAttribute(\"name\")) create new tags newSkill = doc.createElement(\"skill\") newSkill.setAttribute(\"name\", \"jQuery\") doc.firstChild.appendChild(newSkill) skills = doc.getElementsByTagName(\"skill\") print (\"%d skills:\" % skills.length) for skill in skills: print (skill.getAttribute(\"name\"))","title":"xml"},{"location":"python/datetime/","text":"datetime from datetime import date, time, datetime, timedelta date object today = date.today() today.year today.month today.day today.weekday() # 4 days[today.weekday()] # Fri time difference start_time = time.time() end_time = time.time() print end_time - start_time time formatting now = datetime.now() print(now.strftime(\"The current year is %Y\")) print(now.strftime(\"%a, %d, %B, %Y\")) print(now.strftime(\"Locale date and time: %c\")) print(now.strftime(\"Locale date: %x\")) print(now.strftime(\"Locale time: %X\")) print(now.strftime(\"Current time: %I:%M:%S %p\")) print(now.strftime(\"24-hour time: %H:%M\")) timedelta timedelta(days=365, hours=5, minutes=1) print(\"today is: \" + str(now)) print(\"one year from now it will be: \" + str(now + timedelta(days=365))) print(\"In 2 days and 3 weeks, it will be: \" + str(now + timedelta(days=2, weeks=3))) t = datetime.now() - timedelta(weeks=1) s = t.strftime(\"%A %B %d, %Y\") print(\"One week ago, it was: \" + s) print(\"Tomorrow will be\", days[(today.weekday() + 1) % 7]) compute hours def compute_hours(curHour_str, interval_int): curHour_obj = datetime.strptime(curHour_str, '%Y%m%d%H') end_hour_obj = curHour_obj + timedelta(hours=interval_int) end_hour_str = end_hour_obj.strftime('%Y%m%d%H') return end_hour_str countdown nyd = date(today.year, 1, 1) if nyd < today: print(\"New Year's day already went by %d days ago\" % (today-nyd).days) nyd = nyd.replace(year = today.year + 1) time_to_nyd = nyd - today print(\"It's just\", time_to_nyd.days, \"days until New Year's Day\") get a list of dates start = datetime.strptime(\"20220101\", \"%Y%m%d\") end = datetime.strptime(\"20220201\", \"%Y%m%d\") date_obj = [start + timedelta(days=x) for x in range(0, (end-start).days)] dates = [d.strftime(\"%Y%m%d\") for d in date_obj] convert UTC timestamp datetime.utcfromtimestamp(1582503300000/1000).strftime('%Y-%m-%d %H:%M:%S') calendar import calendar plain text calendar c = calendar.TextCalendar(calendar.MONDAY) st = c.formatmonth(2021, 3, 0, 0) print(st) HTML formatted calendar hc = calendar.HTMLCalendar(calendar.MONDAY) ht = hc.formatmonth(2021, 3) print(ht) loop over month for name in calendar.month_name: print(name) loop over weekday for day in calendar.day_name: print(day) calculate days based on a rule i.e. 1st Friday of each month print(\"1st Friday of each month will be on: \") for m in range(1, 13): cal = calendar.monthcalendar(2022, m) weekone = cal[0] weektwo = cal[1] if weekone[calendar.FRIDAY] != 0: meetday = weekone[calendar.FRIDAY] else: meetday = weektwo[calendar.FRIDAY] print(\"%10s %d\" % (calendar.month_name[m], meetday))","title":"datetime"},{"location":"python/datetime/#datetime","text":"from datetime import date, time, datetime, timedelta","title":"datetime"},{"location":"python/datetime/#date-object","text":"today = date.today() today.year today.month today.day today.weekday() # 4 days[today.weekday()] # Fri","title":"date object"},{"location":"python/datetime/#time-difference","text":"start_time = time.time() end_time = time.time() print end_time - start_time","title":"time difference"},{"location":"python/datetime/#time-formatting","text":"now = datetime.now() print(now.strftime(\"The current year is %Y\")) print(now.strftime(\"%a, %d, %B, %Y\")) print(now.strftime(\"Locale date and time: %c\")) print(now.strftime(\"Locale date: %x\")) print(now.strftime(\"Locale time: %X\")) print(now.strftime(\"Current time: %I:%M:%S %p\")) print(now.strftime(\"24-hour time: %H:%M\"))","title":"time formatting"},{"location":"python/datetime/#timedelta","text":"timedelta(days=365, hours=5, minutes=1) print(\"today is: \" + str(now)) print(\"one year from now it will be: \" + str(now + timedelta(days=365))) print(\"In 2 days and 3 weeks, it will be: \" + str(now + timedelta(days=2, weeks=3))) t = datetime.now() - timedelta(weeks=1) s = t.strftime(\"%A %B %d, %Y\") print(\"One week ago, it was: \" + s) print(\"Tomorrow will be\", days[(today.weekday() + 1) % 7]) compute hours def compute_hours(curHour_str, interval_int): curHour_obj = datetime.strptime(curHour_str, '%Y%m%d%H') end_hour_obj = curHour_obj + timedelta(hours=interval_int) end_hour_str = end_hour_obj.strftime('%Y%m%d%H') return end_hour_str countdown nyd = date(today.year, 1, 1) if nyd < today: print(\"New Year's day already went by %d days ago\" % (today-nyd).days) nyd = nyd.replace(year = today.year + 1) time_to_nyd = nyd - today print(\"It's just\", time_to_nyd.days, \"days until New Year's Day\")","title":"timedelta"},{"location":"python/datetime/#get-a-list-of-dates","text":"start = datetime.strptime(\"20220101\", \"%Y%m%d\") end = datetime.strptime(\"20220201\", \"%Y%m%d\") date_obj = [start + timedelta(days=x) for x in range(0, (end-start).days)] dates = [d.strftime(\"%Y%m%d\") for d in date_obj]","title":"get a list of dates"},{"location":"python/datetime/#convert-utc-timestamp","text":"datetime.utcfromtimestamp(1582503300000/1000).strftime('%Y-%m-%d %H:%M:%S')","title":"convert UTC timestamp"},{"location":"python/datetime/#calendar","text":"import calendar","title":"calendar"},{"location":"python/datetime/#plain-text-calendar","text":"c = calendar.TextCalendar(calendar.MONDAY) st = c.formatmonth(2021, 3, 0, 0) print(st)","title":"plain text calendar"},{"location":"python/datetime/#html-formatted-calendar","text":"hc = calendar.HTMLCalendar(calendar.MONDAY) ht = hc.formatmonth(2021, 3) print(ht)","title":"HTML formatted calendar"},{"location":"python/datetime/#loop-over-month","text":"for name in calendar.month_name: print(name)","title":"loop over month"},{"location":"python/datetime/#loop-over-weekday","text":"for day in calendar.day_name: print(day)","title":"loop over weekday"},{"location":"python/datetime/#calculate-days-based-on-a-rule","text":"i.e. 1st Friday of each month print(\"1st Friday of each month will be on: \") for m in range(1, 13): cal = calendar.monthcalendar(2022, m) weekone = cal[0] weektwo = cal[1] if weekone[calendar.FRIDAY] != 0: meetday = weekone[calendar.FRIDAY] else: meetday = weektwo[calendar.FRIDAY] print(\"%10s %d\" % (calendar.month_name[m], meetday))","title":"calculate days based on a rule"},{"location":"python/iPython/","text":"cell execution time %%time sum(range(1000000)) or %timeit $command Built-in magic commands current working directory path %pwd print the most recent 1-3 commands in the current session %history -n 1-3 what classes are available %config","title":"iPython"},{"location":"python/iPython/#cell-execution-time","text":"%%time sum(range(1000000)) or %timeit $command","title":"cell execution time"},{"location":"python/iPython/#built-in-magic-commands","text":"current working directory path %pwd print the most recent 1-3 commands in the current session %history -n 1-3 what classes are available %config","title":"Built-in magic commands"},{"location":"python/pandas/","text":"import numpy as np import pandas as pd import json import os import glob pd.__version__ import warnings warnings.filterwarnings(\"ignore\", category=FutureWarning) data I/O create empty table res = pd.DataFrame() from lists l_dates = ['2022-01-01', '2022-01-02', '2022-01-03'] l_latency = [10, 20, 30] df_latency = pd.DataFrame(zip(l_dates, l_latency), columns=['date', 'latency']) read working directory path dir_path = os.getcwd() csv df = pd.read_csv(dir_path + \"file.csv\") # default sep=',' df = pd.read_csv(dir_path + \"file.csv\", sep='\\t') json file_input = 'file.json' with open(file_input) as f: d = json.load(f) df = pd.json_normalize(data=d, record_path='result', meta='timestamp') read all files into one table under the same folder ## option 1 dir_path = os.getcwd() df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', dir_path + '*.csv')))) ## option 2 path = r'/Users/project_folder/' all_files = glob.glob(os.path.join(path, \"*.csv\")) df_from_each_file = (pd.read_csv(f) for f in all_files) df = pd.concat(df_from_each_file, ignore_index=True) write df.to_csv('output_file.csv', index=False) data explore metadata df.columns df.shape df.size df.dtypes print('size: {0}\\n\\n{1}'.format(df.shape, df.dtypes)) print table df.head() df.tail() from IPython.display import HTML HTML(df.to_html(index=False)) column statistics df.describe() df['$column_name'].describe() data process filter logical operator python df[df.value > 1] df[(df.value > 1) & (df.value < 5)] isin python names = ['John','Jane'] df[df.name.isin(names)] str accessor python df[df.name.str.startswith('J')] df[df.name.str.contains('y')] not / tilde (~) python df[~df.name.str.startswith('J')] query python df.query('product == \"A\" and value > 1') nlargest / nsmallest python df.nlargest(3, 'value') df.nsmallest(2, 'value') loc / iloc python df.iloc[3:5, :] #rows 3 and 4, all columns df.loc[3:5, :] #rows 3 and 4, all columns create col df['algo'] = np.where(df['dt']>20220101, 1, 0) rename col df.rename(columns={'old1':'new1', 'old2':'new2'}, inplace=True) cum_metric_col = ['cum_' + i for i in metric_col] df.rename(columns=dict(zip(metric_col, cum_metric_col))) NA / NULL df.isnull().sum() df.inv_cost.fillna(0, inplace=True) resp = df.loc[df['price'].notnull()] rolling avg df['avg_P14D'] = df['y'].rolling(14).mean() sort df[df['id']==100].sort_values('time') table transform join merge (horizontal) pd.merge(df1, df2, on=[], how='inner') df1.join(df2, on=[], how='inner') # use index to join append (vertical) pd.concat([df1, df2]) groupby res = df.groupby(['id','type'])\\ .agg({'spend':sum, 'budget':sum, 'cnt':sum, 's':np.mean})\\ .reset_index()\\ .sort_values('id') pivot vs pivot_table df.pivot(index=['date', 'latency'], columns='series', values='metric') pd.pivot_table(df, index=['date', 'latency'], columns='series', values='metric', aggfunc=np.mean).reset_index cumulative df_grp = df.groupby(groupby_cols)['cnt'].sum().reset_index() df_grp['cum_cnt'] = df_grp['cnt'].cumsum() df_grp['cum_p_cnt'] = df_grp['cum_cnt']/df_grp['cnt'].sum() transpose df.T Series to DataFrame convert pandas.core.series.Series to DataFrame df['ds'].value_counts().to_frame() bucketize cutoff = [0,1,1.5,2,4,50] spend['grp'] = pd.cut(spend['metric'], cutoff, include_lowest=True) datetime pd.to_datetime('2022-01-01') df['date_obj'].dt.date df['date_obj'].dt.strftime('%Y-%m-%d') json import json import pandas as pd from pandas.io.json import json_normalize df = pd.read_csv('ss.csv', sep='\\t', index_col = False) with open('ssResult.json') as f: d = json.load(f) res = json_normalize(d) res.rename(columns={'event.bucket_name':'bucket', 'event.id':'id', 'timestamp':'dt', 'event.sum_revenue':'revenue', 'event.sum_amount':'amount'}, inplace=True) res.drop(['version'], axis=1, inplace=True) res['dt'] = res.dt.str.slice(0,10) res['dt'] = res.dt.str.replace('-','') res.groupby('dt')[['id']].size() apply fn to row use %timeit $command in jupyter cell for runtime loop over all rows in df (56s) def loop_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) result = [] for i in range(len(df)): row = df.iloc[i] result.append( eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date) ) return pd.Series(result) iterrows (9s) def iterrows_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date) for index, row in df.iterrows() ) itertuples (211ms) itertuples processes rows as tuples. def itertuples_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date) for row in df.itertuples() ) apply (1.85s) Pandas DataFrame apply function is quite versatile and is a popular choice. To make it process the rows, you have to pass axis=1 argument. def apply_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return df.apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1 ) list comprehension (78ms) A column in DataFrame is a Series that can be used as a list in a list comprehension expression. If multiple columns are needed, then zip can be used to make a list of tuples. [ foo(x) for x in df['x'] ] def list_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series([ eisenhower_action(priority == 'HIGH', due_date <= cutoff_date) for (priority, due_date) in zip(df['priority'], df['due_date']) ]) map (71ms) Python\u2019s map function that takes in function and iterables of parameters, and yields results. def map_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( map(eisenhower_action, df['priority'] == 'HIGH', df['due_date'] <= cutoff_date) ) vectorization (20ms) The real power of Pandas shows up in vectorization. But it requires unpacking the function as a vector expression. def map_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( map(eisenhower_action, df['priority'] == 'HIGH', df['due_date'] <= cutoff_date) ) numpy vectorize (35ms) NumPy offers alternatives for migrating from Python to Numpy through vectorization. For example, it has a vectorize() function that vectorzie any scalar function to accept and return NumPy arrays. def np_vec_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return np.vectorize(eisenhower_action)( df['priority'] == 'HIGH', df['due_date'] <= cutoff_date ) Numba Decorators (19ms) Numba is commonly used to speed up applying mathematical functions. It has various decorators for JIT compilation and vectorization. import numba @numba.vectorize def eisenhower_action(is_important: bool, is_urgent: bool) -> int: return 2 * is_important + is_urgent def numba_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return eisenhower_action( (df['priority'] == 'HIGH').to_numpy(), (df['due_date'] <= cutoff_date).to_numpy() ) Multiprocessing with pandarallel (2s) The pandarallel package utilizes multiple CPUs and split the work into multiple threads. from pandarallel import pandarallel pandarallel.initialize() def pandarallel_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return df.parallel_apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1 ) Parallelize with Dask (2s) Dask is a parallel computing library that supports scaling up NumPy, Pandas, Scikit-learn, and many other Python libraries. It offers efficient infra for processing a massive amount of data on multi-node clusters. import dask.dataframe as dd def dask_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return dd.from_pandas(df, npartitions=CPU_COUNT).apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1, meta=(int) ).compute() Opportunistic Parallelization with Swifter (22ms) Swifter automatically decides which is faster: to use Dask parallel processing or a simple Pandas apply. It is very simple to use: just all one word to how one uses Pandas apply function: df.swifter.apply. import swifter def swifter_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return df.swifter.apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1 )","title":"pandas"},{"location":"python/pandas/#data-io","text":"","title":"data I/O"},{"location":"python/pandas/#create","text":"empty table res = pd.DataFrame() from lists l_dates = ['2022-01-01', '2022-01-02', '2022-01-03'] l_latency = [10, 20, 30] df_latency = pd.DataFrame(zip(l_dates, l_latency), columns=['date', 'latency'])","title":"create"},{"location":"python/pandas/#read","text":"working directory path dir_path = os.getcwd() csv df = pd.read_csv(dir_path + \"file.csv\") # default sep=',' df = pd.read_csv(dir_path + \"file.csv\", sep='\\t') json file_input = 'file.json' with open(file_input) as f: d = json.load(f) df = pd.json_normalize(data=d, record_path='result', meta='timestamp') read all files into one table under the same folder ## option 1 dir_path = os.getcwd() df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', dir_path + '*.csv')))) ## option 2 path = r'/Users/project_folder/' all_files = glob.glob(os.path.join(path, \"*.csv\")) df_from_each_file = (pd.read_csv(f) for f in all_files) df = pd.concat(df_from_each_file, ignore_index=True)","title":"read"},{"location":"python/pandas/#write","text":"df.to_csv('output_file.csv', index=False)","title":"write"},{"location":"python/pandas/#data-explore","text":"metadata df.columns df.shape df.size df.dtypes print('size: {0}\\n\\n{1}'.format(df.shape, df.dtypes)) print table df.head() df.tail() from IPython.display import HTML HTML(df.to_html(index=False)) column statistics df.describe() df['$column_name'].describe()","title":"data explore"},{"location":"python/pandas/#data-process","text":"","title":"data process"},{"location":"python/pandas/#filter","text":"logical operator python df[df.value > 1] df[(df.value > 1) & (df.value < 5)] isin python names = ['John','Jane'] df[df.name.isin(names)] str accessor python df[df.name.str.startswith('J')] df[df.name.str.contains('y')] not / tilde (~) python df[~df.name.str.startswith('J')] query python df.query('product == \"A\" and value > 1') nlargest / nsmallest python df.nlargest(3, 'value') df.nsmallest(2, 'value') loc / iloc python df.iloc[3:5, :] #rows 3 and 4, all columns df.loc[3:5, :] #rows 3 and 4, all columns","title":"filter"},{"location":"python/pandas/#create-col","text":"df['algo'] = np.where(df['dt']>20220101, 1, 0)","title":"create col"},{"location":"python/pandas/#rename-col","text":"df.rename(columns={'old1':'new1', 'old2':'new2'}, inplace=True) cum_metric_col = ['cum_' + i for i in metric_col] df.rename(columns=dict(zip(metric_col, cum_metric_col)))","title":"rename col"},{"location":"python/pandas/#na-null","text":"df.isnull().sum() df.inv_cost.fillna(0, inplace=True) resp = df.loc[df['price'].notnull()]","title":"NA / NULL"},{"location":"python/pandas/#rolling-avg","text":"df['avg_P14D'] = df['y'].rolling(14).mean()","title":"rolling avg"},{"location":"python/pandas/#sort","text":"df[df['id']==100].sort_values('time')","title":"sort"},{"location":"python/pandas/#table-transform","text":"","title":"table transform"},{"location":"python/pandas/#join","text":"merge (horizontal) pd.merge(df1, df2, on=[], how='inner') df1.join(df2, on=[], how='inner') # use index to join append (vertical) pd.concat([df1, df2])","title":"join"},{"location":"python/pandas/#groupby","text":"res = df.groupby(['id','type'])\\ .agg({'spend':sum, 'budget':sum, 'cnt':sum, 's':np.mean})\\ .reset_index()\\ .sort_values('id')","title":"groupby"},{"location":"python/pandas/#pivot-vs-pivot_table","text":"df.pivot(index=['date', 'latency'], columns='series', values='metric') pd.pivot_table(df, index=['date', 'latency'], columns='series', values='metric', aggfunc=np.mean).reset_index","title":"pivot vs pivot_table"},{"location":"python/pandas/#cumulative","text":"df_grp = df.groupby(groupby_cols)['cnt'].sum().reset_index() df_grp['cum_cnt'] = df_grp['cnt'].cumsum() df_grp['cum_p_cnt'] = df_grp['cum_cnt']/df_grp['cnt'].sum()","title":"cumulative"},{"location":"python/pandas/#transpose","text":"df.T","title":"transpose"},{"location":"python/pandas/#series-to-dataframe","text":"convert pandas.core.series.Series to DataFrame df['ds'].value_counts().to_frame()","title":"Series to DataFrame"},{"location":"python/pandas/#bucketize","text":"cutoff = [0,1,1.5,2,4,50] spend['grp'] = pd.cut(spend['metric'], cutoff, include_lowest=True)","title":"bucketize"},{"location":"python/pandas/#datetime","text":"pd.to_datetime('2022-01-01') df['date_obj'].dt.date df['date_obj'].dt.strftime('%Y-%m-%d')","title":"datetime"},{"location":"python/pandas/#json","text":"import json import pandas as pd from pandas.io.json import json_normalize df = pd.read_csv('ss.csv', sep='\\t', index_col = False) with open('ssResult.json') as f: d = json.load(f) res = json_normalize(d) res.rename(columns={'event.bucket_name':'bucket', 'event.id':'id', 'timestamp':'dt', 'event.sum_revenue':'revenue', 'event.sum_amount':'amount'}, inplace=True) res.drop(['version'], axis=1, inplace=True) res['dt'] = res.dt.str.slice(0,10) res['dt'] = res.dt.str.replace('-','') res.groupby('dt')[['id']].size()","title":"json"},{"location":"python/pandas/#apply-fn-to-row","text":"use %timeit $command in jupyter cell for runtime loop over all rows in df (56s) def loop_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) result = [] for i in range(len(df)): row = df.iloc[i] result.append( eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date) ) return pd.Series(result) iterrows (9s) def iterrows_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date) for index, row in df.iterrows() ) itertuples (211ms) itertuples processes rows as tuples. def itertuples_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date) for row in df.itertuples() ) apply (1.85s) Pandas DataFrame apply function is quite versatile and is a popular choice. To make it process the rows, you have to pass axis=1 argument. def apply_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return df.apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1 ) list comprehension (78ms) A column in DataFrame is a Series that can be used as a list in a list comprehension expression. If multiple columns are needed, then zip can be used to make a list of tuples. [ foo(x) for x in df['x'] ] def list_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series([ eisenhower_action(priority == 'HIGH', due_date <= cutoff_date) for (priority, due_date) in zip(df['priority'], df['due_date']) ]) map (71ms) Python\u2019s map function that takes in function and iterables of parameters, and yields results. def map_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( map(eisenhower_action, df['priority'] == 'HIGH', df['due_date'] <= cutoff_date) ) vectorization (20ms) The real power of Pandas shows up in vectorization. But it requires unpacking the function as a vector expression. def map_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return pd.Series( map(eisenhower_action, df['priority'] == 'HIGH', df['due_date'] <= cutoff_date) ) numpy vectorize (35ms) NumPy offers alternatives for migrating from Python to Numpy through vectorization. For example, it has a vectorize() function that vectorzie any scalar function to accept and return NumPy arrays. def np_vec_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return np.vectorize(eisenhower_action)( df['priority'] == 'HIGH', df['due_date'] <= cutoff_date ) Numba Decorators (19ms) Numba is commonly used to speed up applying mathematical functions. It has various decorators for JIT compilation and vectorization. import numba @numba.vectorize def eisenhower_action(is_important: bool, is_urgent: bool) -> int: return 2 * is_important + is_urgent def numba_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return eisenhower_action( (df['priority'] == 'HIGH').to_numpy(), (df['due_date'] <= cutoff_date).to_numpy() ) Multiprocessing with pandarallel (2s) The pandarallel package utilizes multiple CPUs and split the work into multiple threads. from pandarallel import pandarallel pandarallel.initialize() def pandarallel_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return df.parallel_apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1 ) Parallelize with Dask (2s) Dask is a parallel computing library that supports scaling up NumPy, Pandas, Scikit-learn, and many other Python libraries. It offers efficient infra for processing a massive amount of data on multi-node clusters. import dask.dataframe as dd def dask_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return dd.from_pandas(df, npartitions=CPU_COUNT).apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1, meta=(int) ).compute() Opportunistic Parallelization with Swifter (22ms) Swifter automatically decides which is faster: to use Dask parallel processing or a simple Pandas apply. It is very simple to use: just all one word to how one uses Pandas apply function: df.swifter.apply. import swifter def swifter_impl(df): cutoff_date = datetime.date.today() + datetime.timedelta(days=2) return df.swifter.apply( lambda row: eisenhower_action( row.priority == 'HIGH', row.due_date <= cutoff_date), axis=1 )","title":"apply fn to row"},{"location":"python/plot/","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.ticker as mtick from matplotlib import rcParams %matplotlib inline import seaborn as sns import warnings warnings.filterwarnings('ignore') pandas df df = pd.DataFrame({ 'name':['john','mary','peter','jeff','bill','lisa','jose'], 'age':[23,78,22,19,45,33,20], 'gender':['M','F','M','M','M','F','M'], 'state':['california','dc','california','dc','california','texas','texas'], 'num_children':[2,0,0,3,2,1,4], 'num_pets':[5,1,0,5,2,2,3] }) scatter plot df.plot(kind='scatter', x='num_children', y='num_pets', color='red') plt.show() bar chart basic df.plot(kind='bar', x='name', y='age') plt.show() group by df.groupby('state')['name'].nunique().plot(kind='bar') plt.show() stacked bar plot w/ group by df.groupby(['state','gender']).size().unstack().plot(kind='bar', stacked=True) plt.show() stacked bar w/ group by (normalized %) df.groupby(['gender','state']).size().groupby(level=0).apply( lambda x: 100 * x / x.sum() ).unstack().plot(kind='bar',stacked=True) plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter()) plt.show() line chart basic ax = plt.gca() # gca = get current axis df.plot(kind='line',x='name',y='num_children',ax=ax) df.plot(kind='line',x='name',y='num_pets', color='red', ax=ax) plt.show() group by fig, ax = plt.subplots(figsize=(12,5)) df.groupby(['total_latency','device'])['cnt'].sum().unstack()\\ .plot(kind='line', ax=ax) pd.pivot_table(df, index='total_latency', columns='device_type', values='cnt').plot(subplots=True, figsize=(15,7)) histogram basic df[['age']].plot(kind='hist',bins=[0,20,40,60,80,100],rwidth=0.8) plt.show() date histogram df2 = pd.DataFrame({ 'name':[ 'john','lisa','peter','carl','linda','betty' ], 'date_of_birth':[ '01/21/1988','03/10/1977','07/25/1999','01/22/1977','09/30/1968','09/15/1970' ] }) df2['date_of_birth'] = pd.to_datetime(df2['date_of_birth'],infer_datetime_format=True) plt.clf() df2['date_of_birth'].map(lambda d: d.month).plot(kind='hist') plt.show() histogram with line example 1 # 1.) Necessary imports. import numpy as np import matplotlib.pyplot as plt from scipy.optimize import curve_fit # 2.) Define fit function. def fit_function(x, A, beta, B, mu, sigma): return (A * np.exp(-x/beta) + B * np.exp(-1.0 * (x - mu)**2 / (2 * sigma**2))) # 3.) Generate exponential and gaussian data and histograms. data = np.random.exponential(scale=2.0, size=100000) data2 = np.random.normal(loc=3.0, scale=0.3, size=15000) bins = np.linspace(0, 6, 61) data_entries_1, bins_1 = np.histogram(data, bins=bins) data_entries_2, bins_2 = np.histogram(data2, bins=bins) # 4.) Add histograms of exponential and gaussian data. data_entries = data_entries_1 + data_entries_2 binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)]) # 5.) Fit the function to the histogram data. popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[20000, 2.0, 2000, 3.0, 0.3]) print(popt) # 6.) Generate enough x values to make the curves look smooth. xspace = np.linspace(0, 6, 100000) # Plot the histogram and the fitted function. plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy', label=r'Histogram entries') plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function') # Make the plot nicer. plt.xlim(0,6) plt.xlabel(r'x axis') plt.ylabel(r'Number of entries') plt.title(r'Exponential decay with gaussian peak') plt.legend(loc='best') plt.show() plt.clf() example 2 import matplotlib import numpy as np import matplotlib.pyplot as plt np.random.seed(19680801) # example data mu = 100 # mean of distribution sigma = 15 # standard deviation of distribution x = mu + sigma * np.random.randn(437) num_bins = 50 fig, ax = plt.subplots() # the histogram of the data n, bins, patches = ax.hist(x, num_bins, density=1) # add a 'best fit' line y = ((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * (1 / sigma * (bins - mu))**2)) ax.plot(bins, y, '--') ax.set_xlabel('Smarts') ax.set_ylabel('Probability density') ax.set_title(r'Histogram of IQ: $\\mu=100$, $\\sigma=15$') # Tweak spacing to prevent clipping of ylabel fig.tight_layout() plt.show() example 3 rcParams['patch.force_edgecolor'] = True #rcParams['patch.facecolor'] = 'b' def plotHistwithLine(df, bin_size, title): deal = df.groupby(['d']).agg({'imp':sum, 'resp':sum}).reset_index() deal['win_rate'] = deal['imp'] / deal['resp'] deal['win_rate'] = deal['win_rate'].apply(lambda x: 1 if x>1 else x) # take care cases of win_rate>1 plt.figure(figsize=(8,6)) ax = plt.gca() ax2= plt.twinx() sns.distplot(deal['win_rate'], ax=ax, hist=True, kde=False, bins=bin_size) sns.distplot(deal['win_rate'], ax=ax2, hist=False, kde=True, bins=bin_size, color='b') #plt.xlim(0,1) plt.title(title) ax.set_xlabel('% win rate') ax.set_ylabel('num of deals') #ax2.axes.get_xaxis().set_ticks([]) #ax2.set_xticks([]) #ax2.set_visible(False) plt.show() pairplots sns.pairplot(df.loc[:, df.dtypes=='int64']) correlation heatmaps corr = df.loc[:, df.dtypes=='int64'].corr() sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=sns.diverging_palette(220, 10, as_cmap=True)) plt.show() boxplots data spread = np.random.rand(50) * 100 center = np.ones(25) * 50 flier_high = np.random.rand(10) * 100 + 100 flier_low = np.random.rand(10) - 100 data = np.concatenate((spread, center, flier_high, flier_low), 0) data basic plt.boxplot(data) plt.show() notched plt.boxplot(data, 1) plt.show() change outlier symbols plt.boxplot(data, 0, 'gD') plt.show() don't show outliers plt.boxplot(data, 0, '') plt.show() horizontal plt.boxplot(data, 0, 'rs', 0) plt.show() change change whiker length plt.boxplot(data, 0, 'rs', 0, 0.75) plt.show() 2-D array spread = np.random.rand(50) * 100 center = np.ones(25) * 50 flier_high = np.random.rand(10) * 100 + 100 flier_low = np.random.rand(10) - 100 d2 = np.concatenate((spread, center, flier_high, flier_low), 0) data.shape = (-1 ,1) d2.shape = (-1, 1) data2 = [data, d2, d2[::2, 0]] basic plt.boxplot(data2) plt.show() plot from pivot data df = pd.DataFrame({ 'date': ['1/1/2020','1/2/2020','1/3/2020','1/4/2020','1/5/2020', '1/1/2020','1/2/2020','1/3/2020','1/4/2020','1/5/2020', '1/1/2020','1/2/2020','1/3/2020','1/4/2020','1/5/2020'], 'SSP': ['SSP1','SSP1','SSP1','SSP1','SSP1', 'SSP2','SSP2','SSP2','SSP2','SSP2', 'SSP3','SSP3','SSP3','SSP3','SSP3'], 'spend': [5, 2, 4, 2, 3, 6, 0, 5, 2, 4, 7, 3,5, 6, 2] }) pv_df = df.pivot('date', columns='SSP', values='spend') pv_df.reset_index() lines in one graph pv_df.plot(figsize=(8,4), legend=True, grid=True, xticks=range(5), rot=10) line per graph pv_df.plot(subplots=True, figsize=(8,6), legend=True, grid=True, xticks=range(5)) subplots example 1 fig = plt.figure(figsize=(15,14)) ax1 = plt.subplot(2, 2, 1) ax2 = plt.subplot(2, 2, 2) ax3 = plt.subplot(2, 2, 3) ax4 = plt.subplot(2, 2, 4) df_sub.boxplot(column=['total_latency'], by='device', ax=ax1) df_sub.boxplot(column=['total_latency'], by='media', ax=ax2) df_sub[df_sub['total_latency']<200].boxplot(column=['total_latency'], by='device', ax=ax3) df_sub[df_sub['total_latency']<200].boxplot(column=['total_latency'], by='media', ax=ax4) plt.show() # all in one plot fig, ax = plt.subplots(figsize=(12,5)) df_sub[df_sub['total_latency']<60].groupby(['total_latency', 'device'])['cnt'].sum().unstack().plot(kind='line', ax=ax) # stacked plots pd.pivot_table(df_sub[df_sub['total_latency']<60], index='total_latency', columns='device', values='cnt' ).plot(subplots=True, figsize=(15,7)) example 2 fig, (ax) = plt.subplots(ncols=2, nrows=2, figsize=(18, 12)) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group1')&(data['type']=='multi')], hue='host', palette=\"Blues\", ax=ax[0,0]) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group1')&(data['type']=='solo')], hue='host', palette=\"Blues\", ax=ax[0,1]) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group2')&(data['type']=='multi')], hue='host', palette=\"Blues\", ax=ax[1,0]) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group2')&(data['type']=='solo')], hue='host', palette=\"Blues\", ax=ax[1,1]) ax[0,0].set_title('[group1] highlight') ax[0,1].set_title('[group1] others') ax[1,0].set_title('[group2] highlight') ax[1,1].set_title('[group2] others') ax[0,0].legend(loc='lower right') ax[0,1].legend(loc='lower right') ax[1,0].legend(loc='lower right') ax[1,1].legend(loc='lower right') fig.suptitle('traffic', fontsize=20) plt.show() annotate aggregation and annotation x = np.arange(5) y = res['[total] SUM of inv_cost']['sum'] plt.bar(x,y) for i, j in zip(x,y): plt.annotate(str(j),xy=(i,j)) plt.show() sankey diagram How To Create Sankey Diagrams from DataFrames in Python Sankey-view Documentation","title":"plot"},{"location":"python/plot/#pandas-df","text":"df = pd.DataFrame({ 'name':['john','mary','peter','jeff','bill','lisa','jose'], 'age':[23,78,22,19,45,33,20], 'gender':['M','F','M','M','M','F','M'], 'state':['california','dc','california','dc','california','texas','texas'], 'num_children':[2,0,0,3,2,1,4], 'num_pets':[5,1,0,5,2,2,3] })","title":"pandas df"},{"location":"python/plot/#scatter-plot","text":"df.plot(kind='scatter', x='num_children', y='num_pets', color='red') plt.show()","title":"scatter plot"},{"location":"python/plot/#bar-chart","text":"basic df.plot(kind='bar', x='name', y='age') plt.show() group by df.groupby('state')['name'].nunique().plot(kind='bar') plt.show() stacked bar plot w/ group by df.groupby(['state','gender']).size().unstack().plot(kind='bar', stacked=True) plt.show() stacked bar w/ group by (normalized %) df.groupby(['gender','state']).size().groupby(level=0).apply( lambda x: 100 * x / x.sum() ).unstack().plot(kind='bar',stacked=True) plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter()) plt.show()","title":"bar chart"},{"location":"python/plot/#line-chart","text":"basic ax = plt.gca() # gca = get current axis df.plot(kind='line',x='name',y='num_children',ax=ax) df.plot(kind='line',x='name',y='num_pets', color='red', ax=ax) plt.show() group by fig, ax = plt.subplots(figsize=(12,5)) df.groupby(['total_latency','device'])['cnt'].sum().unstack()\\ .plot(kind='line', ax=ax) pd.pivot_table(df, index='total_latency', columns='device_type', values='cnt').plot(subplots=True, figsize=(15,7))","title":"line chart"},{"location":"python/plot/#histogram","text":"basic df[['age']].plot(kind='hist',bins=[0,20,40,60,80,100],rwidth=0.8) plt.show() date histogram df2 = pd.DataFrame({ 'name':[ 'john','lisa','peter','carl','linda','betty' ], 'date_of_birth':[ '01/21/1988','03/10/1977','07/25/1999','01/22/1977','09/30/1968','09/15/1970' ] }) df2['date_of_birth'] = pd.to_datetime(df2['date_of_birth'],infer_datetime_format=True) plt.clf() df2['date_of_birth'].map(lambda d: d.month).plot(kind='hist') plt.show()","title":"histogram"},{"location":"python/plot/#histogram-with-line","text":"example 1 # 1.) Necessary imports. import numpy as np import matplotlib.pyplot as plt from scipy.optimize import curve_fit # 2.) Define fit function. def fit_function(x, A, beta, B, mu, sigma): return (A * np.exp(-x/beta) + B * np.exp(-1.0 * (x - mu)**2 / (2 * sigma**2))) # 3.) Generate exponential and gaussian data and histograms. data = np.random.exponential(scale=2.0, size=100000) data2 = np.random.normal(loc=3.0, scale=0.3, size=15000) bins = np.linspace(0, 6, 61) data_entries_1, bins_1 = np.histogram(data, bins=bins) data_entries_2, bins_2 = np.histogram(data2, bins=bins) # 4.) Add histograms of exponential and gaussian data. data_entries = data_entries_1 + data_entries_2 binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)]) # 5.) Fit the function to the histogram data. popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[20000, 2.0, 2000, 3.0, 0.3]) print(popt) # 6.) Generate enough x values to make the curves look smooth. xspace = np.linspace(0, 6, 100000) # Plot the histogram and the fitted function. plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy', label=r'Histogram entries') plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function') # Make the plot nicer. plt.xlim(0,6) plt.xlabel(r'x axis') plt.ylabel(r'Number of entries') plt.title(r'Exponential decay with gaussian peak') plt.legend(loc='best') plt.show() plt.clf() example 2 import matplotlib import numpy as np import matplotlib.pyplot as plt np.random.seed(19680801) # example data mu = 100 # mean of distribution sigma = 15 # standard deviation of distribution x = mu + sigma * np.random.randn(437) num_bins = 50 fig, ax = plt.subplots() # the histogram of the data n, bins, patches = ax.hist(x, num_bins, density=1) # add a 'best fit' line y = ((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * (1 / sigma * (bins - mu))**2)) ax.plot(bins, y, '--') ax.set_xlabel('Smarts') ax.set_ylabel('Probability density') ax.set_title(r'Histogram of IQ: $\\mu=100$, $\\sigma=15$') # Tweak spacing to prevent clipping of ylabel fig.tight_layout() plt.show() example 3 rcParams['patch.force_edgecolor'] = True #rcParams['patch.facecolor'] = 'b' def plotHistwithLine(df, bin_size, title): deal = df.groupby(['d']).agg({'imp':sum, 'resp':sum}).reset_index() deal['win_rate'] = deal['imp'] / deal['resp'] deal['win_rate'] = deal['win_rate'].apply(lambda x: 1 if x>1 else x) # take care cases of win_rate>1 plt.figure(figsize=(8,6)) ax = plt.gca() ax2= plt.twinx() sns.distplot(deal['win_rate'], ax=ax, hist=True, kde=False, bins=bin_size) sns.distplot(deal['win_rate'], ax=ax2, hist=False, kde=True, bins=bin_size, color='b') #plt.xlim(0,1) plt.title(title) ax.set_xlabel('% win rate') ax.set_ylabel('num of deals') #ax2.axes.get_xaxis().set_ticks([]) #ax2.set_xticks([]) #ax2.set_visible(False) plt.show()","title":"histogram with line"},{"location":"python/plot/#pairplots","text":"sns.pairplot(df.loc[:, df.dtypes=='int64'])","title":"pairplots"},{"location":"python/plot/#correlation-heatmaps","text":"corr = df.loc[:, df.dtypes=='int64'].corr() sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=sns.diverging_palette(220, 10, as_cmap=True)) plt.show()","title":"correlation heatmaps"},{"location":"python/plot/#boxplots","text":"","title":"boxplots"},{"location":"python/plot/#data","text":"spread = np.random.rand(50) * 100 center = np.ones(25) * 50 flier_high = np.random.rand(10) * 100 + 100 flier_low = np.random.rand(10) - 100 data = np.concatenate((spread, center, flier_high, flier_low), 0) data basic plt.boxplot(data) plt.show() notched plt.boxplot(data, 1) plt.show() change outlier symbols plt.boxplot(data, 0, 'gD') plt.show() don't show outliers plt.boxplot(data, 0, '') plt.show() horizontal plt.boxplot(data, 0, 'rs', 0) plt.show() change change whiker length plt.boxplot(data, 0, 'rs', 0, 0.75) plt.show()","title":"data"},{"location":"python/plot/#2-d-array","text":"spread = np.random.rand(50) * 100 center = np.ones(25) * 50 flier_high = np.random.rand(10) * 100 + 100 flier_low = np.random.rand(10) - 100 d2 = np.concatenate((spread, center, flier_high, flier_low), 0) data.shape = (-1 ,1) d2.shape = (-1, 1) data2 = [data, d2, d2[::2, 0]] basic plt.boxplot(data2) plt.show()","title":"2-D array"},{"location":"python/plot/#plot-from-pivot","text":"data df = pd.DataFrame({ 'date': ['1/1/2020','1/2/2020','1/3/2020','1/4/2020','1/5/2020', '1/1/2020','1/2/2020','1/3/2020','1/4/2020','1/5/2020', '1/1/2020','1/2/2020','1/3/2020','1/4/2020','1/5/2020'], 'SSP': ['SSP1','SSP1','SSP1','SSP1','SSP1', 'SSP2','SSP2','SSP2','SSP2','SSP2', 'SSP3','SSP3','SSP3','SSP3','SSP3'], 'spend': [5, 2, 4, 2, 3, 6, 0, 5, 2, 4, 7, 3,5, 6, 2] }) pv_df = df.pivot('date', columns='SSP', values='spend') pv_df.reset_index() lines in one graph pv_df.plot(figsize=(8,4), legend=True, grid=True, xticks=range(5), rot=10) line per graph pv_df.plot(subplots=True, figsize=(8,6), legend=True, grid=True, xticks=range(5))","title":"plot from pivot"},{"location":"python/plot/#subplots","text":"example 1 fig = plt.figure(figsize=(15,14)) ax1 = plt.subplot(2, 2, 1) ax2 = plt.subplot(2, 2, 2) ax3 = plt.subplot(2, 2, 3) ax4 = plt.subplot(2, 2, 4) df_sub.boxplot(column=['total_latency'], by='device', ax=ax1) df_sub.boxplot(column=['total_latency'], by='media', ax=ax2) df_sub[df_sub['total_latency']<200].boxplot(column=['total_latency'], by='device', ax=ax3) df_sub[df_sub['total_latency']<200].boxplot(column=['total_latency'], by='media', ax=ax4) plt.show() # all in one plot fig, ax = plt.subplots(figsize=(12,5)) df_sub[df_sub['total_latency']<60].groupby(['total_latency', 'device'])['cnt'].sum().unstack().plot(kind='line', ax=ax) # stacked plots pd.pivot_table(df_sub[df_sub['total_latency']<60], index='total_latency', columns='device', values='cnt' ).plot(subplots=True, figsize=(15,7)) example 2 fig, (ax) = plt.subplots(ncols=2, nrows=2, figsize=(18, 12)) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group1')&(data['type']=='multi')], hue='host', palette=\"Blues\", ax=ax[0,0]) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group1')&(data['type']=='solo')], hue='host', palette=\"Blues\", ax=ax[0,1]) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group2')&(data['type']=='multi')], hue='host', palette=\"Blues\", ax=ax[1,0]) sns.boxplot(x='dt',y='cnt',data=data[(df['group']=='group2')&(data['type']=='solo')], hue='host', palette=\"Blues\", ax=ax[1,1]) ax[0,0].set_title('[group1] highlight') ax[0,1].set_title('[group1] others') ax[1,0].set_title('[group2] highlight') ax[1,1].set_title('[group2] others') ax[0,0].legend(loc='lower right') ax[0,1].legend(loc='lower right') ax[1,0].legend(loc='lower right') ax[1,1].legend(loc='lower right') fig.suptitle('traffic', fontsize=20) plt.show()","title":"subplots"},{"location":"python/plot/#annotate","text":"aggregation and annotation x = np.arange(5) y = res['[total] SUM of inv_cost']['sum'] plt.bar(x,y) for i, j in zip(x,y): plt.annotate(str(j),xy=(i,j)) plt.show()","title":"annotate"},{"location":"python/plot/#sankey-diagram","text":"How To Create Sankey Diagrams from DataFrames in Python Sankey-view Documentation","title":"sankey diagram"},{"location":"python/pyspark/","text":"libraries from pyspark.sql import SparkSession, Row, Window from pyspark.sql.types import * import pyspark.sql.functions as F from pyspark.mllib.stat import Statistics from pyspark.mllib.linalg import Vectors from pyspark.mllib.regression import LabeledPoint from collections import OrderedDict from datetime import datetime, timedelta data I/O read data hive sql_query = \"\"\" SELECT * FROM $db_name.tb_name WHERE datestamp = '%s' \"\"\"%(utc_hour) df = spark.sql(sql_query) avro df = spark.read.format(\"com.databricks.spark.avro\").load(file_path) csv file_path = '/user/test.csv' df = spark.read.csv(file_path, header=True).drop('index') df = spark.read.csv(file_path, header=True, sep='\\t') df = spark.read.format(\"com.databricks.spark.csv\").option(\"delimiter\", \"\\t\").option(\"header\", \"true\").load(file_path) parquet df = spark.read.orc() orc df = spark.read.orc() bz2 df = spark.read.format('json').load() create UDFs to read hourly and aggregate to daily def read_snapshot_hourly(utc_hour): url = \"test.csv\" mapping = spark.read.csv(url, header=False).drop('index') mapping = mapping.withColumnRenamed('_c0','id').withColumnRenamed('_c1','cnt') mapping = mapping.select('id','cnt') mapping = mapping.withColumn('hour', lit(utc_hour)) return mapping def read_snapshot_daily(utc_date): field = [StructField(\"id\",IntegerType(), True), StructField(\"cnt\", StringType(), True), StructField(\"hour\", StringType(), True)] schema = StructType(field) mapdf = sqlContext.createDataFrame(sc.emptyRDD(), schema) for i in range(0,24): j = str(i).zfill(2) utc_hour = utc_date + j mapping = read_snapshot_hourly(utc_hour) mapdf = mapdf.union(mapping) return mapdf sc.parallelize(...) spread the data amongst all executors sc.broadcast(...) copy the data in the jvm of each executor write data hive res.write.format(\"orc\").saveAsTable(\"$db_name.$table_name\") res.coalesce(10).write.partitionBy(\"dt\", \"hour\").saveAsTable(\"$db_name.$table_name\", format = \"orc\", mode = \"overwrite\") insert partitions into hive table if tb_name not in sql_context.tableNames(db_name): res.write.partitionBy(\"datestamp\").saveAsTable(\"%s.%s\"%(db_name, tb_name), format=\"orc\", mode=\"append\") else: spark.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\", \"true\") spark.sql(\"ALTER TABLE %s.%s DROP IF EXISTS PARTITION (datestamp=%s)\"%(db_name, tb_name, utc_hour)) res.write.partitionBy(\"datestamp\").saveAsTable(\"%s.%s\"%(db_name, tb_name), format=\"orc\", mode=\"append\") avro res_path = \"/user/res/\" + mydate res.write.format(\"com.databricks.spark.avro\").save(res_path) csv res_path = '/user/res' res.coalesce(1).write.csv(res_path, header=True) data explore print df.printSchema() print df.dtypes print df.first() print df.collect() print df.limit(5).show() print df.show(5) print df.count() df.columns df.schema.names cols = [i for i in df if i[:8]==date] cols.append('line_id') data process toPandas it is encouraged to use native PySpark against Pandas dfpd = df.toPandas() create table create empty table from pyspark.sql import SQLContext sc = spark.sparkContext sqlContext = SQLContext(sc) # need the above for PySpark Shell field = [StructField(\"id\",StringType(), True), StructField(\"cnt\", IntergerType(), True), StructField(\"hour\", StringType(), True)] schema = StructType(field) mapdf = sqlContext.createDataFrame(sc.emptyRDD(), schema) create random table df = sqlContext.range(0, 10) df = df.select(\"id\", rand(seed=10).alias(\"uniform\"), randn(seed=27).alias(\"normal\")) create from empty pandas dataframe empty_dict = dict() pd_empty = pd.DataFrame.from_dict(df_perf_dict, orient='index', columns=['score']) empty_schema = StructType([StructField('score', DoubleType(), False)]) spark_empty = spark.createDataFrame(pd_empty, schema= empty_schema) create dataframe from list schema = StructType([StructField('id', StringType()), StructField('cnt', IntegerType())]) val = [[1, 13234121], [2, 233], [3, 13132]] df = spark.createDataFrame(val, schema=schema) create col create new columns and assign values df = df.na.fill('0') df.na.fill({'age': 50, 'name': 'unknown'}) df = df.withColumn('if_null', F.when(df.id=='00000',-1) .F.when(df.id=='',0) .otherwise(1)) df = df.withColumn('click_label', F.when(df.click_label==-1,0) .otherwise(df.click_label) .alias('click_label')) df = df.select(*(F.when((col(c))=='', None).otherwise(col(c)).alias(c) for c in df.columns)) df = df.withColumn('app_id',regexp_replace('app_id','APPIDC:','')) df = df.withColumn('category', explode(split('category','APPC:'))) df = df.select(F.substring(df.label,6,100).alias('label')) create empty column in dataframe empty_schema = StructType([StructField('id', StringType(),True), StructField('price', DoubleType(),True), StructField('type', StringType(),True), StructField('info_bag', ArrayType(StructType( [StructField('seats', StringType(),True)]),True),True), StructField('level',StringType(),True)]) df = df.withColumn('info_exp', lit(None).cast(empty_schema)) rename col for c,n in zip(df.columns, newcolnames): df = df.withColumnRenamed(c,n) filters df = df.filter((df.type_id==2) | (df.type_id==3)) df = df.filter(F.col('id')==19) df = df.filter(df.name.isNotNull()).filter(df.name !=\"\") df.filter(\"region='US' and name in ('John','Jane')\").show() change data type df = df.withColumn('id', df.id.cast('integer')) df_num = df_num.select(*(col(c).cast('integer') for c in df_num.columns)) df_num_rdd = df_num.rdd.map(lambda data: Vectors.dense([int(c) for c in data])) OrderedDict(sorted(result_dic.items(), key=lambda t: t[1],reverse=True)) unique value to list browser_list = df.select('name').rdd.flatMap(lambda x: x).collect() use SQL syntax df.registerTempTable(\"people\") a = sqlContext.sql(\"select * from people\") a.show() regular expression vista = vista.withColumn('v_version', F.when(vista.debug_metrics.like('%0.0.%'),1)\\ .F.when(vista.debug_metrics.like('%2.0.%'),2)\\ .otherwise(0)) distinct df.groupBy('click_label').count().show() df.groupby('id_type').agg(countDistinct('id').alias('u_id')).orderBy('u_id').show() df.select( [ countDistinct(cn).alias(cn) for cn in df.columns ] ).show() df.select('user_id').distinct().show() substring dd2 = [('device1','APPC:1'), ('device2','APPC:2'), ('device3','APPC:3')] test2 = spark.createDataFrame(dd2, ['id','label']) replace1 = test2.select(F.substring(test2.label,6,100).alias('label')) replace2 = test2.select(F.regexp_replace('label','APPC:','').alias('label')) explode dd3 = [('device1','APPC:lifeAPPC:sports'), ('device2','APPC:lifeAPPC:gameAPPC:sports'), ('device3','APPC:sports'), ('device4','nah')] test3 = spark.createDataFrame(dd3, ['id','group']) explode = test3.withColumn('group', F.explode(split('group','APPC:')))) explode = explode.filter(F.explode.group !=\"\") extract dd4 = [('device1','APPIDC:1'), ('device2','APPIDC:2'), ('device3','APPIDC:3'), ('device4','')] test4 = spark.createDataFrame(dd4, ['id','group']) extract0 = test4.withColumn('group', F.when(test4.group=='', None).otherwise(test4.group)) extract00 = extract0.na.fill('0') extract = extract00.withColumn('group', F.regexp_replace('group','APPIDC:','')) hashing dd5 = [('device1','level1'), ('device2','level2'), ('device3','level1'), ('device4','')] test5 = spark.createDataFrame(dd5, ['id','group']) test5.select(F.hash('group')).show() column intersection with list dd6 = [('d1',[1,2,3]), ('d2',[1,2]), ('d3',[4]), ('d4',[3])] test6 = spark.createDataFrame(dd6, ['id','labels']) test_list = [2,3] intersect_udf = lambda y: (F.udf( lambda x: ( list(set(x) & set(y)) if x is not None and y is not None else None), ArrayType(IntegerType()))) intersect_with_bucket = intersect_udf(test_list) test6 = test6.withColumn('intersect', intersect_with_bucket(test6.labels)) test6 = test6.withColumn('size', F.size(intersect_with_bucket(test6.labels))) test6.show() table transform join tables side by side df_join = df1.join(df2, df1.source == df2.source, 'outer') df_join = df1.join(df2, 'source', 'outer') skewdf = bigdf.join(F.broadcast(smalldf), key) stack tablenew = table1.union(table2) pivot table df.groupBy('reason').pivot('id_type').agg(F.sum('cnt')).na.fill(0) .orderBy('reason').show(10) cross tabulation / contigency table names = [\"Alice\", \"Bob\", \"Mike\"] items = [\"milk\", \"bread\", \"butter\", \"apples\", \"oranges\"] df = sqlContext.createDataFrame([(names[i % 3], items[i % 5]) for i in range(100)], [\"name\", \"item\"]) df.stat.crosstab(\"name\", \"item\").show() (cumulative) percentages from pyspark.sql import Window df = df.withColumn('total_req', F.sum('req_cnt').over(Window.partitionBy(key_col)))\\ .withColumn('req_p', F.round(100*F.col('req_cnt')/F.col('total_req'),1)) windowval = (Window.partitionBy('bucket').orderBy('fallout_bucket') .rangeBetween(Window.unboundedPreceding, 0)) df = df.withColumn('cum_load', F.sum('load').over(windowval).cast('integer')) df = df.withColumn('adj_cum_load',F.round(df.cum_load/df.traffic_p,0).cast('integer')) row difference my_window = Window.partitionBy().orderBy('time') # get value from the previous row df = df.withColumn('prev_value', F.lead(df.value).over(my_window)) df = df.withColumn('diff', F.when(F.isnull(df.value - df.prev_value), 0).otherwise(df.value - df.prev_value)) # get value from the following row df = df.withColumn('prev_value', F.lag(df.value).over(my_window)) df = df.withColumn('diff', F.when(F.isnull(df.value - df.prev_value), 0).otherwise(df.value - df.prev_value)) bucketizer from pyspark.ml.feature import Bucketizer splits = [-float(\"inf\"), -0.5, 0.0, 0.5, float(\"inf\")] data = [(-999.9,), (-0.5,), (-0.3,), (0.0,), (0.2,), (999.9,)] df = spark.createDataFrame(data, [\"features\"]) bucketizer = Bucketizer(splits=splits, inputCol=\"features\", outputCol=\"bucketedFeatures\") print splits print df.show() # Transform original data into its bucket index. bucketedData = bucketizer.transform(df) print(\"Bucketizer output with %d buckets\" % (len(bucketizer.getSplits())-1)) bucketedData.show() stats basic statistics df.groupBy().agg(F.min('value'),F.avg('value'),F.max('value')).show() pearson / spearman R correlation test df = df.select(*(col(c).cast('float') for c in df.columns)) df_rdd = df.rdd.map(lambda data: Vectors.dense([c for c in data])) result_matrix = Statistics.corr(df_rdd, method=\"pearson\") result_matrix = Statistics.corr(df_rdd, method=\"spearman\") result_dic = dict(zip(df_num.columns, result_matrix[0].tolist())) result_num = pd.DataFrame({'column': result_dic.keys(), 'corr': result_dic.values()}) chi-square test df = df.na.fill('nah') df = df.select(*(hash(col(c)).cast('integer') for c in df.columns)) df_rdd = df.rdd.map(lambda data: Vectors.dense([c for c in data])) df_rdd = df_rdd.map(lambda row: LabeledPoint(row[0],row[1:])) obs = sc.parallelize( [LabeledPoint(1.0, [1.0,3.0]), LabeledPoint(1.0, [1.0,0.0]), LabeledPoint(1.0, [-1.0,-0.5])] ) featureTestResults = Statistics.chiSqTest(obs) for i, result in enumerate(featureTestResults_all_1): print(\"Click correlation with %s:\\n%s\\n\" % (df_rdd.columns[i+1], result)) res = [] for i, result in enumerate(featureTestResults): row = [] row.append(i) row.append(result.degreesOfFreedom) row.append(result.pValue) row.append(result.statistic) res.append(row) res = pd.DataFrame(res,columns=['col','dof','p','chi-sq']) res UDFs and UDAFs def convert_big_num_smart(num): if num >= 1e9: big_num = str(round(num / 1e9, 1)) + 'B' elif num >= 1e6: big_num = str(round(num / 1e6, 1)) + 'M' elif num >= 1e3: big_num = str(round(num / 1e3, 1)) + 'K' else: big_num = str(round(num, 1)) return big_num convertBigNumSmartUDF = F.udf(convert_big_num_smart, StringType())","title":"pyspark"},{"location":"python/pyspark/#libraries","text":"from pyspark.sql import SparkSession, Row, Window from pyspark.sql.types import * import pyspark.sql.functions as F from pyspark.mllib.stat import Statistics from pyspark.mllib.linalg import Vectors from pyspark.mllib.regression import LabeledPoint from collections import OrderedDict from datetime import datetime, timedelta","title":"libraries"},{"location":"python/pyspark/#data-io","text":"","title":"data I/O"},{"location":"python/pyspark/#read-data","text":"hive sql_query = \"\"\" SELECT * FROM $db_name.tb_name WHERE datestamp = '%s' \"\"\"%(utc_hour) df = spark.sql(sql_query) avro df = spark.read.format(\"com.databricks.spark.avro\").load(file_path) csv file_path = '/user/test.csv' df = spark.read.csv(file_path, header=True).drop('index') df = spark.read.csv(file_path, header=True, sep='\\t') df = spark.read.format(\"com.databricks.spark.csv\").option(\"delimiter\", \"\\t\").option(\"header\", \"true\").load(file_path) parquet df = spark.read.orc() orc df = spark.read.orc() bz2 df = spark.read.format('json').load() create UDFs to read hourly and aggregate to daily def read_snapshot_hourly(utc_hour): url = \"test.csv\" mapping = spark.read.csv(url, header=False).drop('index') mapping = mapping.withColumnRenamed('_c0','id').withColumnRenamed('_c1','cnt') mapping = mapping.select('id','cnt') mapping = mapping.withColumn('hour', lit(utc_hour)) return mapping def read_snapshot_daily(utc_date): field = [StructField(\"id\",IntegerType(), True), StructField(\"cnt\", StringType(), True), StructField(\"hour\", StringType(), True)] schema = StructType(field) mapdf = sqlContext.createDataFrame(sc.emptyRDD(), schema) for i in range(0,24): j = str(i).zfill(2) utc_hour = utc_date + j mapping = read_snapshot_hourly(utc_hour) mapdf = mapdf.union(mapping) return mapdf sc.parallelize(...) spread the data amongst all executors sc.broadcast(...) copy the data in the jvm of each executor","title":"read data"},{"location":"python/pyspark/#write-data","text":"hive res.write.format(\"orc\").saveAsTable(\"$db_name.$table_name\") res.coalesce(10).write.partitionBy(\"dt\", \"hour\").saveAsTable(\"$db_name.$table_name\", format = \"orc\", mode = \"overwrite\") insert partitions into hive table if tb_name not in sql_context.tableNames(db_name): res.write.partitionBy(\"datestamp\").saveAsTable(\"%s.%s\"%(db_name, tb_name), format=\"orc\", mode=\"append\") else: spark.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\", \"true\") spark.sql(\"ALTER TABLE %s.%s DROP IF EXISTS PARTITION (datestamp=%s)\"%(db_name, tb_name, utc_hour)) res.write.partitionBy(\"datestamp\").saveAsTable(\"%s.%s\"%(db_name, tb_name), format=\"orc\", mode=\"append\") avro res_path = \"/user/res/\" + mydate res.write.format(\"com.databricks.spark.avro\").save(res_path) csv res_path = '/user/res' res.coalesce(1).write.csv(res_path, header=True)","title":"write data"},{"location":"python/pyspark/#data-explore","text":"print df.printSchema() print df.dtypes print df.first() print df.collect() print df.limit(5).show() print df.show(5) print df.count() df.columns df.schema.names cols = [i for i in df if i[:8]==date] cols.append('line_id')","title":"data explore"},{"location":"python/pyspark/#data-process","text":"","title":"data process"},{"location":"python/pyspark/#topandas","text":"it is encouraged to use native PySpark against Pandas dfpd = df.toPandas()","title":"toPandas"},{"location":"python/pyspark/#create-table","text":"create empty table from pyspark.sql import SQLContext sc = spark.sparkContext sqlContext = SQLContext(sc) # need the above for PySpark Shell field = [StructField(\"id\",StringType(), True), StructField(\"cnt\", IntergerType(), True), StructField(\"hour\", StringType(), True)] schema = StructType(field) mapdf = sqlContext.createDataFrame(sc.emptyRDD(), schema) create random table df = sqlContext.range(0, 10) df = df.select(\"id\", rand(seed=10).alias(\"uniform\"), randn(seed=27).alias(\"normal\")) create from empty pandas dataframe empty_dict = dict() pd_empty = pd.DataFrame.from_dict(df_perf_dict, orient='index', columns=['score']) empty_schema = StructType([StructField('score', DoubleType(), False)]) spark_empty = spark.createDataFrame(pd_empty, schema= empty_schema) create dataframe from list schema = StructType([StructField('id', StringType()), StructField('cnt', IntegerType())]) val = [[1, 13234121], [2, 233], [3, 13132]] df = spark.createDataFrame(val, schema=schema)","title":"create table"},{"location":"python/pyspark/#create-col","text":"create new columns and assign values df = df.na.fill('0') df.na.fill({'age': 50, 'name': 'unknown'}) df = df.withColumn('if_null', F.when(df.id=='00000',-1) .F.when(df.id=='',0) .otherwise(1)) df = df.withColumn('click_label', F.when(df.click_label==-1,0) .otherwise(df.click_label) .alias('click_label')) df = df.select(*(F.when((col(c))=='', None).otherwise(col(c)).alias(c) for c in df.columns)) df = df.withColumn('app_id',regexp_replace('app_id','APPIDC:','')) df = df.withColumn('category', explode(split('category','APPC:'))) df = df.select(F.substring(df.label,6,100).alias('label')) create empty column in dataframe empty_schema = StructType([StructField('id', StringType(),True), StructField('price', DoubleType(),True), StructField('type', StringType(),True), StructField('info_bag', ArrayType(StructType( [StructField('seats', StringType(),True)]),True),True), StructField('level',StringType(),True)]) df = df.withColumn('info_exp', lit(None).cast(empty_schema))","title":"create col"},{"location":"python/pyspark/#rename-col","text":"for c,n in zip(df.columns, newcolnames): df = df.withColumnRenamed(c,n)","title":"rename col"},{"location":"python/pyspark/#filters","text":"df = df.filter((df.type_id==2) | (df.type_id==3)) df = df.filter(F.col('id')==19) df = df.filter(df.name.isNotNull()).filter(df.name !=\"\") df.filter(\"region='US' and name in ('John','Jane')\").show()","title":"filters"},{"location":"python/pyspark/#change-data-type","text":"df = df.withColumn('id', df.id.cast('integer')) df_num = df_num.select(*(col(c).cast('integer') for c in df_num.columns)) df_num_rdd = df_num.rdd.map(lambda data: Vectors.dense([int(c) for c in data])) OrderedDict(sorted(result_dic.items(), key=lambda t: t[1],reverse=True))","title":"change data type"},{"location":"python/pyspark/#unique-value-to-list","text":"browser_list = df.select('name').rdd.flatMap(lambda x: x).collect()","title":"unique value to list"},{"location":"python/pyspark/#use-sql-syntax","text":"df.registerTempTable(\"people\") a = sqlContext.sql(\"select * from people\") a.show()","title":"use SQL syntax"},{"location":"python/pyspark/#regular-expression","text":"vista = vista.withColumn('v_version', F.when(vista.debug_metrics.like('%0.0.%'),1)\\ .F.when(vista.debug_metrics.like('%2.0.%'),2)\\ .otherwise(0))","title":"regular expression"},{"location":"python/pyspark/#distinct","text":"df.groupBy('click_label').count().show() df.groupby('id_type').agg(countDistinct('id').alias('u_id')).orderBy('u_id').show() df.select( [ countDistinct(cn).alias(cn) for cn in df.columns ] ).show() df.select('user_id').distinct().show()","title":"distinct"},{"location":"python/pyspark/#substring","text":"dd2 = [('device1','APPC:1'), ('device2','APPC:2'), ('device3','APPC:3')] test2 = spark.createDataFrame(dd2, ['id','label']) replace1 = test2.select(F.substring(test2.label,6,100).alias('label')) replace2 = test2.select(F.regexp_replace('label','APPC:','').alias('label'))","title":"substring"},{"location":"python/pyspark/#explode","text":"dd3 = [('device1','APPC:lifeAPPC:sports'), ('device2','APPC:lifeAPPC:gameAPPC:sports'), ('device3','APPC:sports'), ('device4','nah')] test3 = spark.createDataFrame(dd3, ['id','group']) explode = test3.withColumn('group', F.explode(split('group','APPC:')))) explode = explode.filter(F.explode.group !=\"\")","title":"explode"},{"location":"python/pyspark/#extract","text":"dd4 = [('device1','APPIDC:1'), ('device2','APPIDC:2'), ('device3','APPIDC:3'), ('device4','')] test4 = spark.createDataFrame(dd4, ['id','group']) extract0 = test4.withColumn('group', F.when(test4.group=='', None).otherwise(test4.group)) extract00 = extract0.na.fill('0') extract = extract00.withColumn('group', F.regexp_replace('group','APPIDC:',''))","title":"extract"},{"location":"python/pyspark/#hashing","text":"dd5 = [('device1','level1'), ('device2','level2'), ('device3','level1'), ('device4','')] test5 = spark.createDataFrame(dd5, ['id','group']) test5.select(F.hash('group')).show()","title":"hashing"},{"location":"python/pyspark/#column-intersection-with-list","text":"dd6 = [('d1',[1,2,3]), ('d2',[1,2]), ('d3',[4]), ('d4',[3])] test6 = spark.createDataFrame(dd6, ['id','labels']) test_list = [2,3] intersect_udf = lambda y: (F.udf( lambda x: ( list(set(x) & set(y)) if x is not None and y is not None else None), ArrayType(IntegerType()))) intersect_with_bucket = intersect_udf(test_list) test6 = test6.withColumn('intersect', intersect_with_bucket(test6.labels)) test6 = test6.withColumn('size', F.size(intersect_with_bucket(test6.labels))) test6.show()","title":"column intersection with list"},{"location":"python/pyspark/#table-transform","text":"","title":"table transform"},{"location":"python/pyspark/#join-tables","text":"side by side df_join = df1.join(df2, df1.source == df2.source, 'outer') df_join = df1.join(df2, 'source', 'outer') skewdf = bigdf.join(F.broadcast(smalldf), key) stack tablenew = table1.union(table2)","title":"join tables"},{"location":"python/pyspark/#pivot-table","text":"df.groupBy('reason').pivot('id_type').agg(F.sum('cnt')).na.fill(0) .orderBy('reason').show(10)","title":"pivot table"},{"location":"python/pyspark/#cross-tabulation-contigency-table","text":"names = [\"Alice\", \"Bob\", \"Mike\"] items = [\"milk\", \"bread\", \"butter\", \"apples\", \"oranges\"] df = sqlContext.createDataFrame([(names[i % 3], items[i % 5]) for i in range(100)], [\"name\", \"item\"]) df.stat.crosstab(\"name\", \"item\").show()","title":"cross tabulation / contigency table"},{"location":"python/pyspark/#cumulative-percentages","text":"from pyspark.sql import Window df = df.withColumn('total_req', F.sum('req_cnt').over(Window.partitionBy(key_col)))\\ .withColumn('req_p', F.round(100*F.col('req_cnt')/F.col('total_req'),1)) windowval = (Window.partitionBy('bucket').orderBy('fallout_bucket') .rangeBetween(Window.unboundedPreceding, 0)) df = df.withColumn('cum_load', F.sum('load').over(windowval).cast('integer')) df = df.withColumn('adj_cum_load',F.round(df.cum_load/df.traffic_p,0).cast('integer'))","title":"(cumulative) percentages"},{"location":"python/pyspark/#row-difference","text":"my_window = Window.partitionBy().orderBy('time') # get value from the previous row df = df.withColumn('prev_value', F.lead(df.value).over(my_window)) df = df.withColumn('diff', F.when(F.isnull(df.value - df.prev_value), 0).otherwise(df.value - df.prev_value)) # get value from the following row df = df.withColumn('prev_value', F.lag(df.value).over(my_window)) df = df.withColumn('diff', F.when(F.isnull(df.value - df.prev_value), 0).otherwise(df.value - df.prev_value))","title":"row difference"},{"location":"python/pyspark/#bucketizer","text":"from pyspark.ml.feature import Bucketizer splits = [-float(\"inf\"), -0.5, 0.0, 0.5, float(\"inf\")] data = [(-999.9,), (-0.5,), (-0.3,), (0.0,), (0.2,), (999.9,)] df = spark.createDataFrame(data, [\"features\"]) bucketizer = Bucketizer(splits=splits, inputCol=\"features\", outputCol=\"bucketedFeatures\") print splits print df.show() # Transform original data into its bucket index. bucketedData = bucketizer.transform(df) print(\"Bucketizer output with %d buckets\" % (len(bucketizer.getSplits())-1)) bucketedData.show()","title":"bucketizer"},{"location":"python/pyspark/#stats","text":"","title":"stats"},{"location":"python/pyspark/#basic-statistics","text":"df.groupBy().agg(F.min('value'),F.avg('value'),F.max('value')).show()","title":"basic statistics"},{"location":"python/pyspark/#pearson-spearman-r-correlation-test","text":"df = df.select(*(col(c).cast('float') for c in df.columns)) df_rdd = df.rdd.map(lambda data: Vectors.dense([c for c in data])) result_matrix = Statistics.corr(df_rdd, method=\"pearson\") result_matrix = Statistics.corr(df_rdd, method=\"spearman\") result_dic = dict(zip(df_num.columns, result_matrix[0].tolist())) result_num = pd.DataFrame({'column': result_dic.keys(), 'corr': result_dic.values()})","title":"pearson / spearman R correlation test"},{"location":"python/pyspark/#chi-square-test","text":"df = df.na.fill('nah') df = df.select(*(hash(col(c)).cast('integer') for c in df.columns)) df_rdd = df.rdd.map(lambda data: Vectors.dense([c for c in data])) df_rdd = df_rdd.map(lambda row: LabeledPoint(row[0],row[1:])) obs = sc.parallelize( [LabeledPoint(1.0, [1.0,3.0]), LabeledPoint(1.0, [1.0,0.0]), LabeledPoint(1.0, [-1.0,-0.5])] ) featureTestResults = Statistics.chiSqTest(obs) for i, result in enumerate(featureTestResults_all_1): print(\"Click correlation with %s:\\n%s\\n\" % (df_rdd.columns[i+1], result)) res = [] for i, result in enumerate(featureTestResults): row = [] row.append(i) row.append(result.degreesOfFreedom) row.append(result.pValue) row.append(result.statistic) res.append(row) res = pd.DataFrame(res,columns=['col','dof','p','chi-sq']) res","title":"chi-square test"},{"location":"python/pyspark/#udfs-and-udafs","text":"def convert_big_num_smart(num): if num >= 1e9: big_num = str(round(num / 1e9, 1)) + 'B' elif num >= 1e6: big_num = str(round(num / 1e6, 1)) + 'M' elif num >= 1e3: big_num = str(round(num / 1e3, 1)) + 'K' else: big_num = str(round(num, 1)) return big_num convertBigNumSmartUDF = F.udf(convert_big_num_smart, StringType())","title":"UDFs and UDAFs"},{"location":"sql/hive/","text":"Hive Hive Language Manual run code: hive -e \"[sql command]\" > res.txt run file: hive -f [file_name.sql] > res.csv Configurations (optional) SET hive.cli.print.header=true; SET mapred.reduce.tasks=10000; SET mapreduce.job.reduces=10; Create/Delete Database CREATE DATABASE $db_name LOCATION '/tmp/$user_name/hive/jj_db'; DROP DATABASE $db_name; -- if $db_name is empty DROP DATABASE $db_name CASCADE; -- if $db_name is not empty, this will drop tables inside Create/Delete Table USE jj_db; CREATE TABLE jj_db.tb ( category string, cnt int) partitioned by(dt string); DROP TABLE $table_name; ALTER TABLE table_name RENAME TO new_table_name; Create a \"smaller\" table * USE jj_db; SET mapreduce.job.reduces=10; CREATE TABLE tmp_overlap STORED AS orc AS SELECT * FROM overlap CLUSTER BY int(rand() * 10); Insert/Delete Partition SET hive.exec.dynamic.partition.mode=nonstrict; INSERT INTO TABLE jj_db.tb PARTITION (dt) SELECT * FROM global_db.tb WHERE dt='20190727'; ALTER TABLE jj_db.res drop IF EXISTS PARTITION (dt='20190727'); Insert/Delete Row INSERT INTO $table (col1, col2, col3) VALUES (val1, val2, val3); DELETE FROM $table WHERE $condition; Insert/Delete Column ALTER TABLE tb ADD COLUMNS IF NOT EXISTS (category_id INT); once new column is added, we cannot add data w/o the new column one trick is to SELECT NULL as category_id make sure the order of columns are the same ALTER TABLE emp REPLACE COLUMNS (name string, dept string); cannot do drop column directly but the following: old table = {id, name, dept} new table = {name, dept} not sure how it works with partition : ( Check table USE jj_db; SHOW TABLES; SHOW PARTITIONS $datatable; SHOW CREATE TABLE $tablename; organized format: SELECT * FROM creative WHERE creative_id = 951866 \\G Query Examples IMPORTANT : every Hive query executed against a partitioned table must have a partition filter. If you run a query that does not have a partition filter, the query will fail with the following error: FAILED: SemanticException [Error 30020]: Partition filter is enforced for partition tables. Partition filter is missing for Table: concat_test<your table> explore data SELECT id, time, price FROM db WHERE datestamp = \"2020012520\" LIMIT 30; SELECT id, time, price FROM db WHERE datestamp BETWEEN \"2020012520\" AND \"2020012522\" LIMIT 30 explode array SELECT COUNT(1) as cnt FROM db.tb LATERAL VIEW EXPLODE (tb.events.sub_events) M as sub_event WHERE dt='${hiveconf:pre_date}' AND status='active' AND id=${hiveconf:id} AND mx3.timestamp>=${hiveconf:cutoff} use group by instead of countDistinct i.e. count distinct devices per publisher SELECT A.customer_id, COUNT(1) as cnt FROM (SELECT customer_id, device_id, COUNT(1) FROM db.tb WHERE datestamp='2019010100' GROUP BY customer_id, device_id) A GROUP BY A.customer_id case when SELECT CASE WHEN product_id = 1 THEN 'inhouse' WHEN product_id = 2 THEN 'outsource' ELSE 'unknown' END AS src, count(1) AS cnt FROM db.tb WHERE dt='20220101' GROUP BY 1 Working with Variables SET start_hour=2021060700; SET end_hour=2021060723; SELECT ROUND(SUM(is_true) * 100.0 / SUM(num), 2) AS imp_vlt_rate FROM db.tb WHERE datestamp >= '${hiveconf:start_hour}' AND datestamp <= '${hiveconf:end_hour}'; Run Hive in Loop from Shell #!/bin/sh if [ $# -lt 2 ] then echo \"Usage: ./run_hive.sh start_date(YYYYMMDD) end_date(YYYYMMDD, non-inclusive)\" exit fi start_date=$1 end_date=$2 while [ $start_date -lt $end_date ]; do echo $start_date hive dt=$start_hour -f generate_data.hql tmp=\"${start_date:0:8} 00:00:00\" start_date=$(date +\"%Y%m%d\" -d \"$tmp 1 day\") done execution ./run_hive.sh 20210101 20210102","title":"hive"},{"location":"sql/hive/#hive","text":"Hive Language Manual run code: hive -e \"[sql command]\" > res.txt run file: hive -f [file_name.sql] > res.csv","title":"Hive"},{"location":"sql/hive/#configurations-optional","text":"SET hive.cli.print.header=true; SET mapred.reduce.tasks=10000; SET mapreduce.job.reduces=10;","title":"Configurations (optional)"},{"location":"sql/hive/#createdelete-database","text":"CREATE DATABASE $db_name LOCATION '/tmp/$user_name/hive/jj_db'; DROP DATABASE $db_name; -- if $db_name is empty DROP DATABASE $db_name CASCADE; -- if $db_name is not empty, this will drop tables inside","title":"Create/Delete Database"},{"location":"sql/hive/#createdelete-table","text":"USE jj_db; CREATE TABLE jj_db.tb ( category string, cnt int) partitioned by(dt string); DROP TABLE $table_name; ALTER TABLE table_name RENAME TO new_table_name; Create a \"smaller\" table * USE jj_db; SET mapreduce.job.reduces=10; CREATE TABLE tmp_overlap STORED AS orc AS SELECT * FROM overlap CLUSTER BY int(rand() * 10);","title":"Create/Delete Table"},{"location":"sql/hive/#insertdelete-partition","text":"SET hive.exec.dynamic.partition.mode=nonstrict; INSERT INTO TABLE jj_db.tb PARTITION (dt) SELECT * FROM global_db.tb WHERE dt='20190727'; ALTER TABLE jj_db.res drop IF EXISTS PARTITION (dt='20190727');","title":"Insert/Delete Partition"},{"location":"sql/hive/#insertdelete-row","text":"INSERT INTO $table (col1, col2, col3) VALUES (val1, val2, val3); DELETE FROM $table WHERE $condition;","title":"Insert/Delete Row"},{"location":"sql/hive/#insertdelete-column","text":"ALTER TABLE tb ADD COLUMNS IF NOT EXISTS (category_id INT); once new column is added, we cannot add data w/o the new column one trick is to SELECT NULL as category_id make sure the order of columns are the same ALTER TABLE emp REPLACE COLUMNS (name string, dept string); cannot do drop column directly but the following: old table = {id, name, dept} new table = {name, dept} not sure how it works with partition : (","title":"Insert/Delete Column"},{"location":"sql/hive/#check-table","text":"USE jj_db; SHOW TABLES; SHOW PARTITIONS $datatable; SHOW CREATE TABLE $tablename; organized format: SELECT * FROM creative WHERE creative_id = 951866 \\G","title":"Check table"},{"location":"sql/hive/#query-examples","text":"IMPORTANT : every Hive query executed against a partitioned table must have a partition filter. If you run a query that does not have a partition filter, the query will fail with the following error: FAILED: SemanticException [Error 30020]: Partition filter is enforced for partition tables. Partition filter is missing for Table: concat_test<your table> explore data SELECT id, time, price FROM db WHERE datestamp = \"2020012520\" LIMIT 30; SELECT id, time, price FROM db WHERE datestamp BETWEEN \"2020012520\" AND \"2020012522\" LIMIT 30 explode array SELECT COUNT(1) as cnt FROM db.tb LATERAL VIEW EXPLODE (tb.events.sub_events) M as sub_event WHERE dt='${hiveconf:pre_date}' AND status='active' AND id=${hiveconf:id} AND mx3.timestamp>=${hiveconf:cutoff} use group by instead of countDistinct i.e. count distinct devices per publisher SELECT A.customer_id, COUNT(1) as cnt FROM (SELECT customer_id, device_id, COUNT(1) FROM db.tb WHERE datestamp='2019010100' GROUP BY customer_id, device_id) A GROUP BY A.customer_id case when SELECT CASE WHEN product_id = 1 THEN 'inhouse' WHEN product_id = 2 THEN 'outsource' ELSE 'unknown' END AS src, count(1) AS cnt FROM db.tb WHERE dt='20220101' GROUP BY 1","title":"Query Examples"},{"location":"sql/hive/#working-with-variables","text":"SET start_hour=2021060700; SET end_hour=2021060723; SELECT ROUND(SUM(is_true) * 100.0 / SUM(num), 2) AS imp_vlt_rate FROM db.tb WHERE datestamp >= '${hiveconf:start_hour}' AND datestamp <= '${hiveconf:end_hour}';","title":"Working with Variables"},{"location":"sql/hive/#run-hive-in-loop-from-shell","text":"#!/bin/sh if [ $# -lt 2 ] then echo \"Usage: ./run_hive.sh start_date(YYYYMMDD) end_date(YYYYMMDD, non-inclusive)\" exit fi start_date=$1 end_date=$2 while [ $start_date -lt $end_date ]; do echo $start_date hive dt=$start_hour -f generate_data.hql tmp=\"${start_date:0:8} 00:00:00\" start_date=$(date +\"%Y%m%d\" -d \"$tmp 1 day\") done execution ./run_hive.sh 20210101 20210102","title":"Run Hive in Loop from Shell"},{"location":"sql/presto/","text":"Presto SQL Statement Syntax Maths APPROX_PERCENTILE(total_amount, 0.90) AS p90 APPROX_DISTINCT() Row Percentage SUM(revenue) * 100.0 / SUM(SUM(revenue)) OVER() AS pct ROUND(SUM(revenue) * 100.0 / SUM(SUM(revenue)) OVER(), 2)AS pct Datetime SPLIT(pickup_datetime, '/')[1] AS month Sampling SELECT * FROM $table_name TABLESAMPLE BERNOULLI (50);","title":"presto"},{"location":"sql/presto/#presto","text":"SQL Statement Syntax","title":"Presto"},{"location":"sql/presto/#maths","text":"APPROX_PERCENTILE(total_amount, 0.90) AS p90 APPROX_DISTINCT() Row Percentage SUM(revenue) * 100.0 / SUM(SUM(revenue)) OVER() AS pct ROUND(SUM(revenue) * 100.0 / SUM(SUM(revenue)) OVER(), 2)AS pct","title":"Maths"},{"location":"sql/presto/#datetime","text":"SPLIT(pickup_datetime, '/')[1] AS month","title":"Datetime"},{"location":"sql/presto/#sampling","text":"SELECT * FROM $table_name TABLESAMPLE BERNOULLI (50);","title":"Sampling"}]}